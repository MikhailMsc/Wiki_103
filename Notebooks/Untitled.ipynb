{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5517505f-4924-4544-b216-69cd79a20068",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import sys\n",
    "import re\n",
    "import os\n",
    "import psutil\n",
    "from functools import lru_cache\n",
    "import time\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from collections import Counter, OrderedDict, namedtuple\n",
    "from functools import reduce\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import einops\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchtext.data import get_tokenizer\n",
    "from torchtext.vocab import vocab\n",
    "\n",
    "from random import randint\n",
    "import random\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "PROJECT_DIR = Path().absolute().parent\n",
    "WIKI_PATH = PROJECT_DIR / 'InputData' / 'wikitext-103'\n",
    "DATA_PATH = PROJECT_DIR / 'Data'\n",
    "\n",
    "sys.path.append(str(PROJECT_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a8620f7-5ec0-44aa-b4e6-bef4f8d2f6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_memory():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    print(f'{round(process.memory_info().rss * 10**(-6))} MB')\n",
    "\n",
    "def objects_memory(*args):\n",
    "    print(f'{round(sum([sys.getsizeof(obj) for obj in args]) * 10**(-6))} MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc170623-263d-42cb-8382-a59ec16f40cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pkl(obj, pth):\n",
    "    with open(pth, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def load_pkl(pth):\n",
    "    with open(pth, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f92c814-b7aa-4203-8bfb-f01e1853f5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import (\n",
    "    decoders,\n",
    "    models,\n",
    "    normalizers,\n",
    "    Regex,\n",
    "    pre_tokenizers,\n",
    "    processors,\n",
    "    trainers,\n",
    "    Tokenizer,\n",
    ")\n",
    "from transformers import PreTrainedTokenizerFast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5515c0ce-5c5a-4880-983c-a5b8b6b6bf48",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7aba1617-5b15-47d3-8ab4-1b54e7bafe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(tp='train'):\n",
    "    if tp not in ['train', 'test', 'valid']:\n",
    "        raise Exception('ERROR: Wrong type of data.')\n",
    "    \n",
    "    pth = WIKI_PATH / f'wiki.{tp}.raw'\n",
    "    heading_pattern = '\\n (= ){1,}[^=]*[^=] (= ){1,}\\n \\n'\n",
    "    with open(pth, 'r') as f:\n",
    "        raw_text = f.read()\n",
    "    \n",
    "    raw_text = re.split(heading_pattern, raw_text)\n",
    "    raw_text = [x.strip().strip('\\n').strip() for x in raw_text if x and x not in [' ', '= ']]\n",
    "    return raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffe72d18-3d98-4d38-be4b-a73ffb80c0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271821/623/552\n",
      "CPU times: user 4.41 s, sys: 2.55 s, total: 6.96 s\n",
      "Wall time: 7.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_data = load_data('train')\n",
    "test_data = load_data('test')\n",
    "valid_data = load_data('valid')\n",
    "\n",
    "print(f'{len(train_data)}/{len(test_data)}/{len(valid_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "236eddb0-6ab8-43fe-a858-2bc500c94fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_corpus():\n",
    "    for i in range(0, len(train_data), 1000):\n",
    "        yield train_data[i : i + 1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30db5bc-102f-4cc7-bc21-2903c15e7d45",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Build Alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2e71ab6-87b4-4a15-8d2e-3d987cba56ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_tokenizer = Tokenizer(models.Unigram())\n",
    "tmp_tokenizer.normalizer = normalizers.Sequence(\n",
    "    [\n",
    "        normalizers.Replace(\"``\", '\"'),\n",
    "        normalizers.Replace(\"''\", '\"'),\n",
    "        normalizers.Replace(\"”\", '\"'),\n",
    "        normalizers.Replace(\"“\", '\"'),\n",
    "        normalizers.Replace('ˈ', \"'\"),\n",
    "        normalizers.Replace('’',\"'\"),\n",
    "        normalizers.Replace('–',\"-\"),\n",
    "        normalizers.Replace('—',\"-\"),\n",
    "        normalizers.Replace('−',\"-\"),\n",
    "        normalizers.Replace('′',\"'\"),\n",
    "        normalizers.Replace('⁄',\"/\"),\n",
    "        normalizers.NFKD(),\n",
    "        normalizers.StripAccents(),\n",
    "        normalizers.Replace(Regex(\" {2,}\"), \" \"),\n",
    "    ]\n",
    ")\n",
    "tmp_tokenizer.pre_tokenizer = pre_tokenizers.Sequence(\n",
    "    [\n",
    "        pre_tokenizers.BertPreTokenizer(), \n",
    "        # pre_tokenizers.Metaspace(replacement = '_', add_prefix_space = True),\n",
    "        # pre_tokenizers.Punctuation(),\n",
    "        pre_tokenizers.Digits(individual_digits=True)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07969638-8cd6-41f9-9eee-25cbb5f56647",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 271821/271821 [00:26<00:00, 10241.82it/s]\n"
     ]
    }
   ],
   "source": [
    "char_counter = Counter()\n",
    "for i in tqdm(range(len(train_data))):\n",
    "    art_counter = Counter(train_data[i])\n",
    "    char_counter.update(art_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01dc6e55-eb0c-4963-a684-2683527d2211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4978, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_counter_df = pd.DataFrame(char_counter.most_common(), columns=['Symbol', 'Count'])\n",
    "char_counter_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d427827-69ad-4710-a0da-57da437268dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4735\n",
       "0     229\n",
       "3      11\n",
       "2       2\n",
       "4       1\n",
       "Name: Base_Symbol, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_base_char(txt):\n",
    "    tokens = tmp_tokenizer.encode(txt).tokens\n",
    "    return tokens\n",
    "char_counter_df['Base_Symbol'] = char_counter_df['Symbol'].apply(get_base_char)\n",
    "char_counter_df['Base_Symbol'].apply(len).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e1ff2ad-61ad-4635-b16b-e4c1cc40047a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Count</th>\n",
       "      <th>Base_Symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>…</td>\n",
       "      <td>1961</td>\n",
       "      <td>[., ., .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>½</td>\n",
       "      <td>757</td>\n",
       "      <td>[1, ⁄, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>″</td>\n",
       "      <td>535</td>\n",
       "      <td>[′, ′]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>⅓</td>\n",
       "      <td>86</td>\n",
       "      <td>[1, ⁄, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>⅔</td>\n",
       "      <td>58</td>\n",
       "      <td>[2, ⁄, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>¼</td>\n",
       "      <td>55</td>\n",
       "      <td>[1, ⁄, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>¾</td>\n",
       "      <td>55</td>\n",
       "      <td>[3, ⁄, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>⅜</td>\n",
       "      <td>11</td>\n",
       "      <td>[3, ⁄, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>⅛</td>\n",
       "      <td>9</td>\n",
       "      <td>[1, ⁄, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>⅝</td>\n",
       "      <td>9</td>\n",
       "      <td>[5, ⁄, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2580</th>\n",
       "      <td>⅞</td>\n",
       "      <td>3</td>\n",
       "      <td>[7, ⁄, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2599</th>\n",
       "      <td>‼</td>\n",
       "      <td>3</td>\n",
       "      <td>[!, !]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3359</th>\n",
       "      <td>ﷺ</td>\n",
       "      <td>2</td>\n",
       "      <td>[صلى, الله, عليه, وسلم]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4238</th>\n",
       "      <td>⅙</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, ⁄, 6]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Symbol  Count              Base_Symbol\n",
       "122       …   1961                [., ., .]\n",
       "172       ½    757                [1, ⁄, 2]\n",
       "202       ″    535                   [′, ′]\n",
       "468       ⅓     86                [1, ⁄, 3]\n",
       "568       ⅔     58                [2, ⁄, 3]\n",
       "591       ¼     55                [1, ⁄, 4]\n",
       "592       ¾     55                [3, ⁄, 4]\n",
       "1310      ⅜     11                [3, ⁄, 8]\n",
       "1468      ⅛      9                [1, ⁄, 8]\n",
       "1482      ⅝      9                [5, ⁄, 8]\n",
       "2580      ⅞      3                [7, ⁄, 8]\n",
       "2599      ‼      3                   [!, !]\n",
       "3359      ﷺ      2  [صلى, الله, عليه, وسلم]\n",
       "4238      ⅙      1                [1, ⁄, 6]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_counter_df[char_counter_df['Base_Symbol'].apply(len) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cacd9e1-f01a-4fe8-aff5-808084e32c0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Count</th>\n",
       "      <th>Base_Symbol</th>\n",
       "      <th>Single_Base_Symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>99530965</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>48657548</td>\n",
       "      <td>[e]</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t</td>\n",
       "      <td>33788437</td>\n",
       "      <td>[t]</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>33364371</td>\n",
       "      <td>[a]</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n</td>\n",
       "      <td>28965321</td>\n",
       "      <td>[n]</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4973</th>\n",
       "      <td>課</td>\n",
       "      <td>1</td>\n",
       "      <td>[課]</td>\n",
       "      <td>課</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4974</th>\n",
       "      <td>純</td>\n",
       "      <td>1</td>\n",
       "      <td>[純]</td>\n",
       "      <td>純</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4975</th>\n",
       "      <td>丽</td>\n",
       "      <td>1</td>\n",
       "      <td>[丽]</td>\n",
       "      <td>丽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4976</th>\n",
       "      <td>치</td>\n",
       "      <td>1</td>\n",
       "      <td>[치]</td>\n",
       "      <td>치</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4977</th>\n",
       "      <td>킨</td>\n",
       "      <td>1</td>\n",
       "      <td>[킨]</td>\n",
       "      <td>킨</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4978 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Symbol     Count Base_Symbol Single_Base_Symbol\n",
       "0            99530965          []                   \n",
       "1         e  48657548         [e]                  e\n",
       "2         t  33788437         [t]                  t\n",
       "3         a  33364371         [a]                  a\n",
       "4         n  28965321         [n]                  n\n",
       "...     ...       ...         ...                ...\n",
       "4973      課         1         [課]                  課\n",
       "4974      純         1         [純]                  純\n",
       "4975      丽         1         [丽]                  丽\n",
       "4976      치         1        [치]                 치\n",
       "4977      킨         1       [킨]                킨\n",
       "\n",
       "[4978 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_counter_df['Single_Base_Symbol'] = char_counter_df['Base_Symbol'].apply(lambda x: x[0] if x else '')\n",
    "char_counter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44eb273f-0f55-4690-87e2-5cbeeec121ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Single_Base_Symbol</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>100128792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>48715319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t</td>\n",
       "      <td>33789131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>33401452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n</td>\n",
       "      <td>28970107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4195</th>\n",
       "      <td>恢</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4196</th>\n",
       "      <td>恒</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4197</th>\n",
       "      <td>恆</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4198</th>\n",
       "      <td>怨</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4199</th>\n",
       "      <td>🖕</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Single_Base_Symbol      Count\n",
       "0                        100128792\n",
       "1                     e   48715319\n",
       "2                     t   33789131\n",
       "3                     a   33401452\n",
       "4                     n   28970107\n",
       "...                 ...        ...\n",
       "4195                  恢          1\n",
       "4196                  恒          1\n",
       "4197                  恆          1\n",
       "4198                  怨          1\n",
       "4199                  🖕          1\n",
       "\n",
       "[4200 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_counter_df = char_counter_df.groupby('Single_Base_Symbol')['Count'].sum().reset_index()\n",
    "char_counter_df = char_counter_df.sort_values('Count', ascending=False).reset_index(drop=True)\n",
    "char_counter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a97a3d22-1d75-4502-bf12-850f23190881",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_counter_df['Cum_Prc'] = (char_counter_df['Count'] / char_counter_df['Count'].sum()).cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c1cc5343-4f8f-4f82-9b33-ccadab7888b0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Single_Base_Symbol</th>\n",
       "      <th>Count</th>\n",
       "      <th>Cum_Prc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>)</td>\n",
       "      <td>572467</td>\n",
       "      <td>0.984419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>(</td>\n",
       "      <td>572111</td>\n",
       "      <td>0.985501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>3</td>\n",
       "      <td>541764</td>\n",
       "      <td>0.986526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5</td>\n",
       "      <td>538413</td>\n",
       "      <td>0.987544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>8</td>\n",
       "      <td>532060</td>\n",
       "      <td>0.988550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>E</td>\n",
       "      <td>514159</td>\n",
       "      <td>0.989523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>J</td>\n",
       "      <td>503445</td>\n",
       "      <td>0.990475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>4</td>\n",
       "      <td>495231</td>\n",
       "      <td>0.991412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>O</td>\n",
       "      <td>462139</td>\n",
       "      <td>0.992286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>6</td>\n",
       "      <td>445885</td>\n",
       "      <td>0.993129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>7</td>\n",
       "      <td>442039</td>\n",
       "      <td>0.993965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>z</td>\n",
       "      <td>418318</td>\n",
       "      <td>0.994757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>j</td>\n",
       "      <td>379936</td>\n",
       "      <td>0.995475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>K</td>\n",
       "      <td>347264</td>\n",
       "      <td>0.996132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>q</td>\n",
       "      <td>339468</td>\n",
       "      <td>0.996774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>U</td>\n",
       "      <td>311682</td>\n",
       "      <td>0.997364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>V</td>\n",
       "      <td>254111</td>\n",
       "      <td>0.997844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>;</td>\n",
       "      <td>190871</td>\n",
       "      <td>0.998205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>:</td>\n",
       "      <td>176460</td>\n",
       "      <td>0.998539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Y</td>\n",
       "      <td>144573</td>\n",
       "      <td>0.998812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>/</td>\n",
       "      <td>72465</td>\n",
       "      <td>0.998949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Z</td>\n",
       "      <td>56234</td>\n",
       "      <td>0.999056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>$</td>\n",
       "      <td>46731</td>\n",
       "      <td>0.999144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Q</td>\n",
       "      <td>46310</td>\n",
       "      <td>0.999232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>]</td>\n",
       "      <td>39560</td>\n",
       "      <td>0.999307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>[</td>\n",
       "      <td>39478</td>\n",
       "      <td>0.999381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>%</td>\n",
       "      <td>38496</td>\n",
       "      <td>0.999454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>X</td>\n",
       "      <td>38489</td>\n",
       "      <td>0.999527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>&amp;</td>\n",
       "      <td>26405</td>\n",
       "      <td>0.999577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>!</td>\n",
       "      <td>17692</td>\n",
       "      <td>0.999610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>°</td>\n",
       "      <td>13468</td>\n",
       "      <td>0.999636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>£</td>\n",
       "      <td>12026</td>\n",
       "      <td>0.999659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>?</td>\n",
       "      <td>11922</td>\n",
       "      <td>0.999681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>+</td>\n",
       "      <td>7602</td>\n",
       "      <td>0.999695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>#</td>\n",
       "      <td>4763</td>\n",
       "      <td>0.999704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>ø</td>\n",
       "      <td>4750</td>\n",
       "      <td>0.999713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>=</td>\n",
       "      <td>4337</td>\n",
       "      <td>0.999722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>ł</td>\n",
       "      <td>4112</td>\n",
       "      <td>0.999729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>&gt;</td>\n",
       "      <td>3857</td>\n",
       "      <td>0.999737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>&lt;</td>\n",
       "      <td>3754</td>\n",
       "      <td>0.999744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>×</td>\n",
       "      <td>3633</td>\n",
       "      <td>0.999751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>α</td>\n",
       "      <td>2819</td>\n",
       "      <td>0.999756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Æ</td>\n",
       "      <td>2759</td>\n",
       "      <td>0.999761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>μ</td>\n",
       "      <td>2739</td>\n",
       "      <td>0.999766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>*</td>\n",
       "      <td>2733</td>\n",
       "      <td>0.999772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ο</td>\n",
       "      <td>2260</td>\n",
       "      <td>0.999776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>æ</td>\n",
       "      <td>2251</td>\n",
       "      <td>0.999780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ð</td>\n",
       "      <td>2076</td>\n",
       "      <td>0.999784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>₹</td>\n",
       "      <td>1747</td>\n",
       "      <td>0.999787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ə</td>\n",
       "      <td>1694</td>\n",
       "      <td>0.999791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Đ</td>\n",
       "      <td>1617</td>\n",
       "      <td>0.999794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>ι</td>\n",
       "      <td>1578</td>\n",
       "      <td>0.999797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>ː</td>\n",
       "      <td>1483</td>\n",
       "      <td>0.999799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>ν</td>\n",
       "      <td>1327</td>\n",
       "      <td>0.999802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>ε</td>\n",
       "      <td>1303</td>\n",
       "      <td>0.999804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>ς</td>\n",
       "      <td>1268</td>\n",
       "      <td>0.999807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>а</td>\n",
       "      <td>1238</td>\n",
       "      <td>0.999809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>и</td>\n",
       "      <td>1190</td>\n",
       "      <td>0.999811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>τ</td>\n",
       "      <td>1144</td>\n",
       "      <td>0.999814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>€</td>\n",
       "      <td>1097</td>\n",
       "      <td>0.999816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Single_Base_Symbol   Count   Cum_Prc\n",
       "50                   )  572467  0.984419\n",
       "51                   (  572111  0.985501\n",
       "52                   3  541764  0.986526\n",
       "53                   5  538413  0.987544\n",
       "54                   8  532060  0.988550\n",
       "55                   E  514159  0.989523\n",
       "56                   J  503445  0.990475\n",
       "57                   4  495231  0.991412\n",
       "58                   O  462139  0.992286\n",
       "59                   6  445885  0.993129\n",
       "60                   7  442039  0.993965\n",
       "61                   z  418318  0.994757\n",
       "62                   j  379936  0.995475\n",
       "63                   K  347264  0.996132\n",
       "64                   q  339468  0.996774\n",
       "65                   U  311682  0.997364\n",
       "66                   V  254111  0.997844\n",
       "67                   ;  190871  0.998205\n",
       "68                   :  176460  0.998539\n",
       "69                   Y  144573  0.998812\n",
       "70                   /   72465  0.998949\n",
       "71                   Z   56234  0.999056\n",
       "72                   $   46731  0.999144\n",
       "73                   Q   46310  0.999232\n",
       "74                   ]   39560  0.999307\n",
       "75                   [   39478  0.999381\n",
       "76                   %   38496  0.999454\n",
       "77                   X   38489  0.999527\n",
       "78                   &   26405  0.999577\n",
       "79                   !   17692  0.999610\n",
       "80                   °   13468  0.999636\n",
       "81                   £   12026  0.999659\n",
       "82                   ?   11922  0.999681\n",
       "83                   +    7602  0.999695\n",
       "84                   #    4763  0.999704\n",
       "85                   ø    4750  0.999713\n",
       "86                   =    4337  0.999722\n",
       "87                   ł    4112  0.999729\n",
       "88                   >    3857  0.999737\n",
       "89                   <    3754  0.999744\n",
       "90                   ×    3633  0.999751\n",
       "91                   α    2819  0.999756\n",
       "92                   Æ    2759  0.999761\n",
       "93                   μ    2739  0.999766\n",
       "94                   *    2733  0.999772\n",
       "95                   ο    2260  0.999776\n",
       "96                   æ    2251  0.999780\n",
       "97                   ð    2076  0.999784\n",
       "98                   ₹    1747  0.999787\n",
       "99                   ə    1694  0.999791\n",
       "100                  Đ    1617  0.999794\n",
       "101                  ι    1578  0.999797\n",
       "102                  ː    1483  0.999799\n",
       "103                  ν    1327  0.999802\n",
       "104                  ε    1303  0.999804\n",
       "105                  ς    1268  0.999807\n",
       "106                  а    1238  0.999809\n",
       "107                  и    1190  0.999811\n",
       "108                  τ    1144  0.999814\n",
       "109                  €    1097  0.999816"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_counter_df.head(110).tail(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad7b6ff5-11ae-4157-9550-91aa250343af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet = list(char_counter_df['Single_Base_Symbol'][:90])\n",
    "[x for x in range(10) if str(x) not in alphabet]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410151a1-c3e7-447a-92f2-7e93d27f1d87",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Build Tokenizer\n",
    "https://colab.research.google.com/github/tenexcoder/huggingface-tutorials/blob/main/BERT_tokenizer_from_scratch.ipynb\n",
    "https://huggingface.co/transformers/v3.5.1/main_classes/tokenizer.html\n",
    "https://huggingface.co/course/chapter6/8?fw=tf\n",
    "\n",
    "Steps\n",
    "1) Normalization\n",
    "2) Pre_tokenization\n",
    "3) Model\n",
    "4) Post-processor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0e2b68-83df-41d7-8ab7-30f3013b81ee",
   "metadata": {},
   "source": [
    "## 1) Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a680bc39-74be-4597-8823-e15e0c741ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "normlzr = normalizers.Sequence(\n",
    "    [\n",
    "        normalizers.Replace(\"``\", '\"'),\n",
    "        normalizers.Replace(\"''\", '\"'),\n",
    "        normalizers.Replace(\"”\", '\"'),\n",
    "        normalizers.Replace(\"“\", '\"'),\n",
    "        normalizers.Replace('ˈ', \"'\"),\n",
    "        normalizers.Replace('’',\"'\"),\n",
    "        normalizers.Replace('–',\"-\"),\n",
    "        normalizers.Replace('—',\"-\"),\n",
    "        normalizers.Replace('−',\"-\"),\n",
    "        normalizers.Replace('′',\"'\"),\n",
    "        normalizers.Replace('⁄',\"/\"),\n",
    "        normalizers.NFKD(),\n",
    "        normalizers.StripAccents(),\n",
    "        normalizers.Replace(Regex(\" {2,}\"), \" \"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d100011-4790-4961-8217-e97d4fa420a7",
   "metadata": {},
   "source": [
    "## 2) Pre-tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6d1a279-382a-4964-8a31-8aac25803ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretknzr = pre_tokenizers.Sequence(\n",
    "    [\n",
    "        pre_tokenizers.BertPreTokenizer(), \n",
    "        # pre_tokenizers.Metaspace(replacement = '_', add_prefix_space = True),\n",
    "        # pre_tokenizers.Punctuation(),\n",
    "        pre_tokenizers.Digits(individual_digits=True)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f01ec3-fe13-4df7-bad4-9874ca9d9033",
   "metadata": {},
   "source": [
    "## 3) Model Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0229a5f-c047-4437-9f3a-d772181b3050",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ?trainers.BpeTrainer\n",
    "# ?trainers.WordPieceTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1b80a932-637b-4d50-8424-08dc7d566691",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_type = 'BPE'\n",
    "# model_type = 'WordPiece'\n",
    "\n",
    "SPEC_TOKENS = [\"[UNK]\", \"[PAD]\"]\n",
    "\n",
    "if model_type == 'WordPiece':\n",
    "    tokenizer = Tokenizer(models.WordPiece(unk_token=\"[UNK]\"))\n",
    "    \n",
    "    trainer = trainers.WordPieceTrainer(\n",
    "        vocab_size=50000, \n",
    "        min_frequency=0, \n",
    "        special_tokens=SPEC_TOKENS, \n",
    "        limit_alphabet=len(alphabet),\n",
    "        initial_alphabet=alphabet,\n",
    "        continuing_subword_prefix='##',\n",
    "        end_of_word_suffix='__'\n",
    "        \n",
    "    )\n",
    "elif model_type == 'BPE':\n",
    "    tokenizer = Tokenizer(models.BPE(unk_token=\"[UNK]\"))\n",
    "    \n",
    "    trainer = trainers.BpeTrainer(\n",
    "        vocab_size=100000, \n",
    "        min_frequency=0, \n",
    "        special_tokens=SPEC_TOKENS, \n",
    "        limit_alphabet=len(alphabet),\n",
    "        initial_alphabet=alphabet,\n",
    "        continuing_subword_prefix='##',\n",
    "        end_of_word_suffix='__'\n",
    "    )\n",
    "    \n",
    "tokenizer.normalizer = normlzr\n",
    "tokenizer.pre_tokenizer = pretknzr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d14bf98f-bd67-4967-a82e-466c1cae8ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(models.Unigram())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7abd1009-7fb5-422c-bd99-73fc8ba0767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.normalizer = normalizers.Sequence(\n",
    "    [\n",
    "        normalizers.Replace(\"``\", '\"'),\n",
    "        normalizers.Replace(\"''\", '\"'),\n",
    "        normalizers.Replace(\"”\", '\"'),\n",
    "        normalizers.Replace(\"“\", '\"'),\n",
    "        normalizers.Replace('ˈ', \"'\"),\n",
    "        normalizers.Replace('’',\"'\"),\n",
    "        normalizers.Replace('–',\"-\"),\n",
    "        normalizers.Replace('—',\"-\"),\n",
    "        normalizers.Replace('−',\"-\"),\n",
    "        normalizers.Replace('′',\"'\"),\n",
    "        normalizers.Replace('⁄',\"/\"),\n",
    "        normalizers.NFKD(),\n",
    "        normalizers.StripAccents(),\n",
    "        normalizers.Replace(Regex(\" {2,}\"), \" \"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a38da04f-2a6b-49f3-bd4d-ede08219641d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pre_tokenizer = pre_tokenizers.Metaspace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8617af-9873-4060-95ff-0bff18ebe623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "special_tokens = [\"<unk>\", \"<pad>\", \"<s>\", \"</s>\"]\n",
    "trainer = trainers.UnigramTrainer(\n",
    "    vocab_size=25000, special_tokens=special_tokens, unk_token=\"<unk>\"\n",
    ")\n",
    "tokenizer.train_from_iterator(get_training_corpus(), trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f41423db-08cf-4feb-a499-bbe7d110230a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁let', \"'\", 's', '▁test', '▁this', '▁to', 'ken', 'i', 'zer', '.']\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer.encode(\"Let's test this tokenizer.\")\n",
    "print(encoding.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a0dd5180-3bf3-4b3b-a0b8-b8b60ebc7cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁let', \"'\", 's', '▁test', '▁this', '▁to', 'ken', 'i', 'zer', '.', '.', '.', '▁on', '▁', 'a', '▁pair', '▁of', '▁sentence', 's', '!']\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer.encode(\"Let's test this tokenizer...\", \"on a pair of sentences!\")\n",
    "print(encoding.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "97e98f64-1b25-4aaa-a121-1b4ec33e36e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decoder = decoders.Metaspace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "df7f1f2d-3177-476d-8364-9b3b169448a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save(str(DATA_PATH / \"unigram_tokenizer.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "94624417-ef45-49b9-9c95-5d94266efa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_object=tokenizer,\n",
    "    bos_token=\"<s>\",\n",
    "    eos_token=\"</s>\",\n",
    "    unk_token=\"<unk>\",\n",
    "    pad_token=\"<pad>\",\n",
    "    padding_side=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "63ebbd5f-a44c-4418-9dd0-15c806360700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁let', \"'\", 's', '▁test', '▁this', '▁to', 'ken', 'i', 'zer', '.', '▁', 'i', '▁want', '▁you', '.']\n",
      "[1575, 72, 8, 778, 49, 15, 2883, 30, 3483, 7, 4, 30, 1163, 226, 7]\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer.encode(\"Let's test this tokenizer. I want you.\")\n",
    "print(encoding.tokens)\n",
    "print(encoding.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5485fbbb-93be-415d-b256-a6cbb0e48c9b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Senjō no Valkyria 3 : Unrecorded Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" Calamaty Raven \" . \\n The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more forgiving for series newcomers . Character designer Raita Honjou and composer Hitoshi Sakimoto both returned from previous entries , along with Valkyria Chronicles II director Takeshi Ozawa . A large team of writers handled the script . The game \\'s opening theme was sung by May \\'n . \\n It met with positive sales in Japan , and was praised by both Japanese and western critics . After release , it received downloadable content , along with an expanded edition in November of that year . It was also adapted into manga and an original video animation series . Due to low sales of Valkyria Chronicles II , Valkyria Chronicles III was not localized , but a fan translation compatible with the game \\'s expanded edition was released in 2014 . Media.Vision would return to the franchise with the development of Valkyria : Azure Revolution for the PlayStation 4 .'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "181df2a7-9ef9-461e-aeac-5b320fffdf6b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁sen', 'jo', '▁no', '▁val', 'k', 'y', 'ria', '▁', '3', '▁', ':', '▁un', 'recorded', '▁chronicle', 's', '▁', '(', '▁japanes', 'e', '▁', ':', '▁', '戦', '場', 'の', 'ウ', 'ァ', 'ル', 'キ', 'ュ', 'リ', 'ア', '3', '▁', ',', '▁lit', '▁', '.', '▁val', 'k', 'y', 'ria', '▁of', '▁the', '▁battlefield', '▁', '3', '▁', ')', '▁', ',', '▁common', 'ly', '▁referre', 'd', '▁to', '▁as', '▁val', 'k', 'y', 'ria', '▁chronicle', 's', '▁iii', '▁outside', '▁japan', '▁', ',', '▁is', '▁', 'a', '▁tactical', '▁role', '▁', '@', '-', '@', '▁playing', '▁video', '▁game', '▁develope', 'd', '▁by', '▁sega', '▁and', '▁media', '.', 'vision', '▁for', '▁the', '▁playstation', '▁portable', '▁', '.', '▁released', '▁in', '▁january', '▁2011', '▁in', '▁japan', '▁', ',', '▁it', '▁is', '▁the', '▁third', '▁game', '▁in', '▁the', '▁val', 'k', 'y', 'ria', '▁series', '▁', '.', '▁employ', 'ing', '▁the', '▁same', '▁fusion', '▁of', '▁tactical', '▁and', '▁real', '▁', '@', '-', '@', '▁time', '▁gameplay', '▁as', '▁its', '▁predecessor', 's', '▁', ',', '▁the', '▁story', '▁runs', '▁parallel', '▁to', '▁the', '▁first', '▁game', '▁and', '▁follows', '▁the', '▁', '\"', '▁name', 'less', '▁', '\"', '▁', ',', '▁', 'a', '▁penal', '▁military', '▁unit', '▁serving', '▁the', '▁nation', '▁of', '▁galli', 'a', '▁during', '▁the', '▁second', '▁europa', 'n', '▁war', '▁who', '▁perform', '▁secret', '▁black', '▁operations', '▁and', '▁are', '▁pitted', '▁against', '▁the', '▁imperial', '▁unit', '▁', '\"', '▁ca', 'lam', 'a', 't', 'y', '▁raven', '▁', '\"', '▁', '.', '▁', '\\n', '▁the', '▁game', '▁began', '▁development', '▁in', '▁2010', '▁', ',', '▁carrying', '▁over', '▁', 'a', '▁large', '▁portion', '▁of', '▁the', '▁work', '▁done', '▁on', '▁val', 'k', 'y', 'ria', '▁chronicle', 's', '▁', 'i', 'i', '▁', '.', '▁while', '▁it', '▁retaine', 'd', '▁the', '▁standard', '▁features', '▁of', '▁the', '▁series', '▁', ',', '▁it', '▁also', '▁under', 'went', '▁multiple', '▁adjustment', 's', '▁', ',', '▁such', '▁as', '▁making', '▁the', '▁game', '▁more', '▁for', 'g', 'iv', 'ing', '▁for', '▁series', '▁newcomer', 's', '▁', '.', '▁character', '▁designer', '▁rai', 't', 'a', '▁', 'h', 'on', 'jo', 'u', '▁and', '▁composer', '▁hit', 'oshi', '▁', 'saki', 'moto', '▁both', '▁returne', 'd', '▁from', '▁previous', '▁', 'e', 'ntries', '▁', ',', '▁along', '▁with', '▁val', 'k', 'y', 'ria', '▁chronicle', 's', '▁', 'i', 'i', '▁director', '▁take', 'shi', '▁', 'o', 'zawa', '▁', '.', '▁', 'a', '▁large', '▁team', '▁of', '▁writers', '▁handle', 'd', '▁the', '▁script', '▁', '.', '▁the', '▁game', \"▁'s\", '▁opening', '▁theme', '▁was', '▁sung', '▁by', '▁may', '▁', \"'\", 'n', '▁', '.', '▁', '\\n', '▁it', '▁met', '▁with', '▁positive', '▁sales', '▁in', '▁japan', '▁', ',', '▁and', '▁was', '▁praise', 'd', '▁by', '▁both', '▁japanes', 'e', '▁and', '▁western', '▁critics', '▁', '.', '▁after', '▁release', '▁', ',', '▁it', '▁receive', 'd', '▁download', 'able', '▁content', '▁', ',', '▁along', '▁with', '▁an', '▁expande', 'd', '▁edition', '▁in', '▁november', '▁of', '▁that', '▁year', '▁', '.', '▁it', '▁was', '▁also', '▁adapted', '▁into', '▁manga', '▁and', '▁an', '▁original', '▁video', '▁animation', '▁series', '▁', '.', '▁due', '▁to', '▁low', '▁sales', '▁of', '▁val', 'k', 'y', 'ria', '▁chronicle', 's', '▁', 'i', 'i', '▁', ',', '▁val', 'k', 'y', 'ria', '▁chronicle', 's', '▁iii', '▁was', '▁not', '▁localize', 'd', '▁', ',', '▁but', '▁', 'a', '▁fan', '▁translation', '▁compatible', '▁with', '▁the', '▁game', \"▁'s\", '▁expande', 'd', '▁edition', '▁was', '▁released', '▁in', '▁2014', '▁', '.', '▁media', '.', 'vision', '▁would', '▁return', '▁to', '▁the', '▁franchise', '▁with', '▁the', '▁development', '▁of', '▁val', 'k', 'y', 'ria', '▁', ':', '▁', 'a', 'zur', 'e', '▁revolution', '▁for', '▁the', '▁playstation', '▁', '4', '▁', '.']\n",
      "479\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer.encode(train_data[0])\n",
    "print(encoding.tokens)\n",
    "print(len(encoding.tokens))\n",
    "# print(encoding.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0392e3e-f673-44ff-847e-d50e6d3a7747",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4) Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6195f4ae-eb5c-450d-9878-354d9385739b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Let', (0, 3)),\n",
       " (\"'\", (3, 4)),\n",
       " ('s', (4, 5)),\n",
       " ('test', (6, 10)),\n",
       " ('pre', (11, 14)),\n",
       " ('-', (14, 15)),\n",
       " ('tokenization', (15, 27)),\n",
       " ('!', (27, 28)),\n",
       " ('1', (29, 30)),\n",
       " ('2', (30, 31)),\n",
       " ('3', (31, 32))]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pre_tokenizer.pre_tokenize_str(\"Let's test pre-tokenization! 123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "48ced57b-e05b-4f66-97f4-e7f9ad074338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "CPU times: user 10min 2s, sys: 37.1 s, total: 10min 39s\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer.train_from_iterator(get_training_corpus(), trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d5b36721-3f45-47c4-97ea-95547e1eebb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello__', 'how__', 'are__', 'u__', '?__']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.encode(\"Héllò hôw are ü?\").tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "762ecdf7-c126-4719-868a-3542a5174d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save(str(DATA_PATH / \"Tokenizer_BPE100k.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "382a4dab-b52e-4022-87f6-4608a32ad531",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_file=str(DATA_PATH / \"Tokenizer_BPE100k.json\"),\n",
    "    unk_token=\"[UNK]\",\n",
    "    pad_token=\"[PAD]\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508f05dd-c8e9-42ea-875e-53f8b218d8b6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Post Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313fca71-0f41-434b-8d4b-aa008333cfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_post_tokenize(encoding):\n",
    "    tokens = ['']\n",
    "    tokens_ids = []\n",
    "    for tk, tkid in zip(encoding.tokens, encoding.ids):\n",
    "        if tk == '[UNK]' and tokens == '[UNK]':[-1]\n",
    "            continue\n",
    "        else:\n",
    "            tokens.append(tk)\n",
    "            tokens_ids.append(tkid)\n",
    "        \n",
    "    tokens.pop(0)\n",
    "    \n",
    "    return tokens, tokens_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "61f4caea-904e-45ed-9402-8489682fa68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.token_to_id('[PAD]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "eceae6d1-8dd1-4dcd-8468-af393452999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Token = namedtuple('Token', ['tid', 'value', 'title', 'upper','part', 'w_end'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b23d5b24-32b2-4632-98e1-0ea31ad8e02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_VOCAB = {\n",
    "    'First': tokenizer.get_vocab(),\n",
    "    'First_Reverse': {v:k for k,v in tokenizer.get_vocab().items()},\n",
    "    'First_Second': {\n",
    "        tokenizer.token_to_id('[UNK]'): Token(tid=tokenizer.token_to_id('[UNK]'), value='[unk]', \n",
    "                       title=False, upper=False, part=False, w_end=True),\n",
    "        tokenizer.token_to_id('[PAD]'): Token(tid=tokenizer.token_to_id('[PAD]'), value='[pad]',\n",
    "                       title=False, upper=False, part=False, w_end=True)\n",
    "    },\n",
    "    'First_Second_Reverse': {\n",
    "        Token(tid=tokenizer.token_to_id('[UNK]'), value='[unk]',\n",
    "              title=False, upper=False, part=False, w_end=True): tokenizer.token_to_id('[UNK]'), \n",
    "        Token(tid=tokenizer.token_to_id('[PAD]'), value='[pad]',\n",
    "              title=False, upper=False, part=False, w_end=True): tokenizer.token_to_id('[PAD]'), \n",
    "    },\n",
    "    'Second': {\n",
    "        '[unk]': tokenizer.token_to_id('[UNK]'),\n",
    "        '[pad]': tokenizer.token_to_id('[PAD]'),\n",
    "    },\n",
    "    'Second_Reverse': {\n",
    "        tokenizer.token_to_id('[UNK]'): '[unk]',\n",
    "        tokenizer.token_to_id('[PAD]'): '[pad]',\n",
    "    }    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "825faf34-8b0d-4669-8a78-78e36815d6a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100000/100000 [00:53<00:00, 1870.71it/s]\n"
     ]
    }
   ],
   "source": [
    "max_new_id = max(ALL_VOCAB['Second_Reverse'].keys())\n",
    "\n",
    "for tk, tkid in tqdm(tokenizer.get_vocab().items()):\n",
    "    if tkid in ALL_VOCAB['First_Second']:\n",
    "        continue\n",
    "        \n",
    "    part = tk[:2] == '##'\n",
    "    w_end = tk[-2:] == '__'\n",
    "    tk = tk.replace('##','').replace('__','')\n",
    "    upper = tk.isupper()\n",
    "    title = tk[0].isupper()\n",
    "    value = tk.lower()\n",
    "    if value in ALL_VOCAB['Second'].keys():\n",
    "        value_id = ALL_VOCAB['Second'][value]\n",
    "    else:\n",
    "        value_id = max(ALL_VOCAB['Second_Reverse'].keys()) + 1\n",
    "        ALL_VOCAB['Second'][value] = value_id\n",
    "        ALL_VOCAB['Second_Reverse'][value_id] = value\n",
    "    \n",
    "    tk = Token(\n",
    "        tid=value_id, value=value, \n",
    "        title=title, upper=upper, part=part, w_end=w_end\n",
    "    )\n",
    "    ALL_VOCAB['First_Second'][tkid] = tk\n",
    "    ALL_VOCAB['First_Second_Reverse'][tk] = tkid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ac3c1ee2-857c-49a0-b42d-0114b6df2330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75463"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ALL_VOCAB['Second_Reverse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3d3040c4-ce10-48c1-a47b-7b1acbb53324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75463"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(x.strip('__').strip('##').lower() for x in  tokenizer.get_vocab().keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "bc0d471e-7442-495b-a3cc-861bd122bdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pkl(ALL_VOCAB, DATA_PATH / \"ALLVOCAB_BPE100k.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "10cb2758-132d-4590-94b7-ff57664dbdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_txt(txt, tokenizer, vocab):\n",
    "    encoding = tokenizer.encode(txt)\n",
    "    all_ids = [(fid, vocab['First_Second'][fid]) for fid in encoding.ids]\n",
    "    return all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "74f1da8a-75a1-4304-89c1-f3e7f72e204a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sen', '##jo__', 'no__', 'Valky', '##ria__', '3__', ':__', 'Un', '##rec', '##orded__', 'Chronicles__', '(__', 'Japanese__', ':__', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '3__', ',__', 'lit__', '.__', 'Valky', '##ria__', 'of__', 'the__', 'Battlefield__', '3__', ')__', ',__', 'commonly__', 'referred__', 'to__', 'as__', 'Valky', '##ria__', 'Chronicles__', 'III__', 'outside__', 'Japan__', ',__', 'is__', 'a__', 'tactical__', 'role__', '@__', '-__', '@__', 'playing__', 'video__', 'game__', 'developed__', 'by__', 'Sega__', 'and__', 'Media__', '.__', 'Vision__', 'for__', 'the__', 'PlayStation__', 'Portable__', '.__', 'Released__', 'in__', 'January__', '2__', '0__', '1__', '1__', 'in__', 'Japan__', ',__', 'it__', 'is__', 'the__', 'third__', 'game__', 'in__', 'the__', 'Valky', '##ria__', 'series__', '.__', 'Employ', '##ing__', 'the__', 'same__', 'fusion__', 'of__', 'tactical__', 'and__', 'real__', '@__', '-__', '@__', 'time__', 'gameplay__', 'as__', 'its__', 'predecessors__', ',__', 'the__', 'story__', 'runs__', 'parallel__', 'to__', 'the__', 'first__', 'game__', 'and__', 'follows__', 'the__', '\"__', 'Nam', '##eless__', '\"__', ',__', 'a__', 'penal__', 'military__', 'unit__', 'serving__', 'the__', 'nation__', 'of__', 'Gall', '##ia__', 'during__', 'the__', 'Second__', 'Europ', '##an__', 'War__', 'who__', 'perform__', 'secret__', 'black__', 'operations__', 'and__', 'are__', 'pitted__', 'against__', 'the__', 'Imperial__', 'unit__', '\"__', 'Cal', '##am', '##aty__', 'Raven__', '\"__', '.__', 'The__', 'game__', 'began__', 'development__', 'in__', '2__', '0__', '1__', '0__', ',__', 'carrying__', 'over__', 'a__', 'large__', 'portion__', 'of__', 'the__', 'work__', 'done__', 'on__', 'Valky', '##ria__', 'Chronicles__', 'II__', '.__', 'While__', 'it__', 'retained__', 'the__', 'standard__', 'features__', 'of__', 'the__', 'series__', ',__', 'it__', 'also__', 'underwent__', 'multiple__', 'adjustments__', ',__', 'such__', 'as__', 'making__', 'the__', 'game__', 'more__', 'forg', '##iving__', 'for__', 'series__', 'newcomers__', '.__', 'Character__', 'designer__', 'Ra', '##ita__', 'Hon', '##j', '##ou__', 'and__', 'composer__', 'Hit', '##oshi__', 'Sak', '##imoto__', 'both__', 'returned__', 'from__', 'previous__', 'entries__', ',__', 'along__', 'with__', 'Valky', '##ria__', 'Chronicles__', 'II__', 'director__', 'Tak', '##eshi__', 'Oz', '##awa__', '.__', 'A__', 'large__', 'team__', 'of__', 'writers__', 'handled__', 'the__', 'script__', '.__', 'The__', 'game__', \"'__\", 's__', 'opening__', 'theme__', 'was__', 'sung__', 'by__', 'May__', \"'__\", 'n__', '.__', 'It__', 'met__', 'with__', 'positive__', 'sales__', 'in__', 'Japan__', ',__', 'and__', 'was__', 'praised__', 'by__', 'both__', 'Japanese__', 'and__', 'western__', 'critics__', '.__', 'After__', 'release__', ',__', 'it__', 'received__', 'downloadable__', 'content__', ',__', 'along__', 'with__', 'an__', 'expanded__', 'edition__', 'in__', 'November__', 'of__', 'that__', 'year__', '.__', 'It__', 'was__', 'also__', 'adapted__', 'into__', 'manga__', 'and__', 'an__', 'original__', 'video__', 'animation__', 'series__', '.__', 'Due__', 'to__', 'low__', 'sales__', 'of__', 'Valky', '##ria__', 'Chronicles__', 'II__', ',__', 'Valky', '##ria__', 'Chronicles__', 'III__', 'was__', 'not__', 'localized__', ',__', 'but__', 'a__', 'fan__', 'translation__', 'compatible__', 'with__', 'the__', 'game__', \"'__\", 's__', 'expanded__', 'edition__', 'was__', 'released__', 'in__', '2__', '0__', '1__', '4__', '.__', 'Media__', '.__', 'Vision__', 'would__', 'return__', 'to__', 'the__', 'franchise__', 'with__', 'the__', 'development__', 'of__', 'Valky', '##ria__', ':__', 'Az', '##ure__', 'Revolution__', 'for__', 'the__', 'PlayStation__', '4__', '.__']\n",
      "376\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer.encode(train_data[0])\n",
    "print(encoding.tokens)\n",
    "print(len(encoding.tokens))\n",
    "# print(encoding.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "ca42ef33-8d8c-4048-aa1a-de9c84e2f5ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2786"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([(k,v) for k,v in ALL_VOCAB['First_Second'].items() if len(v.value) > 1 and v.upper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "a6297f72-ebda-4601-81ac-a20aa9f426ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43762"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([(k,v) for k,v in ALL_VOCAB['First_Second'].items() if len(v.value) > 1 and v.title])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "376cf150-5a9e-4cf7-9e50-d26537bd44b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17739"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([(k,v) for k,v in ALL_VOCAB['First_Second'].items() if v.part])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "77a1a4ed-d478-4b44-a982-e0037e69126b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78507"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([(k,v) for k,v in ALL_VOCAB['First_Second'].items() if v.w_end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "18cc3682-d1b9-4501-978f-8f9c4e32ecab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63572"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([(k,v) for k,v in ALL_VOCAB['First_Second'].items() if v.w_end and not v.part])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "5ef5cf10-416b-4bd0-8a7b-4d8ba90757af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ALL_VOCAB['First_Second'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "c74b49eb-decd-442e-bd84-7564376c59c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dog'"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALL_VOCAB['First_Reverse'][20335]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "a948c23e-da5d-4115-8d7d-e4a3123faa62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20335"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALL_VOCAB['First']['Dog']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f6c072-8c0a-41b5-b5e8-24e22d065c45",
   "metadata": {
    "tags": []
   },
   "source": [
    "# GLOBAL CONFIGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c21aca44-59e0-43a3-a485-1c9ef971bd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data and Train Parameters\n",
    "CURRENT_SEQ_LEN = 30\n",
    "BATCH_SIZE = 16\n",
    "AGG_ROUNDS = 10\n",
    "CNT_NEGATIVE = 5\n",
    "MAX_SEQ_LEN = 1024\n",
    "\n",
    "# Architecture parameters\n",
    "\n",
    "    # Counts\n",
    "CNT_MEANINGS = 5\n",
    "CAT_SIZES = [55000, 30000, 15000, 5000]\n",
    "    \n",
    "    # Embedings\n",
    "POS_EMB_SIZE = 5\n",
    "TITLE_EMB_SIZE = 5\n",
    "UPPER_EMB_SIZE = 5\n",
    "PART_EMB_SIZE = 5\n",
    "END_EMB_SIZE = 5\n",
    "MEANING_EMB_SIZE = 20\n",
    "CAT_EMB_SIZE = 10\n",
    "\n",
    "\n",
    "\n",
    "    # Main Sizes\n",
    "PREDICT_SIZE = (TITLE_EMB_SIZE + UPPER_EMB_SIZE + PART_EMB_SIZE + END_EMB_SIZE) + CAT_EMB_SIZE + MEANING_EMB_SIZE\n",
    "HIDDEN_SIZE = int(1.5 * PREDICT_SIZE)\n",
    "INPUT_SIZE = POS_EMB_SIZE + TITLE_EMB_SIZE + UPPER_EMB_SIZE + PART_EMB_SIZE + END_EMB_SIZE + CAT_EMB_SIZE + MEANING_EMB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e36143e0-a5bc-4423-b9dc-dfda11b34bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HIDDEN_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec31f8fd-9d8a-437b-a3fe-d1df2b28e665",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Make Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd1ebc6-97f5-4b4f-824b-4095b1689728",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_file=str(DATA_PATH / \"Tokenizer_BPE100k.json\"),\n",
    "    unk_token=\"[UNK]\",\n",
    "    pad_token=\"[PAD]\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c558ff4-1667-4b8b-86f7-e2afe8004ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_unks(toks, unk=0):\n",
    "    return [tk for i, tk in enumerate(toks) if (tk != unk) or (i == 0) or (toks[i-1] != unk)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad8e359-24a0-491e-a739-0884717dc856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_tokenizer(txt):\n",
    "    tokens = wrapped_tokenizer(txt)['input_ids']\n",
    "    tokens = merge_unks(tokens, wrapped_tokenizer.unk_token_id)\n",
    "    return np.array(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dd83eb-7670-43a3-b9e6-12fc55626c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_sub_seq(tokens, max_len, pad=1):\n",
    "    ln = len(tokens)\n",
    "    if ln < max_len:\n",
    "        return np.array([np.concatenate([tokens, [pad]*(max_len - ln)])])\n",
    "    sub_seqs = []\n",
    "    for i in range(ln - max_len + 1):\n",
    "        sub_seqs.append(tokens[i:i+max_len])\n",
    "    return np.array(sub_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0a8d73-4d2a-4249-9cb9-f6e9b67955f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_30T = [\n",
    "    get_all_sub_seq(final_tokenizer(txt), max_len=MAX_SEQ_LEN, pad=wrapped_tokenizer.pad_token_id) \n",
    "    for txt in train_data\n",
    "]\n",
    "train_30T = np.concatenate(train_30T, axis=0)\n",
    "train_30T = np.array(train_30T, np.uintc)\n",
    "train_30T.shape #(103596449, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b85ec1d-52be-46bf-a3ba-12f1e85afe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_PATH / 'train_30T.npy', 'wb') as f:\n",
    "    np.save(f, train_30T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3c89e07-378c-4528-b00a-fe050a96a90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585 MB\n",
      "24863 MB\n"
     ]
    }
   ],
   "source": [
    "process_memory()\n",
    "objects_memory(train_30T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d848ddee-f96d-4c5a-8438-d323244a9538",
   "metadata": {},
   "source": [
    "# Load to Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cafa0cba-7ae4-4033-9584-20f587e2131e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "476 MB\n"
     ]
    }
   ],
   "source": [
    "process_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b0c5a7c-95c4-4b99-98cd-50bf9f97a65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_PATH / 'train_30T.npy', 'rb') as f:\n",
    "    train_tokens = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddb6b536-ba94-4362-9443-a725d92f1720",
   "metadata": {},
   "outputs": [],
   "source": [
    "Token = namedtuple('Token', ['tid', 'value', 'title', 'upper','part', 'w_end'])\n",
    "ALL_VOCAB = load_pkl(DATA_PATH / \"ALLVOCAB_BPE100k.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "010d47ee-1c11-4357-99fd-48e278823222",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_file=str(DATA_PATH / \"Tokenizer_BPE100k.json\"),\n",
    "    unk_token=\"[UNK]\",\n",
    "    pad_token=\"[PAD]\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "306756c6-9b68-4566-b448-9ad7de2c831c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1382 MB\n"
     ]
    }
   ],
   "source": [
    "process_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4916bf80-2844-4b0b-b636-4db76389bcf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12432 MB\n"
     ]
    }
   ],
   "source": [
    "objects_memory(train_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c651215-3853-44b5-a3cc-f42a597d8c2d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Arhitecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3bdb2bc-9eac-4b8d-ba90-9c8b4b39b98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) PosEncodind\n",
    "# 2) PropsEmb\n",
    "# 3) TokensEmb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d12648-a65a-455f-b50b-4e147937623f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Position Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4817c42b-4fc7-4a6a-999d-e3ba1b40786f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PosEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, rows, emb_size, seed=0):\n",
    "        super(PosEncoding, self).__init__()\n",
    "        self.rows = rows\n",
    "        self.emb_size = emb_size\n",
    "        self.embedding = nn.Embedding(rows, self.emb_size)\n",
    "        self.init_weights(seed)\n",
    "\n",
    "    def init_weights(self, seed):\n",
    "        torch.manual_seed(seed)\n",
    "        nn.init.xavier_uniform_(self.embedding.weight, gain=1.0)\n",
    "        self.embedding.weight.data = torch.tensor(\n",
    "            np.array(self.embedding.weight.data), \n",
    "            dtype=torch.float32\n",
    "        ).requires_grad_(True)\n",
    "    \n",
    "    def forward(self, batch, ptime=False): \n",
    "        # batch = seq_len x seq_len\n",
    "        t0 = time.time()\n",
    "        batch = self.embedding(batch)\n",
    "        if ptime:\n",
    "            print(f'PosEncoding, forward2 time: {time.time()-t0}')\n",
    "        # batch = seq_len x seq_len x pos_emb\n",
    "        return batch\n",
    "    \n",
    "    \n",
    "    def init_optims(self, opt_type, lr):\n",
    "        self.current_weight_lr = lr\n",
    "        self.opt= getattr(optim, opt_type)([self.embedding.weight], lr=lr)\n",
    "\n",
    "    def set_lr(self, lr_weight, lr_bias):\n",
    "        pass\n",
    "\n",
    "    def step(self):\n",
    "        self.opt.step()\n",
    "        \n",
    "    def zero_grad(self):\n",
    "        self.opt.zero_grad()\n",
    "\n",
    "    def clip_grad(self, maxg=1e-2):\n",
    "        pass\n",
    "\n",
    "    def count_params(self):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dd08b0-21a5-4d5f-9e13-156a30be0ca8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Properties Embeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a71ce752-1026-4cbd-b50b-a85727a6ad74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PropsEmbeding(nn.Module):\n",
    "\n",
    "    def __init__(self, title, upper, part, w_end, seed=0):\n",
    "        super(PropsEmbeding, self).__init__()\n",
    "        self.title = title\n",
    "        self.upper = upper\n",
    "        self.part = part\n",
    "        self.w_end = w_end\n",
    "        \n",
    "        self.title_emb = nn.Embedding(2, self.title)\n",
    "        self.upp_emb = nn.Embedding(2, self.upper)\n",
    "        self.prt_emb = nn.Embedding(2, self.part)\n",
    "        self.end_emb = nn.Embedding(2, self.w_end)\n",
    "        \n",
    "        # FIX ORDER !!!!!!!\n",
    "        self.seq_embs = [self.title_emb, self.upp_emb, self.prt_emb ,self.end_emb]\n",
    "        self.init_weights(seed)\n",
    "\n",
    "    def init_weights(self, seed):\n",
    "        torch.manual_seed(seed)\n",
    "        \n",
    "        for atr in dir(self):\n",
    "            if atr[-4:] != '_emb':\n",
    "                continue\n",
    "            lay = getattr(self, atr)\n",
    "            nn.init.xavier_uniform_(lay.weight, gain=1.0)\n",
    "            lay.weight.data = torch.tensor(np.array(lay.weight.data), dtype=torch.float32).requires_grad_(True)\n",
    "    \n",
    "    def forward(self, batch, ptime=False): \n",
    "        # batch = batch x seq_len x props (=4)\n",
    "        t0 = time.time()\n",
    "        embs_vals = []\n",
    "        seq_len = batch.shape[1]\n",
    "        \n",
    "        embs_vals = torch.cat([\n",
    "            emb_lay(batch[:,:,i])\n",
    "            for i, emb_lay in enumerate(self.seq_embs)\n",
    "        ], dim=-1)\n",
    "        \n",
    "        embs_vals = [\n",
    "            emb_lay(batch[:,:,i])\n",
    "            for i, emb_lay in enumerate(self.seq_embs)\n",
    "        ]\n",
    "        \n",
    "        embs_vals = torch.cat(embs_vals, dim=-1)\n",
    "        # embs_vals = batch x seq_len x props_emb\n",
    "        if ptime:\n",
    "            print(f'PropsEmbeding, forward4 time: {time.time()-t0}')\n",
    "        \n",
    "        return embs_vals\n",
    "    \n",
    "\n",
    "    def init_optims(self, opt_type, lr):\n",
    "        self.current_weight_lr = lr\n",
    "        self.opt = getattr(optim, opt_type)([x.weight for x in self.seq_embs], lr=lr)\n",
    "\n",
    "    def set_lr(self, lr_weight, lr_bias):\n",
    "        pass\n",
    "\n",
    "    def step(self):\n",
    "        self.opt.step()\n",
    "        \n",
    "    def zero_grad(self):\n",
    "        self.opt.zero_grad()\n",
    "\n",
    "    def clip_grad(self, maxg=1e-2):\n",
    "        pass\n",
    "\n",
    "    def count_params(self):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9401b0b-69c7-496a-8e7f-b7a34504789e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Tokens Embeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ece1c731-8fa1-431b-b3a5-f2c8c2b3f46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokensEmbeding(nn.Module):\n",
    "\n",
    "    def __init__(self, cnt_tokens, categories_sz, cnt_meanings, meaning_emb_sz, cat_emb_sz, seed=0):\n",
    "        super(TokensEmbeding, self).__init__()\n",
    "        self.cnt_tokens = cnt_tokens\n",
    "        self.categories_sz = categories_sz\n",
    "        self.cnt_categories = len(self.categories_sz)\n",
    "        self.cnt_meanings = cnt_meanings\n",
    "        self.meaning_emb_sz = meaning_emb_sz\n",
    "        self.cat_emb_sz = cat_emb_sz\n",
    "        \n",
    "        # Categories Embeding\n",
    "        self.cat_emb = nn.Embedding(self.cnt_categories, self.cat_emb_sz)\n",
    "        \n",
    "        # Tokens Embeding for each Category\n",
    "        self.all_tokens_embeds = []\n",
    "        for i, cat_sz in enumerate(self.categories_sz):\n",
    "            setattr(self, f'token{i}_emb', nn.Embedding(cat_sz, self.cnt_meanings * self.meaning_emb_sz))\n",
    "            self.all_tokens_embeds.append(getattr(self, f'token{i}_emb'))\n",
    "\n",
    "        self.init_weights(seed)\n",
    "        self.init_merges(seed)\n",
    "    \n",
    "    def init_merges(self, seed):\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        all_tokens_ids = np.arange(self.cnt_tokens)\n",
    "        for i, cat_sz in enumerate(self.categories_sz):\n",
    "            cat_dict = dict()\n",
    "            while len(cat_dict) != self.cnt_tokens:\n",
    "                cats_ids = np.arange(cat_sz)\n",
    "                all_tokens_ids = [i for i in range(self.cnt_tokens) if i not in cat_dict]\n",
    "                np.random.shuffle(cats_ids)\n",
    "                np.random.shuffle(all_tokens_ids)\n",
    "                indx = slice(0, min(len(all_tokens_ids), cat_sz))\n",
    "                cat_dict.update(zip(all_tokens_ids[indx], cats_ids[indx], ))\n",
    "\n",
    "            setattr(self, f'cat{i}_merge', cat_dict)\n",
    "        \n",
    "    def init_weights(self, seed):\n",
    "        torch.manual_seed(seed)\n",
    "        \n",
    "        for lay in self.all_tokens_embeds:\n",
    "            rows = lay.weight.shape[0]\n",
    "            tmp_lay = lay.weight.data.reshape(rows * self.cnt_meanings, self.meaning_emb_sz).type(torch.float32)\n",
    "            nn.init.xavier_uniform_(tmp_lay, gain=1.0)\n",
    "            tmp_lay = tmp_lay.reshape(rows, self.cnt_meanings * self.meaning_emb_sz)\n",
    "            lay.weight.data = tmp_lay.clone().detach().requires_grad_(True)\n",
    "        \n",
    "        \n",
    "        nn.init.xavier_uniform_(self.cat_emb.weight, gain=1.0)\n",
    "        self.cat_emb.weight.data = torch.tensor(\n",
    "            np.array(self.cat_emb.weight.data), \n",
    "            dtype=torch.float32\n",
    "        ).requires_grad_(True)\n",
    "\n",
    "\n",
    "    def forward(self, batch, negative_batch=None, ptime=False):\n",
    "        # batch = batch x seq_len\n",
    "        # negative_batch = batch x seq_len x cnt_neg\n",
    "        \n",
    "        t0 = time.time()\n",
    "        rows, columns = batch.shape\n",
    "        all_tk_cat = []\n",
    "        \n",
    "        # cnt_cats - > cnt_cats x cat_emb\n",
    "        cat_emb = self.cat_emb(torch.tensor([i for i in range(self.cnt_categories)], dtype=torch.int)) \n",
    "        # cnt_cats x cat_emb\n",
    "        \n",
    "        \n",
    "        cat_emb_ext = einops.repeat(cat_emb, 'c e -> b s c m e', b=rows, s=columns, m=self.cnt_meanings) \n",
    "        # cat_emb_ext = batch x seq_len x cnt_cats x cnt_meanings x cat_emb\n",
    "        \n",
    "        tokens_embeds = [\n",
    "            emb_lay(batch.clone().apply_(getattr(self, f'cat{i}_merge').get))\n",
    "            for i, emb_lay in enumerate(self.all_tokens_embeds)\n",
    "        ]\n",
    "        # tokens_embeds (list) = cnt_cats x batch x seq_len x cnt_meanings x meaning_emb\n",
    "        \n",
    "        tokens_embeds = einops.rearrange(tokens_embeds, 'c b s (m e) -> b s c m e', m=self.cnt_meanings, e=self.meaning_emb_sz)\n",
    "        # tokens_embeds = batch x seq_len x cnt_cats x cnt_meanings x meaning_emb\n",
    "        \n",
    "        cat_tokens_embeds = torch.cat([cat_emb_ext, tokens_embeds], axis=-1)\n",
    "        # cat_tokens_embeds = batch x seq_len x cnt_cats x cnt_meanings x (cat_emb + meaning_emb)\n",
    "        \n",
    "        # tokens_embeds = einops.rearrange(tokens_embeds, 'b s c m e -> b s n c m e', n=1)\n",
    "        tokens_embeds = tokens_embeds.unsqueeze(2)\n",
    "        # tokens_embeds = batch x seq_len x 1 x cnt_cats x cnt_meanings x meaning_emb\n",
    "        \n",
    "        if negative_batch is not None:\n",
    "            cnt_negative = negative_batch.shape[-1]\n",
    "            \n",
    "            negative_batch = einops.rearrange([\n",
    "                emb_lay(negative_batch.clone().apply_(getattr(self, f'cat{i}_merge').get))\n",
    "                for i, emb_lay in enumerate(self.all_tokens_embeds)], \n",
    "                'c b s n (m e) -> b s n c m e', \n",
    "                m=self.cnt_meanings, e=self.meaning_emb_sz\n",
    "            )\n",
    "            # negative_batch = batch x seq_len x cnt_negative x cnt_cats x cnt_meanings x meaning_emb\n",
    "            \n",
    "            # cat_emb_ext2 = einops.repeat(cat_emb, 'c e -> b s (n c m) e', b=rows, s=columns, n=cnt_negative, \n",
    "            #                              m=self.cnt_meanings) \n",
    "            # cat_emb_ext2 = batch x seq_len x (cnt_negative * cnt_cats * cnt_meanings) x cat_emb\n",
    "            \n",
    "            # negative_batch = torch.cat([cat_emb_ext2, negative_batch], axis=-1)\n",
    "            # negative_batch = batch x seq_len x (cnt_negative * cnt_cats * cnt_meanings) x (cat_emb + meaning_emb)\n",
    "        \n",
    "        if ptime:\n",
    "            print(f'TokensEmbeding, forward5 time: {time.time()-t0}')\n",
    "            \n",
    "        # cat_tokens_embeds = batch x seq_len x cnt_cats x cnt_meanings x (cat_emb + meaning_emb)   \n",
    "        # negative_batch = batch x seq_len x cnt_negative x cnt_cats x cnt_meanings x meaning_emb\n",
    "        # tokens_embeds = batch x seq_len x 1 x cnt_cats x cnt_meanings x meaning_emb\n",
    "        \n",
    "        return cat_tokens_embeds, tokens_embeds, negative_batch\n",
    "    \n",
    "    \n",
    "    def init_optims(self, opt_type, lr):\n",
    "        self.current_weight_lr = lr\n",
    "        self.opt = getattr(optim, opt_type)(\n",
    "            [self.cat_emb.weight, ] + [x.weight for x in self.all_tokens_embeds], lr=lr\n",
    "        )\n",
    "\n",
    "    def set_lr(self, lr_weight, lr_bias):\n",
    "        pass\n",
    "\n",
    "    def step(self):\n",
    "        self.opt.step()\n",
    "        \n",
    "    def zero_grad(self):\n",
    "        self.opt.zero_grad()\n",
    "\n",
    "    def clip_grad(self, maxg=1e-2):\n",
    "        pass\n",
    "\n",
    "    def count_params(self):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0708d29-00d4-4ea0-8301-9afaf198c337",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Attention Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "62b11eb6-84d3-4421-b29d-ee346b203868",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionNet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_sz, seed=0):\n",
    "        super(AttentionNet, self).__init__()\n",
    "        self.seed=seed\n",
    "        self.lay0 = nn.Linear(in_features=input_sz, out_features=1)\n",
    "        # self.activation = nn.LeakyReLU()\n",
    "        self.init_weights(seed)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "    \n",
    "    def init_weights(self, seed):\n",
    "        torch.manual_seed(seed)\n",
    "        nn.init.xavier_uniform_(self.lay0.weight, gain=1.0)\n",
    "        self.lay0.weight.data = torch.tensor(np.array(self.lay0.weight.data), dtype=torch.float32).requires_grad_(True)\n",
    "        self.lay0.bias.data = torch.tensor(np.array(self.lay0.bias.data), dtype=torch.float32).requires_grad_(True)\n",
    "        \n",
    "        \n",
    "    def forward_tokens(self, batch, mask):\n",
    "        # batch =  batch x seq_len x seq_len * (cnt_cats * cnt_meanings) x embeds\n",
    "        seq_len = batch.shape[1]\n",
    "        cm = batch.shape[3]\n",
    "        \n",
    "        att = einops.rearrange(self.lay0(batch), 'b s1 s2 cm e -> b s1 (s2 cm e)')\n",
    "        # att =  batch x seq_len x (seq_len * cnt_cats * cnt_meanings)\n",
    "        \n",
    "        if mask is not None:\n",
    "            att = att + mask \n",
    "        att = einops.rearrange(self.softmax(att), 'b s1 (s2 cm e) -> b s1 s2 cm e', s2=seq_len, cm=cm, e=1)\n",
    "        # att = self.softmax(att).unsqueeze(dim=-1)\n",
    "        # att = batch x seq_len x seq_len x (cnt_cats * cnt_meanings) x 1\n",
    "        return att\n",
    "    \n",
    "    \n",
    "    def forward_hidden(self, batch, mask):\n",
    "        # batch = batch x seq_len x seq_len x 2 * hidden + pos_emb\n",
    "        seq_len = batch.shape[1]\n",
    "        \n",
    "        att = einops.rearrange(self.lay0(batch), 'b s1 s2 e -> b s1 (s2 e)')\n",
    "        if mask is not None:\n",
    "            att = att + mask\n",
    "        \n",
    "        att = einops.rearrange(self.softmax(att), 'b s1 (s2 e) -> b s1 s2 e', s2=seq_len, e=1)\n",
    "        # att = batch x seq_len x seq_len x 1\n",
    "        return att\n",
    "\n",
    "    def init_optims(self, opt_type, lr):\n",
    "        self.current_weight_lr = lr\n",
    "        self.opt = getattr(optim, opt_type)([self.lay0.weight, self.lay0.bias], lr=lr)\n",
    "\n",
    "    def set_lr(self, lr_weight, lr_bias):\n",
    "        pass\n",
    "\n",
    "    def step(self):\n",
    "        self.opt.step()\n",
    "        \n",
    "    def zero_grad(self):\n",
    "        self.opt.zero_grad()\n",
    "\n",
    "    def clip_grad(self, maxg=1e-2):\n",
    "        pass\n",
    "\n",
    "    def count_params(self):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced34edd-cb2a-49ed-b7e2-0cfd88fda66a",
   "metadata": {},
   "source": [
    "## Process Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "114a53a3-ccb1-4ecc-9659-524ee76a886d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProceccNet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size, seed=0):\n",
    "        super(ProceccNet, self).__init__()\n",
    "        self.seed=seed\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.lay0 = nn.Linear(in_features=input_size, out_features=output_size)\n",
    "        self.activation = torch.tanh\n",
    "        self.init_weights(seed)\n",
    "        \n",
    "    \n",
    "    def init_weights(self, seed):\n",
    "        torch.manual_seed(seed)\n",
    "        nn.init.xavier_uniform_(self.lay0.weight, gain=1.0)\n",
    "        self.lay0.weight.data = torch.tensor(np.array(self.lay0.weight.data), dtype=torch.float32).requires_grad_(True)\n",
    "        self.lay0.bias.data = torch.tensor(np.array(self.lay0.bias.data), dtype=torch.float32).requires_grad_(True)\n",
    "        \n",
    "        \n",
    "    def forward(self, batch):\n",
    "        # batch = batch x seq_len x embs + 2 * hidden\n",
    "        batch = self.activation(self.lay0(batch))\n",
    "        # batch = batch x seq_len x hidden\n",
    "        return batch\n",
    "\n",
    "    def init_optims(self, opt_type, lr):\n",
    "        self.current_weight_lr = lr\n",
    "        self.opt = getattr(optim, opt_type)([self.lay0.weight, self.lay0.bias], lr=lr)\n",
    "\n",
    "    def set_lr(self, lr_weight, lr_bias):\n",
    "        pass\n",
    "\n",
    "    def step(self):\n",
    "        self.opt.step()\n",
    "        \n",
    "    def zero_grad(self):\n",
    "        self.opt.zero_grad()\n",
    "\n",
    "    def clip_grad(self, maxg=1e-2):\n",
    "        pass\n",
    "\n",
    "    def count_params(self):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5284f7-7575-4a8f-911a-8de8653dedd3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Aggregation Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2ecd174b-c4e8-441a-b07e-0df097e2fd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AggregationNet(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size, full_embeding_size, short_embeding_size, pos_embebing_size, seed=0):\n",
    "        super(AggregationNet, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.full_embeding_size = full_embeding_size\n",
    "        self.short_embeding_size = short_embeding_size\n",
    "        self.pos_embebing_size = pos_embebing_size\n",
    "        self.seed=seed\n",
    "        self.att_tokens = AttentionNet(self.hidden_size + self.full_embeding_size, seed=seed)\n",
    "        self.att_hidden = AttentionNet(2 * self.hidden_size + self.pos_embebing_size, seed=seed)\n",
    "        self.process_net = ProceccNet(2 * self.hidden_size + self.short_embeding_size, self.hidden_size, seed=seed)\n",
    "        \n",
    "    def forward(self, pos_props_tokens, pos, mask, rounds=10, ptime=False):\n",
    "        # pos_props_tokens = batch x seq_len (s_w) x seq_len (s_h) x (cnt_cats * cnt_meanings) x (pos_emb + cat_emb + emb_meaning)\n",
    "        # pos = batch x seq_len x seq_len x pos_emb\n",
    "        \n",
    "        t0 = time.time()\n",
    "        batch_sz = pos_props_tokens.shape[0]\n",
    "        seq_len = pos_props_tokens.shape[1]\n",
    "        cm = pos_props_tokens.shape[3]\n",
    "        start_emb = self.full_embeding_size - self.short_embeding_size\n",
    "        \n",
    "        \n",
    "        # batch x seq_len x hidden\n",
    "        h = torch.zeros((batch_sz, seq_len, self.hidden_size), dtype=torch.float32).requires_grad_(False)\n",
    "        \n",
    "        all_hidens = []\n",
    "        for i in range(rounds):\n",
    "            h_ext = einops.repeat(h, 'b s_h e -> b s_h s_w cm e', s_w=seq_len, cm=cm)\n",
    "            # h_ext = batch x seq_len (s_h) x seq_len (s_w) x (cnt_cats * cnt_meanings) x hidden\n",
    "            \n",
    "            att_tk = self.att_tokens.forward_tokens(torch.cat([h_ext, pos_props_tokens], axis=-1), mask)\n",
    "            # att_tk = batch x seq_len x seq_len x (cnt_cats * cnt_meanings) x 1\n",
    "            \n",
    "            agg_tk = einops.reduce(pos_props_tokens[:,:,:,:,self.pos_embebing_size:] * att_tk, 'b s1 s2 cm e -> b s1 e', 'sum')\n",
    "            # att_tk = batch x seq_len x embs\n",
    "            \n",
    "            h_ext2 = einops.repeat(h, 'b s_h e -> b s_w s_h e', s_w=seq_len)\n",
    "            # h_ext2 = batch x seq_len (s_w) x seq_len (s_h) x hidden\n",
    "            \n",
    "            h_ext3 = einops.repeat(h, 'b s_h e -> b s_h s_w e', s_w=seq_len)\n",
    "            # h_ext3 = batch x seq_len (s_h) x seq_len (s_w) x hidden\n",
    "            \n",
    "            att_h = self.att_hidden.forward_hidden(torch.cat([h_ext3, h_ext2, pos], axis=-1), mask)\n",
    "            # att_h = batch x seq_len x seq_len x 1\n",
    "            \n",
    "            agg_h = einops.reduce(h_ext2 * att_h, 'b s1 s2 e -> b s1 e', 'sum')\n",
    "            # agg_h = batch x seq_len x hidden\n",
    "            \n",
    "            agg_output = torch.cat([h, agg_h, agg_tk], axis=-1)\n",
    "            # agg_output = batch x seq_len x embs\n",
    "            \n",
    "            # torch.Size([16, 30, 75]) torch.Size([16, 30, 75]) torch.Size([16, 30, 55])\n",
    "            h = self.process_net.forward(agg_output)\n",
    "            # h = batch x seq_len x hidden\n",
    "            all_hidens.append(h)\n",
    "        \n",
    "        if ptime:\n",
    "            print(f'AggregationNet, forward time: {time.time()-t0}')\n",
    "        return all_hidens\n",
    "\n",
    "    \n",
    "    def init_optims(self, opt_type, lr):\n",
    "        self.att_tokens.init_optims(opt_type, lr)\n",
    "        self.att_hidden.init_optims(opt_type, lr)\n",
    "        self.process_net.init_optims(opt_type, lr)\n",
    "\n",
    "    def set_lr(self, lr_weight, lr_bias):\n",
    "        pass\n",
    "\n",
    "    def step(self):\n",
    "        self.att_tokens.step()\n",
    "        self.att_hidden.step()\n",
    "        self.process_net.step()\n",
    "\n",
    "    def zero_grad(self):\n",
    "        self.att_tokens.zero_grad()\n",
    "        self.att_hidden.zero_grad()\n",
    "        self.process_net.zero_grad()\n",
    "\n",
    "    def clip_grad(self, maxg=1e-2):\n",
    "        pass\n",
    "\n",
    "    def count_params(self):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d59c2e-426b-4509-a238-28ab45f0ce4f",
   "metadata": {},
   "source": [
    "## Property Prediction Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "609d7c04-9ba8-4b7b-b41f-c85bafef4e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PropertyNet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, seed=0):\n",
    "        super(PropertyNet, self).__init__()\n",
    "        self.seed=seed\n",
    "        self.input_size = input_size\n",
    "        self.lay0 = nn.Linear(in_features=input_size, out_features=4)\n",
    "        self.activation = torch.sigmoid\n",
    "        self.init_weights(seed)\n",
    "        \n",
    "    \n",
    "    def init_weights(self, seed):\n",
    "        torch.manual_seed(seed)\n",
    "        nn.init.xavier_uniform_(self.lay0.weight, gain=1.0)\n",
    "        self.lay0.weight.data = torch.tensor(np.array(self.lay0.weight.data), dtype=torch.float32).requires_grad_(True)\n",
    "        self.lay0.bias.data = torch.tensor(np.array(self.lay0.bias.data), dtype=torch.float32).requires_grad_(True)\n",
    "        \n",
    "        \n",
    "    def forward(self, batch):\n",
    "        # batch = batch x seq_len x rounds_agg x hidden\n",
    "        batch = self.lay0(batch)\n",
    "        batch = torch.sigmoid(batch)\n",
    "        \n",
    "        # batch = batch x seq_len x rounds_agg x props (=4)\n",
    "        return batch\n",
    "\n",
    "    def init_optims(self, opt_type, lr):\n",
    "        self.current_weight_lr = lr\n",
    "        self.opt = getattr(optim, opt_type)([self.lay0.weight, self.lay0.bias], lr=lr)\n",
    "\n",
    "    def set_lr(self, lr_weight, lr_bias):\n",
    "        pass\n",
    "\n",
    "    def step(self):\n",
    "        self.opt.step()\n",
    "        \n",
    "    def zero_grad(self):\n",
    "        self.opt.zero_grad()\n",
    "\n",
    "    def clip_grad(self, maxg=1e-2):\n",
    "        pass\n",
    "\n",
    "    def count_params(self):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568b870f-7fd0-48a1-b6a8-a8af3bac3478",
   "metadata": {},
   "source": [
    "## Category Prediction Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "07630e10-d543-45db-8393-e2a24c1fb479",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoryNet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, cnt_categories, seed=0):\n",
    "        super(CategoryNet, self).__init__()\n",
    "        self.seed=seed\n",
    "        self.input_size = input_size\n",
    "        self.cnt_categories = cnt_categories\n",
    "        self.lay0 = nn.Linear(in_features=input_size, out_features=self.cnt_categories)\n",
    "        # self.softmax = nn.Softmax(dim=-1)\n",
    "        self.activation = torch.sigmoid\n",
    "        self.init_weights(seed)\n",
    "        \n",
    "    def init_weights(self, seed):\n",
    "        torch.manual_seed(seed)\n",
    "        nn.init.xavier_uniform_(self.lay0.weight, gain=1.0)\n",
    "        self.lay0.weight.data = torch.tensor(np.array(self.lay0.weight.data), dtype=torch.float32).requires_grad_(True)\n",
    "        self.lay0.bias.data = torch.tensor(np.array(self.lay0.bias.data), dtype=torch.float32).requires_grad_(True)\n",
    "        \n",
    "        \n",
    "    def forward(self, batch):\n",
    "        # batch = batch x seq_len x rounds_agg x hidden\n",
    "        batch = self.activation(self.lay0(batch))\n",
    "        # batch = batch x seq_len x rounds_agg x cnt_categories\n",
    "            \n",
    "        # batch = self.softmax(batch)\n",
    "        # batch = batch x seq_len x rounds_agg x cnt_categories\n",
    "        return batch\n",
    "    \n",
    "    def init_optims(self, opt_type, lr):\n",
    "        self.current_weight_lr = lr\n",
    "        self.opt = getattr(optim, opt_type)([self.lay0.weight, self.lay0.bias], lr=lr)\n",
    "\n",
    "    def set_lr(self, lr_weight, lr_bias):\n",
    "        pass\n",
    "\n",
    "    def step(self):\n",
    "        self.opt.step()\n",
    "        \n",
    "    def zero_grad(self):\n",
    "        self.opt.zero_grad()\n",
    "\n",
    "    def clip_grad(self, maxg=1e-2):\n",
    "        pass\n",
    "\n",
    "    def count_params(self):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61284703-78b3-4a1c-bce9-7da5ea844efb",
   "metadata": {},
   "source": [
    "## Meaning Prediction Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d65bfd10-b62b-4a4d-9b3e-e227a32e9754",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeaningNet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, seed=0):\n",
    "        super(MeaningNet, self).__init__()\n",
    "        self.seed=seed\n",
    "        self.input_size = input_size\n",
    "        self.lay0 = nn.Linear(in_features=input_size, out_features=1)\n",
    "        self.activation = torch.sigmoid\n",
    "        self.init_weights(seed)\n",
    "        \n",
    "    \n",
    "    def init_weights(self, seed):\n",
    "        torch.manual_seed(seed)\n",
    "        nn.init.xavier_uniform_(self.lay0.weight, gain=1.0)\n",
    "        self.lay0.weight.data = torch.tensor(np.array(self.lay0.weight.data), dtype=torch.float32).requires_grad_(True)\n",
    "        self.lay0.bias.data = torch.tensor(np.array(self.lay0.bias.data), dtype=torch.float32).requires_grad_(True)\n",
    "        \n",
    "        \n",
    "    def forward(self, batch):\n",
    "        # batch = batch x seq_len x rounds_agg x (1 + cnt_negative) x cnt_cats x cnt_meanings x hidden + meaning_emb\n",
    "        batch = self.lay0(batch)\n",
    "        batch = torch.sigmoid(batch).squeeze()\n",
    "        # batch = batch x seq_len x rounds_agg x (1 + cnt_negative) x cnt_meanings\n",
    "        return batch\n",
    "\n",
    "    def init_optims(self, opt_type, lr):\n",
    "        self.current_weight_lr = lr\n",
    "        self.opt = getattr(optim, opt_type)([self.lay0.weight, self.lay0.bias], lr=lr)\n",
    "\n",
    "    def set_lr(self, lr_weight, lr_bias):\n",
    "        pass\n",
    "\n",
    "    def step(self):\n",
    "        self.opt.step()\n",
    "        \n",
    "\n",
    "    def zero_grad(self):\n",
    "        self.opt.zero_grad()\n",
    "\n",
    "    def clip_grad(self, maxg=1e-2):\n",
    "        pass\n",
    "\n",
    "    def count_params(self):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39d75ee-9050-4864-b018-c4bca069276e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "03dc580d-0cb4-435a-9f50-13e0be72a1ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['First', 'First_Reverse', 'First_Second', 'First_Second_Reverse', 'Second', 'Second_Reverse'])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALL_VOCAB.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ab6b477a-51a3-45c7-89fc-875019dc7f80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Token(tid=0, value='[unk]', title=False, upper=False, part=False, w_end=True)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALL_VOCAB['First_Second'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d55a0212-d1ed-4f4c-91b6-425373cc296b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @lru_cache(maxsize=1000)\n",
    "def change_tokens(tkid):\n",
    "    new_tk = ALL_VOCAB['First_Second'][tkid]\n",
    "    # return new_tk.tid\n",
    "    return (new_tk.tid, int(new_tk.title), int(new_tk.upper), int(new_tk.part), int(new_tk.w_end))\n",
    "\n",
    "v_change_tokens = np.vectorize(change_tokens)\n",
    "\n",
    "def process_batch(batch):\n",
    "    return np.stack(v_change_tokens(batch), axis=2)\n",
    "\n",
    "\n",
    "def reorder_posistions(matrix, wpos):\n",
    "    sz, _ = matrix.shape\n",
    "    indx = [wpos,] + [i for i in range(sz) if i != wpos]\n",
    "    return matrix[indx,:][:,indx]\n",
    "\n",
    "def reorder_tokens(marix, w0):\n",
    "    matrix = np.array([\n",
    "        marix[i,[w0[i],] + [j for j in range(marix.shape[1]) if j != w0[i]]] \n",
    "        for i in range(marix.shape[0])\n",
    "    ])\n",
    "    return matrix\n",
    "\n",
    "def negative_tokens(tkid, cnt):\n",
    "    neg_set = set()\n",
    "    while len(neg_set) != cnt:\n",
    "        tmp_set = set(np.random.randint(0, high=len(ALL_VOCAB['Second']), size=cnt - len(neg_set), dtype=int))\n",
    "        neg_set = neg_set | tmp_set\n",
    "    return tuple(neg_set)\n",
    "\n",
    "v_negative_tokens = np.vectorize(negative_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b21a9fb6-5a32-4eea-a5a4-10d30bc187b7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_old(nets, data, \n",
    "          batch_size, max_seq_len, cnt_negative, rounds_agg, \n",
    "          mask_coef, hidden_coef, pos_sum_coef, pad,\n",
    "          avg_info=100, opt_type='SGD', lr=1e-3, seed=0, cnt_epochs=10**6, ptime=False\n",
    "         ):\n",
    "    _ = [x.init_optims(opt_type, lr) for x in nets]\n",
    "    PosEnc, PropsEmb, TokensEmb, AggNet, PropNet, CMNet = nets\n",
    "    l2_none_loss = torch.nn.MSELoss(reduction='none')\n",
    "    \n",
    "    rows, _ = data.shape\n",
    "    indices = np.arange(rows)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Определяем дефолтную матрицу позиций\n",
    "    default_positions = np.array([\n",
    "        [max_seq_len + j - i - 1 for j in range(max_seq_len) ] \n",
    "        for i in range(max_seq_len)\n",
    "    ])\n",
    "    \n",
    "    hist_props_l2 = []\n",
    "    hist_props_l2_mask = []\n",
    "    \n",
    "    hist_neg_l2 = []\n",
    "    hist_neg_l2_mask = []\n",
    "    \n",
    "    hist_pos_max_l2 = []\n",
    "    hist_pos_max_l2_mask = []\n",
    "    \n",
    "    hist_pos_sum_l2 = []\n",
    "    hist_pos_sum_l2_mask = []\n",
    "\n",
    "    # Цикл по эпохам\n",
    "    for epoch_i in range(cnt_epochs):\n",
    "        np.random.shuffle(indices) # Шафлим индексы, так как шафлить массив намного дольше\n",
    "        \n",
    "        for i in range(int(rows / batch_size) + 1): # Цикл по батчам\n",
    "            batch_ids = indices[i*batch_size:(i+1)*batch_size]\n",
    "            if len(batch_ids) == 0:\n",
    "                continue # Прошлись по всей выборке\n",
    "            \n",
    "            _ = [n.zero_grad() for n in nets]\n",
    "            t0 = time.time()\n",
    "            batch = data[batch_ids,:] # Batch x SeqLen\n",
    "            batch_sz = batch.shape[0]\n",
    "            batch_len = batch.shape[1] - (batch == pad).sum(axis=1) # Опрделеям длины последовательностей в батче, (Batch_Sz,)\n",
    "            seq_len = max(batch_len)\n",
    "            if seq_len < batch.shape[1]:\n",
    "                batch = batch[:, :seq_len] # Если максимальная длина меньше дефолтной, ограничиваем массив\n",
    "                print(f'step 1_1: {batch.shape}')\n",
    "            \n",
    "            \n",
    "            batch_default_positions = default_positions[:seq_len,:seq_len] # max_len x max_len\n",
    "            center_words = list(map(np.random.randint, batch_len)) # Выбираем токен, который опустим в последовательности, (Batch_Sz,)\n",
    "            \n",
    "            batch = reorder_tokens(batch, center_words) # Меняем порядок строк/столбцов в матрице токенов, Batch_Sz x Len_Seq\n",
    "            \n",
    "            # Меняем порядок строк/столбцов в позиционной матрице, Batch_Sz x max_len x max_len\n",
    "            pos_matrix = np.stack([reorder_posistions(default_positions, x) for x in center_words])\n",
    "            \n",
    "            # Делаем замену начальных токенов на новые токены + фичи + Негативный сэмплинг\n",
    "            batch = process_batch(batch) # Batch_Sz x max_len x 5 (id, title, upper, w_end, part)\n",
    "            negative_batch = torch.tensor(einops.rearrange(\n",
    "                np.stack(v_negative_tokens(batch[:,:,0], cnt_negative), axis=2),\n",
    "                'b s n -> (b s) n'\n",
    "            ), dtype=torch.int).requires_grad_(False)\n",
    "            batch = torch.tensor(batch, dtype=torch.int).requires_grad_(False) # Batch_Sz x max_len x 5 (id, title, upper, w_end, part)\n",
    "            \n",
    "            # Получаем эмбединг позиционной матрицы, Batch_Sz x max_len x max_len x pos_emb_size\n",
    "            pos_matrix = PosEnc.forward2(torch.tensor(pos_matrix, dtype=torch.int).requires_grad_(False), ptime)\n",
    "            \n",
    "            # Получаем эмбединги фичей токенов\n",
    "            # Batch_Sz x max_len x max_len x Cnt_Cats * Cnt_Meanings x (EmbTitle + EmbUpper + EmbPart + ...)\n",
    "            props_embs = PropsEmb.forward4(batch[:,:,1:], ptime)\n",
    "            \n",
    "            # Получаем эмбединги токенов\n",
    "            tokens_embs, tokens_embs_ext, negative_batch = TokensEmb.forward5(batch[:,:,0], negative_batch, ptime)\n",
    "            \n",
    "            # tokens_embs = Batch_Sz x max_len x x max_len x Cnt_Cats * Cnt_Meanings x (CatEmb + EmbMeaning)\n",
    "            tokens_embs = einops.rearrange(tokens_embs, 'b s cm e -> (b s) cm e')\n",
    "            \n",
    "            all_tk_cat_ext = einops.repeat(all_tk_cat, 'b s_h cm e-> b s_w s_h cm e', s_w=columns)\n",
    "            \n",
    "        \n",
    "            \n",
    "            \n",
    "            \n",
    "            # Объединяем все матрицы в одну\n",
    "            pos_props_tokens = torch.cat([pos_matrix, props_embs, tokens_embs_ext], axis=-1)\n",
    "            \n",
    "            # Создаем маску, чтобы не учитывать центранльные токены при агрегировании\n",
    "            # TODO: Добавить логигу когда у нас будет PAD в последовательности\n",
    "            mask = torch.tensor([-np.inf,] + [1.0 for i in range(max_len - 1)], dtype=torch.float32).requires_grad_(False)\n",
    "            mask_ext = einops.repeat(mask, 's1 -> s2 (s1 m)', s2=batch_sz * max_len, \n",
    "                                 m=TokensEmb.cnt_meanings * TokensEmb.cnt_categories).requires_grad_(False)\n",
    "            \n",
    "            mask = einops.repeat(mask, 's1 -> s2 s1', s2=batch_sz * max_len, \n",
    "                                 m=TokensEmb.cnt_meanings * TokensEmb.cnt_categories).requires_grad_(False)\n",
    "            # Подаем собранные данные в агрегирующую рекурсивную сеть,\n",
    "            # На выходе массив скрытых состояний.\n",
    "            hidden_states = AggNet.forward(pos_props_tokens, mask, rounds_agg)\n",
    "            hidden_states = einops.rearrange(hidden_states, 'r bs e -> (r bs) e')\n",
    "            \n",
    "            hidden_states_ext = einops.repeat(\n",
    "                hidden_states, 'rbs e -> rbs m e',\n",
    "                m=TokensEmb.cnt_categories * TokensEmb.cnt_meanings * (cnt_negative + 1)\n",
    "            )\n",
    "            tokens_props = einops.repeat(batch[:,:,1:], 'b s f -> (m b s) f', m=rounds_agg).requires_grad_(False)\n",
    "            props_pred = PropNet.forward(hidden_states)\n",
    "            \n",
    "            loss_mask = torch.tensor([1.0, ] + [mask_coef, ] * (max_len - 1), dtype=torch.float32).requires_grad_(False)\n",
    "            loss_mask = einops.repeat(loss_mask, 's -> (rp b s) f', rp=rounds_agg, b=batch_sz, f=1).requires_grad_(False)\n",
    "            \n",
    "            \n",
    "            loss_mask2 = torch.tensor(\n",
    "                [(i/rounds_agg)**hidden_coef for i in range(1, rounds_agg + 1)],\n",
    "                dtype=torch.float32).requires_grad_(False)\n",
    "            loss_mask2 = einops.repeat(loss_mask2, 'h -> (h bs) f', bs=batch_sz*max_len , f=1).requires_grad_(False)\n",
    "            \n",
    "            props_l2 = l2_none_loss(props_pred, tokens_props.type(torch.float32)) # Лосс на свойства токенов\n",
    "            props_l2_mask = props_l2 * loss_mask * loss_mask2\n",
    "            \n",
    "            hist_props_l2.append(props_l2.mean().item())\n",
    "            hist_props_l2_mask.append(props_l2_mask.mean().item())\n",
    "            \n",
    "            if len(hist_props_l2) > avg_info:\n",
    "                hist_props_l2.pop(0)\n",
    "                hist_props_l2_mask.pop(0)\n",
    "                \n",
    "                \n",
    "            # Предсказание слов\n",
    "            true_false_batch = torch.cat([tokens_embs, negative_batch], axis=1)\n",
    "            true_false_batch = einops.repeat(true_false_batch, 'bs m e -> (r bs) m e', r=rounds_agg)\n",
    "            \n",
    "            meanings_pred = CMNet.forward(torch.cat([hidden_states_ext,true_false_batch], axis=-1)).squeeze()\n",
    "            \n",
    "            # Негативный лосс\n",
    "            neg_fact = torch.zeros(\n",
    "                (rounds_agg * batch_sz * max_len, cnt_negative * TokensEmb.cnt_categories * TokensEmb.cnt_meanings),\n",
    "                dtype=torch.float32).requires_grad_(False)\n",
    "            neg_l2 = l2_none_loss(meanings_pred[:, (TokensEmb.cnt_categories * TokensEmb.cnt_meanings):], neg_fact) # Лосс на негативные значения\n",
    "            neg_l2_mask = neg_l2 * loss_mask * loss_mask2\n",
    "            \n",
    "            hist_neg_l2.append(neg_l2.mean().item())\n",
    "            hist_neg_l2_mask.append(neg_l2_mask.mean().item())\n",
    "            \n",
    "            if len(hist_neg_l2) > avg_info:\n",
    "                hist_neg_l2.pop(0)\n",
    "                hist_neg_l2_mask.pop(0)\n",
    "                \n",
    "            \n",
    "            # Позитивный лосс\n",
    "            max_pred = meanings_pred[:, :(TokensEmb.cnt_categories * TokensEmb.cnt_meanings)].max(axis=1)[0]\n",
    "            pos_fact_1 = torch.ones((rounds_agg * batch_sz * max_len,), dtype=torch.float32).requires_grad_(False)\n",
    "            pos_max_l2 = l2_none_loss(max_pred, pos_fact_1)\n",
    "            pos_max_l2_mask = pos_max_l2 * loss_mask.squeeze() * loss_mask2.squeeze() \n",
    "            \n",
    "            sum_pred = meanings_pred[:, :(TokensEmb.cnt_categories * TokensEmb.cnt_meanings)].sum(axis=1)\n",
    "            pos_sum_l2 = l2_none_loss(sum_pred, pos_fact_1)\n",
    "            pos_sum_l2_mask = pos_sum_l2 * loss_mask.squeeze() * loss_mask2.squeeze() \n",
    "            \n",
    "            \n",
    "            hist_pos_max_l2.append(pos_max_l2.mean().item())\n",
    "            hist_pos_max_l2_mask.append(pos_max_l2_mask.mean().item())\n",
    "            \n",
    "            hist_pos_sum_l2.append(pos_sum_l2.mean().item())\n",
    "            hist_pos_sum_l2_mask.append(pos_sum_l2_mask.mean().item())\n",
    "            \n",
    "            if len(hist_pos_max_l2) > avg_info:\n",
    "                hist_pos_max_l2.pop(0)\n",
    "                hist_pos_max_l2_mask.pop(0)\n",
    "                \n",
    "                hist_pos_sum_l2.pop(0)\n",
    "                hist_pos_sum_l2_mask.pop(0)\n",
    "            \n",
    "            \n",
    "            \n",
    "            final_loss = props_l2_mask.mean() + neg_l2_mask.mean() + pos_max_l2_mask.mean() + \\\n",
    "                pos_sum_coef * pos_sum_l2_mask.mean()\n",
    "            \n",
    "            # final_loss = props_l2_mask.mean()\n",
    "            print(f'final_loss: {final_loss.item()}')\n",
    "            final_loss.backward()\n",
    "            \n",
    "            _ = [n.step() for n in nets]\n",
    "            \n",
    "            print(f'Batch Time: {time.time() - t0}')\n",
    "            return None\n",
    "            # return (hist_props_l2[0], hist_props_l2_mask[0], hist_neg_l2[0], hist_neg_l2_mask[0], \n",
    "                    # hist_pos_max_l2[0], hist_pos_max_l2_mask[0], hist_pos_sum_l2[0], hist_pos_sum_l2_mask[0])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0b12196d-634e-4a0e-bb84-d287105d693d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(nets, data, \n",
    "          batch_size, cnt_negative, rounds_agg, \n",
    "          mask_coef, hidden_coef, pos_sum_coef, pad,\n",
    "          length_hist=100, opt_type='SGD', lr=1e-3, seed=0, max_seq_len=1024, cnt_epochs=10**6, ptime=False\n",
    "         ):\n",
    "    \n",
    "    for net in nets:\n",
    "        if type(net) is list:\n",
    "            for subnet in net:\n",
    "                subnet.init_optims(opt_type, lr)\n",
    "        else:\n",
    "            net.init_optims(opt_type, lr)\n",
    "    \n",
    "    PosEnc, PropsEmb, TokensEmb, AggNet, PropNet, CatNet, MngNets = nets\n",
    "    l2_none_loss = torch.nn.MSELoss(reduction='none')\n",
    "    \n",
    "    rows, _ = data.shape\n",
    "    indices = np.arange(rows)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Определяем дефолтную матрицу позиций\n",
    "    default_positions = np.array([\n",
    "        [max_seq_len + j - i - 1 for j in range(max_seq_len) ] \n",
    "        for i in range(max_seq_len)\n",
    "    ]) # Dist_ij = Dist(Token_i, Token_j)\n",
    "    \n",
    "    hist_props_l2 = []\n",
    "    hist_props_l2_mask = []\n",
    "    \n",
    "    hist_neg_l2 = []\n",
    "    hist_neg_l2_mask = []\n",
    "    \n",
    "    hist_pos_max_l2 = []\n",
    "    hist_pos_max_l2_mask = []\n",
    "    \n",
    "    hist_pos_sum_l2 = []\n",
    "    hist_pos_sum_l2_mask = []\n",
    "    \n",
    "    hist_final_loss = []\n",
    "    \n",
    "    try:\n",
    "        # Цикл по эпохам\n",
    "        for epoch_i in range(cnt_epochs):\n",
    "            np.random.shuffle(indices) # Шафлим индексы, так как шафлить массив намного дольше\n",
    "\n",
    "            for batch_i in range(int(rows / batch_size) + 1): # Цикл по батчам\n",
    "                batch_ids = indices[batch_i*batch_size:(batch_i+1)*batch_size]\n",
    "                if len(batch_ids) == 0:\n",
    "                    continue # Прошлись по всей выборке\n",
    "\n",
    "                for net in nets:\n",
    "                    if type(net) is list:\n",
    "                        for subnet in net:\n",
    "                            subnet.zero_grad()\n",
    "                    else:\n",
    "                        net.zero_grad()\n",
    "\n",
    "                t0 = time.time()\n",
    "                batch = data[batch_ids,:] # Batch x SeqLen\n",
    "                batch_sz = batch.shape[0]\n",
    "                batch_len = batch.shape[1] - (batch == pad).sum(axis=1) # Опрделеям длины последовательностей в батче, (Batch,)\n",
    "                seq_len = max(batch_len)\n",
    "                if seq_len < batch.shape[1]:\n",
    "                    batch = batch[:, :seq_len] # Если максимальная длина меньше дефолтной, ограничиваем массив\n",
    "                    print(f'step 1_1: {batch.shape}')\n",
    "\n",
    "\n",
    "                pos_matrix = default_positions[:seq_len,:seq_len] # seq_len x seq_len\n",
    "\n",
    "                # Делаем замену начальных токенов на новые токены + фичи + Негативный сэмплинг\n",
    "                batch = process_batch(batch) # batch x seq_len x 5 (id, title, upper, w_end, part)\n",
    "                batch = torch.tensor(batch, dtype=torch.int).requires_grad_(False) # batch x seq_len x 5 (id, title, upper, w_end, part)\n",
    "\n",
    "                negative_batch = torch.tensor(\n",
    "                    np.stack(v_negative_tokens(batch[:,:,0], cnt_negative), axis=2), \n",
    "                    dtype=torch.int\n",
    "                ).requires_grad_(False) # batch x seq_len x cnt_negative\n",
    "\n",
    "\n",
    "                # Получаем эмбединг позиционной матрицы, seq_len x seq_len x pos_emb\n",
    "                pos_matrix = PosEnc.forward(torch.tensor(pos_matrix, dtype=torch.int).requires_grad_(False), ptime)\n",
    "                # pos_matrix = seq_len x seq_len x pos_emb\n",
    "\n",
    "                pos_matrix_ext = einops.repeat(pos_matrix, 's_w s_h e -> b s_w s_h (c m) e', \n",
    "                                               b=batch_sz, c=TokensEmb.cnt_categories, m=TokensEmb.cnt_meanings)\n",
    "                # pos_matrix_ext = batch x seq_len x seq_len x (cnt_cats * cnt_meanings) x pos_emb\n",
    "\n",
    "                pos_matrix_ext2 = einops.repeat(pos_matrix, 's_w s_h e -> b s_w s_h e', b=batch_sz)\n",
    "                # pos_matrix_ext2 = batch x seq_len x seq_len x pos_emb\n",
    "\n",
    "\n",
    "                # Получаем эмбединги фичей токенов\n",
    "                props_embs = PropsEmb.forward(batch[:,:,1:], ptime)\n",
    "                # batch x seq_len x props_embs\n",
    "\n",
    "                props_embs = einops.repeat(props_embs, 'b s_h e -> b s_w s_h cm e', s_w=seq_len, \n",
    "                                           cm=TokensEmb.cnt_categories * TokensEmb.cnt_meanings) \n",
    "                # props_embs = batch x seq_len (s_w) x seq_len (s_h) x (cnt_cats * cnt_meanings) x props_embs\n",
    "\n",
    "                # Получаем эмбединги токенов\n",
    "                cat_tokens_embeds, tokens_embeds, negative_batch = TokensEmb.forward(batch[:,:,0], negative_batch, ptime)\n",
    "                # cat_tokens_embeds = batch x seq_len x cnt_cats x cnt_meanings x (cat_emb + meaning_emb)   \n",
    "                # negative_batch = batch x seq_len x cnt_negative x cnt_cats x cnt_meanings x meaning_emb\n",
    "                # tokens_embeds = batch x seq_len x 1 x cnt_cats x cnt_meanings x meaning_emb\n",
    "\n",
    "                cat_tokens_embs_ext = einops.repeat(cat_tokens_embeds, 'b s_h c m e -> b s_w s_h (c m) e', s_w=seq_len)\n",
    "                # tokens_embs_ext = batch x seq_len x seq_len x (cnt_cats * cnt_meanings) x (cat_emb + emb_meaning)\n",
    "\n",
    "                # Объединяем все матрицы в одну\n",
    "                pos_props_tokens = torch.cat([pos_matrix_ext, props_embs, cat_tokens_embs_ext], axis=-1)\n",
    "                # pos_props_tokens = batch x seq_len x seq_len x (cnt_cats * cnt_meanings) x (pos_emb + cat_emb + emb_meaning)\n",
    "\n",
    "                # TODO: Добавить логику маскирования pad токенов.\n",
    "                # Подаем собранные данные в агрегирующую рекурсивную сеть,\n",
    "                # На выходе массив скрытых состояний.\n",
    "                mask = None\n",
    "                hidden_states = AggNet.forward(pos_props_tokens, pos_matrix_ext2, mask, rounds_agg, ptime)\n",
    "                # hidden_states = rounds_agg x batch x seq_len x hidden\n",
    "\n",
    "                hidden_states = einops.rearrange(hidden_states, 'r b s e -> b s r e')\n",
    "                # hidden_states = batch x seq_len x rounds_agg x hidden\n",
    "\n",
    "                # ПРЕДСКАЗАНИЕ СВОЙСТВ\n",
    "                props_pred = PropNet.forward(hidden_states)\n",
    "                # props_pred = batch x seq_len x rounds_agg x props (=4)\n",
    "\n",
    "                props_fact = einops.repeat(batch[:,:,1:], 'b s p -> b s r p', r=rounds_agg).\\\n",
    "                    requires_grad_(False).type(torch.float32)\n",
    "                # props_fact = batch x seq_len x rounds_agg x props (=4)\n",
    "\n",
    "                # Лосс на свойства токенов\n",
    "                props_l2 = l2_none_loss(props_pred, props_fact)\n",
    "                # props_l2 = batch x seq_len x rounds_agg x props (=4)\n",
    "\n",
    "                loss_round_mask = torch.tensor(\n",
    "                    [(i/rounds_agg)**hidden_coef for i in range(1, rounds_agg + 1)],\n",
    "                    dtype=torch.float32\n",
    "                ).requires_grad_(False)\n",
    "                # loss_round_mask = (rounds_agg, )\n",
    "\n",
    "                loss_round_mask = einops.repeat(loss_round_mask, 'r -> b s r f', b=batch_sz, s=seq_len, f=1).requires_grad_(False)\n",
    "                # loss_round_mask = batch x seq_len x rounds_agg x 1\n",
    "\n",
    "                props_l2_mask = props_l2 * loss_round_mask\n",
    "                # props_l2_mask = batch x seq_len x rounds_agg x props (=4)\n",
    "\n",
    "                hist_props_l2.append(props_l2.mean().item())\n",
    "                hist_props_l2_mask.append(props_l2_mask.mean().item())\n",
    "\n",
    "                if len(hist_props_l2) > length_hist:\n",
    "                    hist_props_l2.pop(0)\n",
    "                    hist_props_l2_mask.pop(0)\n",
    "\n",
    "                # ПРЕДСКАЗАНИЕ КАТЕГОРИИ\n",
    "                # hidden_states = batch x seq_len x rounds_agg x hidden\n",
    "                cat_pred = CatNet.forward(hidden_states)\n",
    "                # cat_pred = batch x seq_len x rounds_agg x cnt_categories\n",
    "\n",
    "\n",
    "                # Предсказание слов\n",
    "                # tokens_embeds = batch x seq_len x 1 x cnt_cats x cnt_meanings x meaning_emb\n",
    "                # negative_batch = batch x seq_len x cnt_negative x cnt_cats x cnt_meanings x meaning_emb\n",
    "                # hidden_states = batch x seq_len x rounds_agg x hidden\n",
    "\n",
    "                true_false_tokens = torch.cat([tokens_embeds, negative_batch], axis=2)\n",
    "                # true_false_tokens = batch x seq_len x (1 + cnt_negative) x cnt_cats x cnt_meanings x meaning_emb\n",
    "\n",
    "                true_false_tokens_ext = einops.repeat(true_false_tokens, 'b s np c m e -> b s r np c m e',\n",
    "                                                      r=rounds_agg)\n",
    "                # true_false_tokens_ext = batch x seq_len x rounds_agg x (1 + cnt_negative) x cnt_cats x cnt_meanings x meaning_emb\n",
    "\n",
    "                hidden_states_ext = einops.repeat(hidden_states, 'b s r h -> b s r np m h', \n",
    "                                                  np=1+cnt_negative, m=TokensEmb.cnt_meanings)\n",
    "                # hidden_states_ext = batch x seq_len x rounds_agg x (1 + cnt_negative) x cnt_meanings x hidden\n",
    "\n",
    "\n",
    "                meanings_pred = []\n",
    "                for i in range(TokensEmb.cnt_categories):\n",
    "                    meaning_pred_i = MngNets[i].forward(\n",
    "                        torch.cat([\n",
    "                            hidden_states_ext, \n",
    "                            true_false_tokens_ext[:,:,:,:,i,:,:]\n",
    "                        ], axis=-1)\n",
    "                    )\n",
    "                    # meaning_pred_i = batch x seq_len x rounds_agg x (1 + cnt_negative) x cnt_meanings\n",
    "\n",
    "                    meanings_pred.append(meaning_pred_i)\n",
    "                # meanings_pred (list) = cnt_cats x batch x seq_len x rounds_agg x (cnt_negative + 1) x cnt_meanings\n",
    "\n",
    "                meanings_pred = einops.rearrange(meanings_pred, 'c b s r np m -> b s r np c m')\n",
    "                # meanings_pred = batch x seq_len x rounds_agg x (cnt_negative + 1) x cnt_cats x cnt_meanings\n",
    "\n",
    "                cat_pred_ext = einops.repeat(cat_pred, 'b s r c -> b s r np c m', \n",
    "                                             np=1+cnt_negative, m=TokensEmb.cnt_meanings)\n",
    "                # cat_pred_ext = batch x seq_len x rounds_agg x (1 + cnt_negative) x cnt_categories x cnt_meanings\n",
    "\n",
    "                final_meanings_pred = meanings_pred * cat_pred_ext\n",
    "                # final_meanings_pred = batch x seq_len x rounds_agg x (1 + cnt_negative) x cnt_categories x cnt_meanings\n",
    "\n",
    "                # НЕГАТИВНЫЙ ЛОСС\n",
    "                negative_l2 = final_meanings_pred[:, :, :, 1:, :, :] ** 2\n",
    "                # negative_l2 = batch x seq_len x rounds_agg x cnt_negative x cnt_categories x cnt_meanings\n",
    "\n",
    "                loss_round_mask_ext = einops.repeat(loss_round_mask.squeeze(), 'b s r -> b s r n c m', n=cnt_negative, \n",
    "                                                    c=TokensEmb.cnt_categories, m=TokensEmb.cnt_meanings).requires_grad_(False)\n",
    "                # loss_round_mask_ext = batch x seq_len x rounds_agg x cnt_negative x cnt_categories x cnt_meanings\n",
    "\n",
    "\n",
    "                negative_l2_mask = negative_l2 * loss_round_mask_ext\n",
    "                # negative_l2_mask = batch x seq_len x rounds_agg x cnt_negative x cnt_categories x cnt_meanings\n",
    "\n",
    "                hist_neg_l2.append(negative_l2.mean().item())\n",
    "                hist_neg_l2_mask.append(negative_l2_mask.mean().item())\n",
    "\n",
    "                if len(hist_neg_l2) > length_hist:\n",
    "                    hist_neg_l2.pop(0)\n",
    "                    hist_neg_l2_mask.pop(0)\n",
    "\n",
    "\n",
    "                # ПОЗИТИВНЫЙ ЛОСС\n",
    "                true_tokens = einops.rearrange(final_meanings_pred[:, :, :, 0, :, :], 'b s r c m -> b s r (c m)')\n",
    "                # true_tokens = batch x seq_len x rounds_agg x (cnt_categories * cnt_meanings)\n",
    "\n",
    "                max_pred = true_tokens.max(axis=-1)[0].squeeze()\n",
    "                # max_pred = batch x seq_len x rounds_agg\n",
    "\n",
    "                sum_pred = true_tokens.sum(axis=-1).squeeze()\n",
    "                # sum_pred = batch x seq_len x rounds_agg\n",
    "\n",
    "                pos_fact = torch.ones((batch_sz, seq_len, rounds_agg), dtype=torch.float32).requires_grad_(False)\n",
    "                # pos_fact = batch x seq_len x rounds_agg\n",
    "\n",
    "                pos_sum_l2 = l2_none_loss(sum_pred, pos_fact)\n",
    "                # pos_sum_l2 = batch x seq_len x rounds_agg\n",
    "\n",
    "                # loss_round_mask = batch x seq_len x rounds_agg x 1\n",
    "                pos_sum_l2_mask = pos_sum_l2 * loss_round_mask.squeeze()\n",
    "                # pos_max_l2_mask = batch x seq_len x rounds_agg\n",
    "\n",
    "                pos_max_l2 = l2_none_loss(max_pred, pos_fact)\n",
    "                # pos_max_l2 = batch x seq_len x rounds_agg\n",
    "\n",
    "                pos_max_l2_mask = pos_max_l2 * loss_round_mask.squeeze()\n",
    "                # pos_max_l2_mask = batch x seq_len x rounds_agg\n",
    "\n",
    "                hist_pos_max_l2.append(pos_max_l2.mean().item())\n",
    "                hist_pos_max_l2_mask.append(pos_max_l2_mask.mean().item())\n",
    "\n",
    "                hist_pos_sum_l2.append(pos_sum_l2.mean().item())\n",
    "                hist_pos_sum_l2_mask.append(pos_sum_l2_mask.mean().item())\n",
    "\n",
    "                if len(hist_pos_max_l2) > length_hist:\n",
    "                    hist_pos_max_l2.pop(0)\n",
    "                    hist_pos_max_l2_mask.pop(0)\n",
    "\n",
    "                    hist_pos_sum_l2.pop(0)\n",
    "                    hist_pos_sum_l2_mask.pop(0)\n",
    "\n",
    "                final_loss = props_l2_mask.mean() + negative_l2_mask.mean() + pos_max_l2_mask.mean() + \\\n",
    "                    pos_sum_coef * pos_sum_l2_mask.mean()\n",
    "                \n",
    "                hist_final_loss.append(final_loss.item())\n",
    "                \n",
    "                # print(f'final_loss: {final_loss.item()}')\n",
    "                final_loss.backward()\n",
    "                \n",
    "                if batch_i % 50 == 0 and batch_i != 0:\n",
    "                    print(f'Avg Final Loss: {round(np.mean(hist_final_loss[-50:]),4)}')\n",
    "                \n",
    "                for net in nets:\n",
    "                    if type(net) is list:\n",
    "                        for subnet in net:\n",
    "                            subnet.step()\n",
    "                    else:\n",
    "                        net.step()\n",
    "\n",
    "                # print(f'Batch Time: {time.time() - t0}')\n",
    "                # return None\n",
    "    except:\n",
    "        print('Stop Running.')\n",
    "        return (hist_props_l2, hist_props_l2_mask, hist_neg_l2, hist_neg_l2_mask, \n",
    "                hist_pos_max_l2, hist_pos_max_l2_mask, hist_pos_sum_l2, hist_pos_sum_l2_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d7859eb8-e046-496e-968e-b07153c64ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PosEnc = PosEncoding(\n",
    "    rows=(MAX_SEQ_LEN - 1) * 2 + 1, \n",
    "    emb_size=POS_EMB_SIZE\n",
    ")\n",
    "PropsEmb = PropsEmbeding(\n",
    "    title=TITLE_EMB_SIZE, \n",
    "    upper=UPPER_EMB_SIZE, \n",
    "    part=PART_EMB_SIZE, \n",
    "    w_end=END_EMB_SIZE\n",
    ")\n",
    "TokensEmb = TokensEmbeding(\n",
    "    cnt_tokens=len(ALL_VOCAB['Second']), \n",
    "    categories_sz=CAT_SIZES, \n",
    "    cnt_meanings=CNT_MEANINGS,\n",
    "    meaning_emb_sz=MEANING_EMB_SIZE,\n",
    "    cat_emb_sz=CAT_EMB_SIZE\n",
    ")\n",
    "AggNet = AggregationNet(\n",
    "    hidden_size=HIDDEN_SIZE, \n",
    "    full_embeding_size=INPUT_SIZE,\n",
    "    short_embeding_size=PREDICT_SIZE,\n",
    "    pos_embebing_size=POS_EMB_SIZE\n",
    ")\n",
    "PropNet = PropertyNet(\n",
    "    input_size=HIDDEN_SIZE\n",
    ")\n",
    "CatNet = CategoryNet(\n",
    "    input_size=HIDDEN_SIZE,\n",
    "    cnt_categories=len(CAT_SIZES)\n",
    ")\n",
    "MngNets = [MeaningNet(input_size=HIDDEN_SIZE + MEANING_EMB_SIZE, seed=i) for i in range(len(CAT_SIZES))]\n",
    "\n",
    "\n",
    "MAX_POSITION_MATRIX = np.array([\n",
    "        [MAX_SEQ_LEN + j - i - 1 for j in range(MAX_SEQ_LEN)] \n",
    "        for i in range(MAX_SEQ_LEN)\n",
    "    ]) # Dist_ij = Dist(Token_i, Token_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f06c6b9-579b-44ee-8f04-1eec725da422",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Final Loss: 0.4149\n"
     ]
    }
   ],
   "source": [
    "returned_vals = train(\n",
    "    nets=[PosEnc, PropsEmb, TokensEmb, AggNet, PropNet, CatNet, MngNets],\n",
    "    data=train_tokens, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    max_seq_len=MAX_SEQ_LEN,\n",
    "    cnt_negative=CNT_NEGATIVE,\n",
    "    rounds_agg=AGG_ROUNDS,\n",
    "    opt_type='SGD', \n",
    "    lr=1e-3, \n",
    "    mask_coef=0.8,\n",
    "    hidden_coef=1.15,\n",
    "    pos_sum_coef=0.05,\n",
    "    pad=wrapped_tokenizer.pad_token_id,\n",
    "    length_hist=1000,\n",
    "    ptime=False\n",
    ")\n",
    "\n",
    "(hist_props_l2, hist_props_l2_mask, hist_neg_l2, hist_neg_l2_mask, \n",
    "                hist_pos_max_l2, hist_pos_max_l2_mask, hist_pos_sum_l2, hist_pos_sum_l2_mask) = returned_vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7944a06a-35d6-44d5-9abb-00d701110450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.23224606826901437, 0.1191893957555294)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(hist_props_l2), np.mean(hist_props_l2_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a2fbae0d-dde2-43e9-b3d0-a0e2db9a3ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.04550806749612093, 0.021601198166608812)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(hist_neg_l2), np.mean(hist_neg_l2_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2a7825ef-4ffa-46ce-bd32-7a283490f7c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.38175197660923005, 0.19401257276535033)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(hist_pos_max_l2), np.mean(hist_pos_max_l2_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7c691f99-1a34-4169-bc90-1eaf59841f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.549992718696594, 1.994976280927658)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(hist_pos_sum_l2), np.mean(hist_pos_sum_l2_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140a4193-e304-4693-ac23-81204682cb92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5ce8bd-8f3d-47b2-b157-5217247d56b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "fb38ec31-848b-4bd6-ad7b-0887890084a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8d26d4dd60>]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD7CAYAAABjVUMJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABjL0lEQVR4nO29eZxkZ3nf+3tqObVX7z3Ts49Go2UkgUCDJDBiswCxXAnbiS3AGN/rRMaWrmUgNvINITfEuUmILcf+RHEiGwgmCAWDicdGRjaLWC1pZkDbaJvRrD1b711d+/bcP877nnrPqVNVp7qruqeq3u/nM5/pOrX0OV1V7/M+v2cjZoZGo9FoBg/fRp+ARqPRaDYGbQA0Go1mQNEGQKPRaAYUbQA0Go1mQNEGQKPRaAYUbQA0Go1mQPFkAIjoNiJ6iYiOEdF9TR73C0TERLRfOfZ74nkvEdE7leMniehZInqKiA6t7TI0Go1G0y6BVg8gIj+ABwC8HcA0gINEdICZn3c8LgHgXgBPKMf2AbgTwDUAtgD4FhFdwcwV8ZC3MvNcR65Eo9FoNG3R0gAAuBHAMWY+DgBE9DCAOwA873jcvwXwHwH8jnLsDgAPM3MBwAkiOiZe7x9Xc7Lj4+O8a9eu1TxVo9FoBpbDhw/PMfOE87gXA7AVwBnl9jSAm9QHENFrAWxn5m8Q0e84nvu447lbxc8M4O+JiAH8d2Z+sNWJ7Nq1C4cOabVIo9Fo2oGITrkd92IAWr2wD8D9AH61zae+kZnPEtEkgH8goheZ+fsur38XgLsAYMeOHWs9XY1Go9EIvASBzwLYrtzeJo5JEgCuBfAYEZ0EcDOAAyIQ3PC5zCz/nwHwdZjSUB3M/CAz72fm/RMTdR6MRqPRaFaJFwNwEMBeItpNRAbMoO4BeSczLzPzODPvYuZdMCWf25n5kHjcnUQUIqLdAPYCeJKIYiJoDCKKAXgHgOc6emUajUajaUpLCYiZy0R0D4BHAfgBfI6ZjxDRpwEcYuYDTZ57hIi+AjNgXAZwNzNXiGgTgK8TkTyHh5j5mx24Ho1Go9F4hHqpHfT+/ftZB4E1Go2mPYjoMDPvdx7XlcAajUYzoGgDoNFoNAOKNgAai0eePY/5dGGjT0Oj0awT2gBoAACZQhm/+aWf4Gs/md7oU9FoNOuENgAaAEChXAUArOTLG3wmGo1mvdAGQAMAKFVMA5ApVFo8UqPR9AvaAGgAAEXhAeRK2gPQaAYFbQA0AIBy1awH0R6ARjM4aAOgAVCTgLJF7QFoNIOCNgAaADUJSHsAGs3goA2ABoD2ADSaQUQbAA0AoFQxYwDZovYANJpBQRsADQCgbHkA2gBoNIOCNgAaAEBR1gFoCUijGRi0AdAAUCQgHQTWaAYGbQA0AGpB4GKlav2s0Wj6G20A2uDJEwt4y3/6LtKF/pNJ1EVfxwE0msHAkwEgotuI6CUiOkZE9zV53C8QEYuB8PLY74nnvURE72z3NS8lXryQwsn5LM4t5Tb6VDqOlIAAnQqq0QwKLWcCE5EfwAMA3g5gGsBBIjrAzM87HpcAcC+AJ5Rj+2AOkb8GwBYA3yKiK8TdLV/zUiMndsZL2dIGn0nnUT0AXQym0QwGXjyAGwEcY+bjzFwE8DCAO1we928B/EcAeeXYHQAeZuYCM58AcEy8ntfXvKTIlaQBKG7wmXQeuwSkPQCNZhDwYgC2Ajij3J4WxyyI6LUAtjPzNzw+t+VrXopYBiDXfx6AbAUBaA9AoxkU1hwEJiIfgPsBfHztp+P6+ncR0SEiOjQ7O9uNX+GZvJCAUn1oANQYgG4JrdEMBl4MwFkA25Xb28QxSQLAtQAeI6KTAG4GcEAEghs9t9VrWjDzg8y8n5n3T0xMeDjd7lGTgPrPAJR1DECjGTi8GICDAPYS0W4iMmAGdQ/IO5l5mZnHmXkXM+8C8DiA25n5kHjcnUQUIqLdAPYCeLLVa16q5ErmIrmU0zEAjUbT+7TMAmLmMhHdA+BRAH4An2PmI0T0aQCHmLnhwi0e9xUAzwMoA7ibmSsA4Paaa7+c7tLPWUBFRQLSHoBGMxi0NAAAwMyPAHjEcexTDR77Fsftfwfg33l5zUudvJCAlvsyBlCF4fehWKlaUpdGo+lvdCVwG/RzDKBUqSIa8iPgI2T6sNJZo9HUow1AG1gSUF/GABhBvw9Rw69bQWg0A4InCUhjYklAfeoBGH6f9gA0mgFCG4A2kAYglS+jUmX4fbTBZ9Q5SpUqgn6C3+fTHoBGMyBoCagNcqUKSKz5/VYMZhoAH2KhgE4D1WgGBG0A2iBXqmAiHgLQf+0gimUzBhAJ+pHRHoBGMxBoA+CRapWRL1UxNRQG0FsN4Y5eXMG+T30Tp+ezDR9TrpoSkPYANJrBQRsAjxREs7TN0gD0kAfw4oUVZIsVnJjPNHyMlICihl+PhdRoBgRtADwiawA2J00D0EuZQIvCW1nJNz7nkpCAYkZAD4bXaAYEbQA8Ig3Aph6UgObT5rmm840X9mKlimDAh2hI1wFoNIOCNgAekUVglgeQ651dsvQAms0yNusAyCoEY+aGj9VoNP2BNgAufPO5C7j7Sz+xHZM1APFQAIlQoKeqgRcy5rmmmngA5Qoj4PMhagRQqbIV89BoNP2LNgAuPH58Ht949jyqVXVIimkAIoYfQ9FgT8UApAFoJgGVhAQUM/wAoGUgjWYA0AbABZkGqQZDpQQUCfoxHA32VBaQZQAKjc+5KCqBoyGzOFy3g9Bo+h9tAFyQhVBqX3zpAYSDfgxHjJ4KAksDsNLCAzBEFhAA3RJa4YXzKdx6//d6yuvTaLygDYALcrev7pjzDgmoVzwAZvYYBK51AwW0B6Dy3NllHJtJ48xi40I6jaYX8WQAiOg2InqJiI4R0X0u93+EiJ4loqeI6IdEtE8cN4jo8+K+p4noLcpzHhOv+ZT4N9mpi1orcvFLKx6AZQCCfgxFeicGkC6UrYHvzYLApUoVAZEFBHiLATz85Gl8+cnTnTnRSxj5edBekabfaNkNlIj8AB4A8HYA0wAOEtEBZn5eedhDzPzfxONvB3A/gNsA/HMAYObrxAL/d0T0OmaWKSYfFLODLynkF10NmtpiAJEglnMlMDOILu2OoFL+AYB0s0IwKQG1EQN4+OAZFMpVvP/GHWs/0UsYKQnmdGBc02d48QBuBHCMmY8zcxHAwwDuUB/AzCnlZgyATJ/ZB+A74jEzAJYA7F/jOXedmgegGAAxED5imEHgcpV7ommaNACTiVBbEpAXD2AlX8KF5VxnTvQSRnsAmn7FiwHYCuCMcntaHLNBRHcT0SsAPgPgt8ThpwHcTkQBItoN4AYA25WnfV7IP/+KLqGtdC0GoBoA81go4MNwxADQG9XA0gDsHIs2DAJXqoxKla120IBXA1DGYrZkyWP9ivxb9Pt1agaPjgWBmfkBZt4D4BMAPikOfw6mwTgE4D8D+DEA+S36IDNfB+AW8e9Dbq9LRHcR0SEiOjQ7O9up021KLQuotmDmSxVEgn4QEYaiQQC9MRtYGoDto1FkixVUqvUVvqWK6d0EA4SI5QG0loCkQTm/nO/U6V6SyI2Aro3Q9BteDMBZ2Hft28SxRjwM4H0AwMxlZv4oM1/PzHcAGAbwsrjvrPh/BcBDMKWmOpj5QWbez8z7JyYmPJzu2nH1AIoVa3EcjpgGYLkLmUBmxslKx15PZgDtHI0BcC8GKwujEPT5EA3KLKDmi12pUrW8ovN9LgNZEpA2AJo+w4sBOAhgLxHtJiIDwJ0ADqgPIKK9ys33ADgqjkeJKCZ+fjuAMjM/LyShcXE8COC9AJ5b89V0gGK5iqLYEauSSU54AAAwHJUSUOcNwL/838/h97/xQsdebz5ThOH3YfOQOchmxaUYrCTaPgT9hIDfh1DA19IDUA3JhT73AKwgsJaANH1GyywgZi4T0T0AHgXgB/A5Zj5CRJ8GcIiZDwC4h4huBVACsAjgw+LpkwAeJaIqTK9ByjwhcTwoXvNbAP6sg9e1atRdXsYRAwgHTXs5LCWgLvQDWs4WUal2rg/PYqaI0ZiBRNg8Z7dAcE0CMq8vFmrdElo1jv0uAWkPQNOveBoKz8yPAHjEcexTys/3NnjeSQBXuhzPwAwIX3JkS7WFTV0s88UKwsIDGOqiBJQuVKy8/U6wkCliJGYgLoK7boFg6fEE/aYBkB1Bm5FSUkoHRgLSHoCmz/BkAPqVhUwRxXLVmvIF2LVvZxaQlIDCQT9CAV9XisEyhTI6mVy0kCliLGYgETbfarcYgDQ4hmoAWsQAbB7AUp97AEVtADT9yUC3gvjXB47gN7502HZMdfPTzhiACAIDpgzU6RhApcrIlSrIFisdSzlczJYwohiAFRcJqCw8gIDfzMSNepgKJqeLTSZCfS8BSWOY1xKQps8YaANweiGLmVTBdkwufEbAV9cNVEpAAMyGcB2OAai/r1PGZT5dwGg0aMUA3MZCOiWgmIepYNIDuGJTAhdS/W0AdBqopl8ZaAMwt1KwadlAzQOYTIRsHkBekYAAmA3hOuwBqEHnxQ7oQKVKFal8GaOxkBUD8CYBBVq2gpCGZO+mOBYyxb4tkipXqtZwHC0BafqNgTUAzIy5dAHpQtk2/lDuwp2tE3IOAyD7AXWSThsA+RqjsSCihh8+cg8Cl5wegOFvudipHgDQv6mgarsPbQA0/cbAGoB0oYxCuQpm+5c8a3kAYXsWUKna9RiA2n10MbP215avMRoLgYgQDwXc00CVOgAAiBiBloVg6UIZoYAPO0ejAPo3FdRZDa7R9BMDawDm0rUdtqqLZ8UXfjIZsrVOMOsAFAmoBzwA2QZiJGbq/4lw0N0DENcYUDyAVoVgqXwZiXDQyqDq11RQ9e/QLzGASpXx/3z9Wbx8sXMV55reZIANQC34q+ri2VItBgCYklClyiiWq3YJKGogV+pctg5gTztdzHTOAIzGzMrleCjgGgSWHoAVAwgFkC1WbDORnazkS0iGA5gaigDoXw9AemUj0WDfFILNpQt46InTeOylmY0+Fc0GM7gGYKVmANRBKdlCBUTAWNw0AOl8WZkGVvtzyWKwVAe9ALsHsPbXXcjaDUAi3EACUprBAbAGwzfTvFfyZSTCAas9dr/GAKRHOB4P9Y0EJD8DbgkBmsFicA2A4gGou+JMsYyYEbDy5jOFsrUQ2j0A0wB0YqG2frf4YoaDvo60ml4QMteI6F0UDwe8VQJ7aAm9ki8hLv5Gm5PhvpWA5GI5Fjf6RgKSnzO3mhDNYDGwBmBW8QCcXT+jht/qi79SKFuuvzMGAHS2HYSUG7aNRK3d+1pYzBaRDAeshT0RDjbwAOxpoDEPLaFX8mUkQubfYGoo3LcSkFz0JxJh5EoVW8ZYr6I9AI1kcA1Augg5gkbdFWeEAUgooxHVgfCSbhiATKEMH5kLakckINEITmLGALxUArduCS0lIACYGo70rQSUtiQg8+8oawJ6Gfm+tqr21vQ/A2sA5tIFbBEBTFUCyhXLiBoBywNI5xtIQGIqWGc9AFN+Go0ZnZGARCM4SSLcIAhc1wxOSkDNPICSVV08lQxjvk+LweTfYFzEhPohEJwWLcEbTYjTDA4DbQB2jkVBZHeFMwXTA7AqZxUJKNJlCShTKCMWCmAkatiGua8W2QhOkggFUChXUXTsYotCAlJbQQCNYwAVMQ9ZegAyFfRiH7aEkLKc9KSyfWDk5DU1mxGtGQwG2gBMJMwWCSlHGmg0FLAbAPGlDysSUCIcAJHZv79TZIplxEJ+jEQNrOTL1s58tSxkilYAGIAVtHW2eZC/x/DoAUiDKQ3AluH+TQXNFMqIGn5LFusHDyCjYwAaweAagJUixuMhJB3FUdlCGdFgLQisxgDCgZoB8PkIiVCg40HgeChgFW6tpdKYmbGQLWI0bo8BAPWuv7MSOGbIa3df7GT/pKSQgPq5GCxbNL0yaRT7QeayDID2AAaegTQAMrVzPB4S7RGUSuBiBdGQH0bAByPgM7OAXILAgNkQrhsSUG3k5Oq9i2yxgmK5itGoGgMQHUEdYyFlJbDfJ1tBNM8CWnF4AFOWAWjuAcyuFPDXTzUbJ33pkS5UEDP8lvzXD/2A0toAaASeDAAR3UZELxHRMSK6z+X+jxDRs0T0FBH9kIj2ieMGEX1e3Pc0Eb1Fec4N4vgxIvoTIpmT031kDcB43BCBUbXcv2y5+4lQwAwCF80dshoDAMxAcDcMgFy015IJVGsDYQ8CAy4eQKUKw++DfAtkDCDTQO6QgWRpUKJGAEOR1sVgf/WTadz78FMdCXCvF1nxnsgiwH6oBVA9gH5Ia9WsnpYGgIj8AB4A8C4A+wC8Xy7wCg8x83XMfD2AzwC4Xxz/5wDAzNcBeDuAPyQi+Tv/VNy/V/y7bW2X4h1pACYSIRcDULEkkFgoYE8DdRiATvcDShfKiIcCVpFZu4HgMwtZ/Ju/OYIfHp2zrnHMxQA4td9SuWrJP4B5nUS1KlgnTg8AML2Acy0mg8kdp9qH6VJHZmbJGpD+iAGY18DcHwZNs3q8eAA3AjjGzMeZuQjgYQB3qA9g5pRyMwZAbiv2AfiOeMwMgCUA+4loCkCSmR9ncwvyFwDet4braIvZFXMBGo+HEA8HrR2t7P0u9V7ZPbMWBLb/uYYiQSx5NADVKuPn/+uP8M3nzjd8jOkB+K1de7s75W8+dwGf/9FJ/PJnn8CvfPZJAHYPQA1sq5QqVWsgPAAQESYTIZxrsKOXEpJqADYPhXEh1TwGIBee+XSh6eMuJbLFCmIhf1diAF9+8jQePXKhY6/nFfX91zLQYOPFAGwFcEa5PS2O2SCiu4noFZgewG+Jw08DuJ2IAkS0G+Yg+O3i+dOtXrNbOD0Aa+KT+HJLCSgu7suXKvBRLUtGkowEPfcCKpSr+MnpJfzD840bcGWKlTVJQMu5EnwE/PGd1+PV24cxHjeweyxm3R+3JCD76xYrbKWASi4bj+OV2bTr76llAQWtYyNRo2XQOlcyn9eJFNf1Qspy0vvr5I75T759FJ//0YmOvZ5X1CwwXQsw2HRsKDwzPwDgASL6AIBPAvgwgM8BuBrAIQCnAPwYQFvfICK6C8BdALBjx46OnKtsAzEqZuXKNFDp3keFBh4PBTCzkkeuWBGyiD1MISUgZq67z0mhbL72ixdSrveXKmZ+ftwwG6yFAr62W0KnRHHWHddvxR3X19vTpBUEtn/py5Uqgj77+e+ZjOHAU+dcry3lIgElG/QZUrE8gF4yAKI3VKeDwPlSBRdSeSvwvp6kC2UE/YRShVtOftP0N148gLMwd+2SbeJYIx6GkHOYuczMH2Xm65n5DgDDAF4Wz9/m5TWZ+UFm3s/M+ycmJjycbmvm0gWMRIMI+n1IhAIolqsolCvWl8HyAELmYBTnQHjJcDSIUoU9LQr5khlIPnoxbbVeUJG/W6afjkSNtltCp3Ilq0DNjVDAh4CPXIPAqgQEAHsm4kjly66L9UreXEBCynMSQkprFlSUWUXzPRQDyBQqIghsvv+dkoDOLuXAbE5SqzRpu90NMsUyJhNm5paWgAYbLwbgIIC9RLSbiAwAdwI4oD6AiPYqN98D4Kg4HiWimPj57QDKzPw8M58HkCKim0X2z68A+Ou1X4435tIFq7RfyhjpfNly76NKEHhFtIIIB+sNQDvVwNIDKFaqODGXqbtffhGlTj8SM1YlASUjjZ06IjJlrToD4CIBTcQBAK/M1MtAsg2E6hkkwgFUuXHmEFCTTxYyvREDYGarOC/oJ/h91LEg8OmFLACgXOV1r6DOFCpW7YaWgAablgaAmcsA7gHwKIAXAHyFmY8Q0aeJ6HbxsHuI6AgRPQXgYzDlHwCYBPATInoBwCcAfEh56d8E8OcAjgF4BcDfdeB6PDGXLioGoJYaWTMAfus+mQXkzAACagbAS8GW9AAA4IUL9ZOYpDxS8wCCq5CAyk09AMB9JkCxUq0zAHsmzNjBK7P1xkptBCdJit/r1mtIIo1Dr0hAZvdP8z0hIkSC/o7FAM4IAwAA04vrW0CXLpSxOak9AI3HGAAzPwLgEcexTyk/39vgeScBXNngvkMArvV6op1kLl3Aq7YNA7BXx0qJwvIAjABypQpW8mVXCWg1HgAAvHg+hdtfvcV2f9qSgMzfMxI18EKDeEEjUrkSJhPxpo+Jh4J1i7RZB2DXorcMRRAO+nDcJRBsegD2j45qSKeG3H+3TCvtFQnIek/Eex8O+jsWAzg9XzMAZ5eyAEY78rqtkLGmyaQceNTZsaaa3mIgK4HnVgqYcEhAK4VSnQcgs2bm0sU1S0CqB/CiqwfglICCbccAlnMlK9DbCGfdAwCUK2zNA5b4fITdDTKB1FkAtddtPSGtJgH1hgHIOryyqOHvWAzg9EIW20fNHkrTC+vnAcjPmfQAmkl2mv5n4AxArlhBpljBeKI2JhGwS0Axqw7AXPTn0oWmElA7HsC2kQhePF+/s3cLAi/nSk3n8jpJ5UsYirYwAKFGElB9NsqeiZhnCahRlbGKFQTuEQOQLtg9QlMC6oxkcnohiysmExiPh3B2af0MgLymkahhtjrRMYCBZuAMQK0NhFsMQHzhrTRQczGdb2QAot7nAksP4NXbh3FuOY9lR9zAGQQejhqocq3xWisK5QrypSqS4eaqnttYyJJLDAAwA8HTi9m6Xa86C0AiPY9m5yt3m4vZYluGrdM8eWIBXz083fJxckMg35Ow4UeutPaBMMyMMwtZbB+NYutIZF1jAGllo5Fw9MHSDB4DZwBmZRFYXRZQvQQk9fgq1zeCA4C4EYCP6oPAz59L1S1w0gO4XsQenPUATg9gNNZeO4hUznx+chVBYNkLyMmeiRiqDJxS9GqgQRBY3E412FGWhfY8Eg2iUuWOttBol//5+Cn8p0dfbPm4jCMuEwn6kO+AZLKQKSJTrGDnWBTbRiLr6gGo1xQL1WeEaQaLgTMAcytNPIBCGUS1ts/qIucWA/D5CElHP6Djs2m8+09+gMdetlf8FsTO8fodwwDq4wBydywXm+E2q4HlzrtVFpAMAqv5+qVyfRooYNYCALDFAapVRrpYrvM0rFhKAw9AVllvH40C2FgZKF+qeDJAcmRiLQYQ6EgQWKaA7hiNYttwBGcXc+vmEclhMHEx80JnAQ02g2cARAaKjAEE/T6Eg2bb56yo+PWJ6sy4Euh0k4CA+oZwx4Vm7sx0yQsPYMdoFCPRYJ0HIKszQ4FaFhDgvR+QPAcvQeBShW2zbUvVqjUPWOUykQqqZgKli2Uwo04CCgfdi8wkMqC6fcQ0ABsZCM6Xq8iXqrbMLDecXlmnYgA2AzASQbFStaTJbqNeU9zFG/SCKTfq4HE/MHAGQLaBGIuFrGPmrrgsBsLXdrZyNw6YC5wbww4DIN155xdEegDhgB9XbU7ihfMOD0D0nJHIfkDeJSBhADxIQIA9/7uRBBQ1AtgyFLYFgt06gQJmkVkyUp9iKpG76W0i82UjG8LJ98bpBaQLZRw5t2zdtmozlDTQfAdiADIFdNuIGQMAgOl1koHUWJNbQoAXPvn153DXFw93+tQ0G8DAGYC5dAFDkSAMpY1BUgxLV2cBALClOjbyAJwS0PSi+eV2LhTSAwgFfbhqKoGXLqzY3H7Zdlgy3OZUMHkOQ00qgQH3qWCNJCAA2DNpTwV1zgJQSYQDVizCiayglR7ARkpABWkAHH/bL/7jKfzcAz+2dskZRxZQ1OhMHcDphSwmEyFEDD+2ib/HegWCVQ/ALQbw3Nlla5PUiFPzWRy9WJ/KrOk9BtIATCRCtmMyNz5brNgMgOoBuAWBgXoJSHoAzoVCegChgA9Xb04iV6pYUgBgfjHjigeQCAUQ8BEWhAT0lUNn8GffP97wumTwtbUEVGt9ITF7Abk3JbtsPIbjsxkrZtDIA5DHGnoAYuHZJna8GyoBiffC6QFcWM6hWKlaMl66WIbh91mbhYjh70griNMLWewQsZCtYp7y2XU3AH5XCehDn30C//WxY01fI5UvYS5d0MNk+oCBMwDnlvOYdBgA+UVwegABER8A3IPAgIsBWHSXgPLlCoyAOXXrqqkEAHsmkNl0rPY7iAjDUQNL2SIe+O4x/O5Xn2naOtirBFTzAGrn7NYKQrJnMo50oYwZsSuUhiPuYgCc85VVZIbVcNTswLqRBkBq/04DIAPuR2fM3W3W8Z7ISuC1BmzPKAYgFgpgJBq0PMduky5UrFhTImRPCU4XyljMllp6ACv5MkqVjc3k0nSGgTIA+VIFL5xL4bqt9l4FCZEZkxX9+FXiSgDQjeForSU0UHPl3TwA2T1z72QCPgKeV+IAaUcMADD7Af3N0+fxnx59yQxANpEfUrkSjICvoaGyrtUlXbPs0gxOssfRFK42EL6RB9DcAEQNP8ZixroFPd1o5AHI3kvHxLU64zLyM6AG0NulUK7gfCpvZUMBwNZ1TAVVrykeCqBQrqIkutPKpnStZEf5GdjI91DTGQbKADx7dhnFShU37ByxHbckoIJdAgIUA9BEAqpUGZliBblixdK2nTGAQrlqLc4Rw4/to1Fbdo1TAgLMTKB0oYwP3rQDv3zzjqaNyFL55q2g1WsF7B5AqUElMFDLBHpFdDCtSUBuMYBgw0KwjNVnyY+xeGiDs4DcPQC58FkGoGiPy8jPxlriAGcXzTbQOxQDsG04uq4xAKvSXXwWpCxkGYBc4/emWmVLNpKT9TS9y0AZgIMnFwCgzgDI6thsqWzLAgLsKYBuqO0g1F1cfRZQxdY/f9dYzNYW2rnbBIBffv1O/N67rsLvv+9axMTcgka941O5+tx8N6yhMGIhr1YZ5WpjD2BzMoyY4ceRs8u25zWOATRKA5WN1QIYjRldMQDLuRL+/AfH8dPTi00fJ98b50633gOwS0C1qWCrTwW1UkDHHB7AYm5dNPV0oVbEF3MkBHjxADIiDRioFVVqepeOTQTrBQ6fXMRlEzGMxZ1B4KCVh9/IA2gWAwDMfH1VO60zAIoHAAC7x2M4dHLBmriVdvEA1I6hcteWLZZdd9/mLIDWHkA8bP/Sl6qmp9LIABARbrt2Cl//6Vn89q1XYCVfgt9HrgYxKf6OlSrXTbqS8lVESEA/Pb3U8ly9spIv4X/86CT+7AfHkcqX8d5XTeG/fGDE9bHM3FACkgvfqYWsOSCoaH9Pwh0YCnNGqQGQbBuJIFeqYCFTrPtsdhpzvoF5TQnHjOiLKfPz68yOUlEN/FyLWIHm0mdgPIBqlXH49CL276xfGOTOeTFbalsCSrp4AJOJUJ1MkHd4ALvHY8gUK5gV2RSZon236UT+/kYykFcJKOj3IRL0WxJQqWJu59zqACT3/uxeVKqMB757zGoD4TYC063GQJItVOD3mVPExuJGR/sB/dJ/fxx/+A8v46bLxrB9NNJ0zGFRmcam9nAqlqtIF8rYMxFDpco4OZe1ySVAzQPIFVcfAzi9kEUo4LMlIliZQOsQB0gXanEupwR0Ydn0AFYKZSsu4MRmALQH0PMMjAE4PpfGUraE/Tvr+66ruzynBCS/JA2DwBGzYCuVK2F6MYeAj7BjNNrSA9g1bmrrJ2YzKAhpxykBqURbGAAvraAlyUjA0urleEq3SmDJjrEofvF12/HwwdN48ULKVf4BlIZwLtkhGZFhRUQYjYVQqbLnRnfNWM6W8Pz5FD566xX4s1/Zj63DEauAyw01NqN6AFL3ft0u8/NxbCaNTKFiNQYEOhMDkCmgqgG1isHWIQ5gxppqI0+B2ozomZXaZLJGGT7qe9YqW0hz6TMwBuDgSVMX3r+r3gNQJZWGHkAjCSiqeACLOWwZjiAaCtR1jazzAMZMA3ByPlPXCdSNmgFw3922mgesklDSNeWOuJEEJPm/33Y5iAgHTy7WzQKQyHGUbnEANcA+FjONZieKwV6ZM/X6a7YkAZhSWaaJRl9QFm+bARCyx2t3joBIGACnBNSRGEDOJv8AsIrB2qkF+MnpRXzki4fbniesejWWx5a3ewBA4ziA9Bx9pD2AfsCTASCi24joJSI6RkT3udz/ESJ6loieIqIfEtE+cTxIRF8Q971ARL+nPOek8pxDnbskdw6dXMRYzMBusfNWUXe00QZpoGHD/U/lDAJvHY64do10egBbRyII+gknhNQAwCY3OJGeiVshEjMjlS83nQesogZrvUhAADA1FMEHb9phPd/9dRs3hMuWKtb1jcWFAejAZDBZtLVn0kxXjYUCTSUg1QNYUgyAHL4zNRTGtpEIjs6sIFOwJwXITcBqYwDVKuPkXMYWAAbMz1AiFGhLAnri+AK+eeSC515REjXdOOYSAxgX781yg0wg+bnZNhLVQeA+oKUBICI/gAcAvAvAPgDvlwu8wkPMfB0zXw/gMwDuF8f/KYAQM18H4AYAv05Eu5TnvZWZr2fm/Wu7jNYcPrUgdnf1Uoda1BQNthcEjhl++H2EpWwJ04tZbB2JmD1jys1jAH4hFZ2YS9eNg3RD7p7dJjhlihVUquxZAlLTNUsip71RJbDKb7xlDyJBf0NPo9lQmGyhbMkpozHZ52jtC8grs2kE/YTtQkaJhfxNp1zJIrBEKGDzAGQR2EjUwOUTcbxwPoVShS25BFi7BHR2KYdcqYIrNiXq7ts6ErHNCW6FNELtzChmZlu6sfw/nS+jWmXMrOStc2vkAcj6kcsmYpjTaaA9jxcP4EYAx5j5ODMXATwM4A71AcystraMAZB+KQOIEVEAQARAEUB7g247wOxKASfns3idi/wD2IuanIvwu67bjN962+VWxoQTIsJQJIi5dAEzKwVsG4kgEqxvGVAoV20GADADwWaw0T560A0ZBM65yA8pqw+QxxiAzQPwJgEBwGQijM/+6n587B1XuN6faDIUJlMsIxoUHoBoxNcJCej4bBo7x2LWSMuY4c0DmEyGHBKQeS7D0SD2bkrguEjRtRWCGWsLAsv00r2T9XObr9ycwNPTy54D47IYrR0DkCtVUOXaNUmPzKwALqJUYVy5ubkBkN7d7vEY5jOFDR3so1k7XgzAVgBnlNvT4pgNIrqbiF6B6QH8ljj8VQAZAOcBnAbwB8y8IO5jAH9PRIeJ6K5Gv5yI7iKiQ0R0aHZ21sPp1nP4lMz/dx+8bY8B2BfhyycT+Ng7rnT1HCTDkSBevLACZjOjw+wa6TQAlTovYvd4DCfnM9aXqnkQWKaB1n/hlz22gZCYMQB7FlDA5y0c9IY947hqc9L1vmQTDyBXrNR5AJ2QgF6ZzeAyRdaLhQLIFhu3a5Ce2eahMIrlqvU+OT0AmeuuynJrjQHIFhOXuxiAN+2dwFy6gOddxoW6XoflAXg/l1qsybwOn4+smQAXRA3AVcIALDaQllbyZQR8hG0jUd0Oog/oWBCYmR9g5j0APgHgk+LwjQAqALYA2A3g40R0mbjvjcz8WpjS0t1E9KYGr/sgM+9n5v0TExOrOrdDJxdhBHy4dqv7wmXPAmreSsGNpDAAAGoSUF0QuN4D2DUeQ6FctbptNgsCx5pkAa3GA0g5PADDgwTUimYxgEyxFgMwAr6O9AMqV6o4NZ+x9H+g5sE1apshF85NCXMoulzAlrJFGH4foobf8XqdiwEcvZjGeDxkDftRueWKcQDA94962+RIKasdD8DN04yF/Ejny5gRNQCXT8bho8ZZQOY40IDVUFEHgnsbLwbgLIDtyu1t4lgjHgbwPvHzBwB8k5lLzDwD4EcA9gMAM58V/88A+DpMY9EVDp1axKu3DVnDVpxEhY5v/tx+bdxQJIiicMm3j0QRCfpRrNirdl09AJEJ9NxZc9fnRQJy2/F57QQqSYrzzZcqbUlArTACPoQaDBrPFsq2WoqxmLFmCWh6MYdShes8AAANZSBpmCeS5gImpY7FbBHD0SCIyLZDV9NAjYA59Ga1MYBjs2lX+Qcw5bV9U0l87yWPBqDUvgTkHHADoM4D2DwUwVAk2EQCKiMZCVojVXUguLfx8q0/CGAvEe0mIgPAnQAOqA8gor3KzfcAOCp+Pg3gbeIxMQA3A3iRiGJElFCOvwPAc2u5kGbcdu1m/OL+7Q3vJyJr970aD0DuvH1kSguyg6jcKcrq07oYwIQ0AGabhbiHLKDmEpD3LCDA/DJ7TQP1SqN+QGYWkGIA4qE1D4WRntNlE8qO3WhuAOTO2ekBLGZL1hS2oUjQ2uE6vTJzKlj7BoCZcexiGns3uRsAAHjzlRM4fGqxYUttlXx5LRKQYgDCQawUylYbiMmE6aEsNaoDyEkPwPxb6VqA3qblt56ZywDuAfAogBcAfIWZjxDRp4nodvGwe4joCBE9BeBjAD4sjj8AIE5ER2Aaks8z8zMANgH4IRE9DeBJAN9g5m928sJUPvLmPfinTQwAUPtSRJtk4jRCGoBNybBZaetoGSAX2ZDDA9iUMI3FiXkZcGz8u/0+ghHwuaaBtisBqQ3hZAygUwbALDJrUAegTjzrQD8gKwV0ws0DaCQBme/FpmS9BDQcrf395E7duSEIG/XxHS9cTBWwUig39AAA4M1XTKBcZfz4lfmWr9cpDyAh0mYvpvIYjxsI+n3CA2gcA0iEgtZM7bkOxHE0G4enLSMzPwLgEcexTyk/39vgeWmYqaDO48cBvLqtM+0yclFcjQQkFw457EQOlZdSQV4ZBqPi8xF2jcXw4oUVhAI+K5OlETHDffeZajKlyw1ZyJXKl61K4EbdQNsl4TIToFSpolip2lJsx2IGnjqztKbf9cpsGmMxw6apx6x02UYSkAwCmwuY6gFcrngSl0/G8eNX5us8gOgqh8LUAsD1KaCS1+4YQczw4/svz+Kd12xu+nrSA2iW8eTEGQQ2fw5gdqWAi6mCZRSHo8GGAfqVfBk7x6IYigQR9FNDDyBfquD8ct617kZz6TAwlcCtkPp5o4rfZsidt+zpUmsaZi6uUnZwqyWQX5BmAWBJtEGV63KuhEQoUNeArREyW8j0ADorASXDgbpWENYsAIcHsJhp3g9oKVvEO/7oew0NxfHZjDWvQNI6BmCey6RLEHgkVjOg128fRjjow0jMHrCNBFc3FvLoRZEC2kQCMgI+vOHycXzv5dmWnUHlZ6sdY+QeBBYxgOW8ZQBGokbDltBmENiMlYzHQw2DwA89cRrv/uMfWLExzaWJNgCCeDiAcNDneRFVkQvqVssDsMcACg08AKDWE6hZAFjSaCRhKlf2nAIKOGMAHZaAwvWD4aVO7YwBlFv0A3rubAovX0zja4enXe8/Ppe25hVIpIzWqBhM5s+Px0Mgke3CzFjKlmyexM+9Zit+9Im31QXWw6uMARydSWMkGrTaYDTizVdMYHoxZ9UhNMLKAmrDGLlKQGKM58xKzQC0CgLLz89EorEBuJjKI1eqrKlthqb7aAMgSIQDTVsxNEN6ALKnizMGULAGwrt4AGPeDUC0gQS0LAJzXrHFAMSC2KoVRDuv7ZSA5M5TzQKSQdaZJkFEGRv57kszdTvi5WwJc+miiwFoEQQuVUAEhIM+sxo4W0S6UEa5yhhRYgBE5NqaOeJS4+GFYzMr2DuZaFpPApgGAEDLbCDpAWRXIQGpn3OZBTSXLmKTyIwajpoyXtnREbRaZaSLtbkT4/FQQwlI/q7VGMtLhWqV8ZjLZ6+f0AZA8L7rt+L/euPuVT13y5C585dyhJR6nDGAsIsHIDOB4h6Cz430Z6+toCXSW0jlam1/vbSC8IKbAZDnrC48XoahnxS74OnFnFVFK5FN4JwSULRFFlBeVGTLmcvLuZK123XLz3cSNdqXgJgZR2fSuLyJ/CPZPhrFZROxlvUAq6sDKNtSngHT85Uq3GYZA4jUYkQqaTEMRn5+xuONR3v2gwH43suz+NXPH8SRc+vevGDd0AZA8NarJnH3Wy9f1XOv2zaEv7v3Fty426w0rhUM2WMAbh7ArrY8APcYQMrjMBhJ3AiASHgA1fYqgVuRCAeRU+oLAGUcpGLktlktkBv3vzk1n7GyTb770oztPjmj+DJnDEAGgRtmAdXqMYYi5jxnWfU64sEAhFcRBJ7PFLHkCDI341Vbh6wU10bkV5MFVKyfOqfGnmpBYPPv4KwGlrEdVQKaT7vHcWSH0V6WgOT0tlYzknsZbQA6xNVTtSpjWQeQc8QA3DyA8biBeCiwxhiA91kAgGgBYJjpmp2WgNzaQWStecC1a5yIh2D4fZhu0gHzxFwG+3eO4KrNCXznRbsBOD6XsTWBkwT8PoSDvqZZQDJLq2YAZBuI1n9Dtz5PrfASAFYZigSbTuUCVtsKolKXbKDenhQSkGxx7lz4nPOgx0Ucx61mYKUPPIDzoj12s/bivY42AF1A7jBlS+h8Ew+AiPDRt1+Bf3LDtpavG20QgEzly21JQIDpxqfULKCOSUD17SCs7BMlBuDzEbYMhxtKQJUq48xCDrvGY3jrVZM4dHLRFjB2NoFTadYQrlCuIiQMtDQAtUZwrT2A1WQBHRMpoHubpICqDEUNrIjRmo2QwexmnU+dmHOn3bvdAjUJSHpCzpbQznnQzdpByL//alJmLxUuLJufzV6+hlZoA9AFLANQdngAQfc/96+9cTfeeuVky9c1G53ZF7ZyxRxl6LUKWCK1+k6ngbq1hM65pIECYhh6Aw/g3FIOxUoVu8ejeOuVkyhXGT88Omfd/8psxlYAptJsJoDqASSlB5CRElBrI7qaGMDRmTQSoYAVZG3FUCQIZveeSoAZnJTple0sTmnHiEug1go96Cdr4ZcxgHoPwF5vIuU5t0BwP8QAzmkPQLMaarNjHR5Ag15Enl/XJQtILrTtegAy/a9odQPtrAeg1gJYMQCHB7R1ONLQAzghAsC7xmJ47Y5hJMMBSwb60bE5nJzLuHbVBMxFutHOOF+qWobYKQF5+RvKRn/ttEE+etEMALfKAJKoQ4bcUOcatyUB5csNJaDJRBg+8RkYbikB1bKAAHcPQMYAennxlBPStAegaYuwMwjcwgPwSjToR1nZ/QG1KuB2YgBArWK3XKki6CfPi1MrpCeSssUApAfgNABRzKwUXNMqT4oU0F3jpszzpism8NhLs/jLQ2fw4c89iT0TcXz49btczyHewgOQUtxwNIhShXF+OYdkONCyEhtQUnzL3heFozONm8C50coAqH+vTgWBVe/ELPRCnbZf8wDsEpCbB7DSQxLQSr6EHziyrpjZMgC97MW0QhuALuD3EQy/T0kD7ZwHANi/VO3OApCYLaHNGECn5B/zdetjANmi2UPeGWiWhXPnlVm0khNzGUQNPybFIvO2qyYxly7gd776DG66bBR/+Ruvx6TQrJ1EQ4HGHoAymlMutCfns3UVv42IurwHkpNzmTrdvlypYi5dwJbhSN3jGzEcbWUAZAtvX9tpoHUGQCzmm4dqf0u/j5AM1/cDcnadTYYDMPy+uo6gxXLV2qT0wuL5vw6ewYc++yRmVmqfw/lM0fK0etmLaYU2AF0iHPQphWCd8QDklzdbqn0gU7nVSkBBEQPgjhoAtxhAplBBxPDXeRkyFdRNBjo5l8HOsZj1nDdfMYHhaBC/8Npt+Pyv3tjU44mH/E0LwWRFtmUA5jKeAsBAfY2H5NxSDj97//fwjWfP247LXbSXFFPJUAMNXiLTikejRtvdQJ31JqoEpDISra8GXsmXYfh91t/PbAdh1I2GVP/2bhPsLjXkKE7ZXBCoyT9Ab3gxq2V1pa+alqhTwQodSrWMuuS4WxLQKoPAhXJnPQC5oKQcHoBblbVVDLZUXwtwcj6Lq6dqWTNj8RAO/stbPZ1r1Ag0rJAtuHgAMysF7NviPizIiTO+I3n6zBIqVa6ra6gVmXk30K0lIPPzNBIzcCGVR7FcheGSYqxSrlSRL1XrPIBQwIc7X7e9rvnckEtL6JQYBqMacrd2EOlCvfx3KSODvSfmMrj5sjEAdq+0F65htWgD0CUiStvgfKmCgI88acxNX9Nl8VlusxW0JBkJoiJ68Rgd6gQKmHn4McPvqAOouLbZ3jwUho/qPYBypYozC1m861r7ouTVUMn2Bm6YWUB2DwDwvkOPNPAAZLWoc9e81EaRmaSVAbA8ANG8LlestDQAUhJzBoGJCP/hF15V9/hhl5bQah8gyXg8VCfh2by/Hlg8LygGQHJepIAORYI9XczWCi0BdYlwoJYuqO4610JtKIwqAa02CGy+1kK6uGbDVP/aQUcMoOI6aCfo92FzMoxphwE4u5RDucpWo7x2iYXMbCm3Hi7OSmCJ1x26fJwcoSg5cs4c6uOccaDOGvZKOOiHEfDVdVWVWB6AeE1VEmyEWyO4ZgxHg65BYGfL8bG4gflMYw+gFyQgudirEtD55bxZaDga6WsPQBuALmEODjG/qHlFd14LUZd5t4vZEoJ+anuSmfwiL2SKHZsFUHvtgCMGUG44Z2HrSKSuGljuxFbbSz5qBFCusiW9qRTKtclsQ9H2PYBrtgwh4CMcPr1oO17zAJwGQBaZtWegh5t05JSe5agIXHtZoKRhGvboKQ5HglZ9hMTNAxgR/ZRUMj0kARXKFWuojcw8A2C1x44ZAWQbtBXpBzytSkR0GxG9RETHiOg+l/s/QkTPEtFTRPRDItonjgeJ6AvivheI6Pe8vmavEw74uuABCAOgfCAXM0WMRI220zjlF3k+U+xoDACoVRlLco5xkCrbRqJ1EpBsArdzLLqq3x9v0BHUHM1Z8wDiRgCy/MFLERhgSnvXbB3C4ZM1AzC7UrC6mjo9gKVVGgBZo+CGNGyWB+BhgZKxie2j3v6mQ1EDqby9GlkOhLc/Loh8qWpLTZUpoMlwYNXzkztFsVxtGsSV8s94PIRT87UsrnNLOUwNhc3iSw8eluSbz13AuSbtTS41Wn7zicgPc7TjuwDsA/B+ucArPMTM1zHz9QA+A+B+cfyfAggx83UAbgDw60S0y+Nr9jQRw4+CEgPoiAcQrJeA5jNFayfYDlIyWswWW+rH7dKWBzAcwYVU3tZ6+OR8FjHDbw0ebxfLUDq++KUKo8q1bCyfj6z0Wa9ZQADwup0jeGp6ydLipfwzkQi5xABKCPjI08AflWYGoN4DaL1AnZo3DcAOj0ZVGkRVhjI9ALshG46Y56BetywCm0yG25pY1g1+/xvP40OffaLh/TJ+8YY9YyhV2NqMXEjlMTUUcS2+bES5UsVvfukwvvTEqbWf+Drh5Zt/I4BjzHycmYsAHgZwh/oAZlb7pcYAyG0DA4gRUQBABEARQMrLa/Y6zhiAWx+gdrHqAJRd1UKmgLH4agyAuSBVqp1NAwXqx0I2igEApgRUqTIuKsVEJ+Yy2DUeW3VxmlxsnYHgvMtkNhkHaEej379rFMVyFc+dNRd+Kf/8zJ4xLNRJQOagmXavxZMH0IYEdHohi+Fo0HOsyKoGdhgA5/NHrMfVrjtdMJ8zmQhtuAR0Yi6DF86nGvb0l/r/G/aY2T/H59JgZpxfzmNqKGz23/IoAS3nSqhyb3UP9fLN3wrgjHJ7WhyzQUR3E9ErMD2A3xKHvwogA+A8gNMA/oCZF7y+Zi8T6UIMQDbyUr9UC5kiRmPt75TVnVyn2kBIxuMGLizXdvXZYqVh8FGmgk4v1NInT85nVh0ABmo9h5w7Y6sgz8UAtCPR3LBzBABwSMhAz59LYcdoFDtGo1jOlWyyyVK26FleUhmKevAAou0ZgB0e5R9A3dmbC3ulykgX6mMAbp1D02LBHIuHNlwCWsqWkClWrHoZJ+eWpAcwDsCUHxcyRRTLVWyWEpDHQLZ8v5zzMC5lOrb1Y+YHmHkPgE8A+KQ4fCOACoAtAHYD+DgRXdbO6xLRXUR0iIgOzc42H5JxKREOOmMAa/9TyyZmao77QqbYcsygG2rdQKcloOu3DyNXquDFC2YXzGyxbJsGpiKrgWVTuFKliunFnDUpbTXIYqe0Y+fmNprT8gDa+BtOJELYPR7DQWEAjpxbxr6pJEZiBpjt6ZuL2WLb+r88r9YegPm6XipV2zUAzoU97egDJGkkAcVDAcRDgQ33AOTfsFHTwQvLeQxFgtg+GkEiFMCJuYwlC7UrAdUMQH95AGcBbFdubxPHGvEwgPeJnz8A4JvMXGLmGQA/ArC/nddk5geZeT8z75+YmPBwupcG4aDfagdtZp6sXQLy+QgRpSV0qVJFKl9uS76QRIK1yVCdloD27zIH4xw6uYBiuYpShRsGgZ2Twc4sZFFZQwoooKTLOiSgQlMJqL1Fev/OERw+tYBUvoST81lcsyVpafJqINg5a9grQ5GgOaqyUp/J5IwBtKpULVeqOLuYa9MDsEs7jXpO1RrH2SWgeChgjjDd4BiAPC8p9Tg5v2wGe4kIuydiOD6XsQLDU0NhxIz6/lsNf1efegAHAewlot1EZAC4E8AB9QFEtFe5+R4AR8XPpwG8TTwmBuBmAC96ec1eJxz0K+2gOyMBAWIusFgAZJre6CpiAERk7eY6nQa6dTiCqaEwDp1adB0GoxIO+jEeD1k7tC8+fgpEwGt2DK/69zeMAbgM5hmOBmEEfFaBl1f27xrBYraEbzxjtn64ZmvSWujVxXBxtRJQg7GMQG2u8YhHCej8ch7lKrdlAEai9p29sxOoxC1WkBZzB+RndaNm6pqFjuZ5N8rMObeUt/o07R6P4eR8xjIWU0NhRMTn1ks7iFQ/GgBmLgO4B8CjAF4A8BVmPkJEnyai28XD7iGiI0T0FICPAfiwOP4AgDgRHYG56H+emZ9p9JqdvLCNJhL0o1RhlCvVjqWBAmYtgPwwzgsDsBoJCIBiADpfDnLDzhEcPrVY6wTapE5BzgV4+eIK/uIfT+EDN+6om/XbDo2ygOTOWX0vfvnmnfh377u27SCt9HK+8OOTAMz6AKnJOz2A1XhozRrCyVoGc7Zx6ywgOdrQawYQUGsuWDMA9lkAkkjQD8Pvs0lAK/ky4uEgIoYfzHCtx1gP1Aymcy4NBwHTA5CN8HaNxTC9mMOp+SwCPsJ4PFRrv+JBZutFCchTbhozPwLgEcexTyk/39vgeWmYqaCeXrOfkJp/vlztWBAYMFNBZWqd5QGs0gCY7nyuKwZg/84R/O0z53FUzO51DoNR2TYcwfPnU/g3f3ME8VAAH3/HlWv63bEWHoD6Xly1OYmrNnvrA6Ry2XgMozEDL15YwXjcwGQiZMkEcjHMFSsolKurloDM1yrCTKxTr6OCUMBsrhcz7Dp7vlTBXx46g/ffuMOq8LYMQBsegNkRNFAX2HR6AEQkAtY1o5cplJEIBaz+T9lipWMboHZQjaebB5AvVbCYLWGLMACXTcTADDxxYgGbkuZ8hEabCdffl+1DD0CzOtS+PZ30ACLKRKr5NRqAbklAQG2H/IOXzcB9oxgAYHoAJ+Yy+NGxeXz8HVes+nokoYAPAR/V5aC7xQBWCxFZ2UD7tgyBiGoxACEBrbYKGGjeD0hNKjCDlLXrfOylGfyrvz6CHyjT004vZBH0E6aGvLekBszPlTQeKwX7LAAVZ+dQs+towAr8r0cvna8dnsa3X7hoO7bUwgCowV6gVnn+3LllTAmj4NZ+pRHy96WL5bYGBm0k2gB0idpQmEpnPQAlK2FhzQbAXGS64QFctTmBqOHH98WgjUZZQECtLfRVmxP4wI071vy7icj2d5JYMYAOGePX7TINwDWik2jUMOWQRYcBWEsMwM0ASA8AMA2rep2yIvnJkwvWsdPzWWwbiVpBf6+885rNeOylGZxZyFq7Wre5E8MRw7pWQGQBhQNt7Z7Xyp9+7xV87kcnbMdkLGbnWNRK91Q5v1TT+gFYiQfMwJSIC8Ta8QDEe8VsGoFeQBuALqEagI7GABSXfz5TtAUD2yXZRQMQ8Pvwmh3DePmiKQG5tYOW7JtKwu8j/L+3X9OxxnRuHUFrMYDO/I7XX2bmjr9m+zAA0/CMxGo9dGqtoFcjAZnPcWsIp461jBgBW3tw2dfm4AnFACxkPbeAUPnwG3aBiPCFH5+0zsPNAxhyeAArwgNoZQBOzmVwy2e+Y/XjXwupXAnzaXsRnlyQr96cxIVUvm5Yj+UBiMU+GQ5aYy6lUXAbwtSIZUfRXC+gDUCXkBJQumD2U+mkByA7LC5kChiOBNve2Unkl7nTdQCSG3aOWj/HXNpBS/bvGsUz//odVi/2ThB1KeBxqwReC9dtG8I3f/sWvH3fJuvYSNTAQsZcCJZW0QlU0mwoTKFc09Rjhh85pVeN7M3/zPSyZfDMGoD25B8A2DIcwbuvm8L/OngG55fzMAI+13TmYaVmgZmRkRKQS+sSlSdOzOPMQg5PTy+1fW5OVvJlSxKVWAZgKolKletGV6rZPpLd46ah3Cymzcl4UjtBYPN8eiMQrA1Al5BfUKkLds4DqA08X8yU1qSXy3YQna4EluwXGjkAK52uEV7bFHslFgp4KgRbK1dtTtoyiEaihiU9rEUCkqmp7hJQraOps1BpTixyxUoVz0wvYzlbwnKuhJ2jq6ur+LU37sZKoYyv//Ss9XlxMqx4ALlSBVU2R01Ko99o93xUeIfnXeSZdihVqsiVKljIFG3auzwnOVjIWQx2bjmP0Zhh+27KOMCWYeEBBNsLAsvHaw9gwIkY5p9WZgaEOiQ7RI2AkgZaWJMB6GYMADBz+aVtaRYE7gYxlyKkTnsAbozGDCsILA3B0CoMANC4Glj1AMxiK1UCKmDflBmTOHhywQrirkYCAsyq7v07R5AtVupSQCXDUQM5EeuSFcOqBNRoKMzLIkPsXIMiLa/I31mpsu3vtZQ1C9Jk+qszEHxhOW/t9CW7x830480iMFzrwOvNA5DxLO0BDDjSVZaLQGeDwGUws+gDtAYPINJdCSgRDuLKzTJAur7D52KuMYDOewBO1N3wYraEqOFfdRV4IwOgegAxw96ueD5TxOWTcVyxKW4zAO2kgDr5Z7fsBuCu/wP2mgXZCjoRDihFVO6L57GLZquQtXoA6m5bHU6zlCtiKBK0Cr2c1cDnlnLWTl/ylisncOOuUeydNA1BbQ633YjNpwt1BW7LuZJlaLUHMODI4FGnJaCI4UdVFNesthGcpOYBdEcCAoCbdo+a2TFdXHTdcGbHALWK7NV2GfXCaMyUgKpVFlXAqzfQQy5TuQDTk5EN7SJOD2DF7A67f9coDp9ctIactFME5uTt+zZj51gUkwn3z5raD8iaPGYEEG0in6zkS1Zx1lo9AHX2xJwSCE7lShiKmB1Q46FAXSaQ2fHTHhu5eiqJr3zk9dbCL4vtcrZMqzxu/vffxndenLGOFcoV5EoVbBcegFsF96WIngncJawYgJSAOugBAGaxzWK2tOoqYKC7lcCSj956BX7uNevf6DUWCtTVAajDYLrFcNRAlc1FyewDtDr5BzA9ALcMmUKpajUGjCkN13LFCjLFCsbjIWwdjuChJ07j749cwFjMaHsegYrfR3j4rpvhb2A41X5AMtMmHg7UJti5GIBjQv4ZjxuuKZrtoBoANRNI/ftvGQ7bJKBssYzlXMmqAm6ELLZTM63OLuZQqjCOzqTxs1ebCQDSU9s2Ij0ALQENNDIYJD8YnZgHANTSKWVaWztdLJ3INNBOzwRWGYoG8WqRJrmexEKBuswNdRxkt5CD2hcyRdEKeg0eQJMYgIwpRYJmYWC1ylYG0EQ8hNftNjOwnp5eXrX+rzI1FMFk0n2xtDKWFAkoHgrA8Pvg95FrFpCsEH/T3gnMpQtWkd5qaCwBqQYgYvM0ZAqoUwJyI+LItJLB/YupmuGSabKTyRCCftIS0KAj87QXOxwDkNKSHKS+Fg9AFvUYXZSANoqYEUC+VLV101wvDwAw9f9OeACuBsDmAdSGBEkDMJ4wsHU4YrU4WIv+7wUrBpAt2dpGE5E5UMXFAzh6cQWhgA83CkN1cblQ9xivqIvtnMMDkMZpaihiizXIn71UR0cNv80DkGm+M6naOcv3aSgSFAORtAcw0IQDdgmok2mgACxpYC1B4F1jUXzitqtw69WbWj+4x5ALY8bWJ6czcxmaIRvCLWaKq54FIBmOBJEtVupaEedVD0DptyMXP1nMJL2A1c5W9nyeltErWoF3KTlFDL9rGujRmTT2TMQtyaRRv34vyN130E+YF0aQmUUMwDy3rcNhzGeKVm2E9Aa2eDIA9n5LstBP9QDUoj/nSNRLGW0AuoTPRzACPuvD2S0PYC0GgIjwG2/Zg7FVzt69lIm5TAXLl7vvAcj3Yz5TwHJudZ1AJUMuHUErVUapwtYGoxZoLVsegHw/Xyf6MXVCAmpGzPAj4CMs5UqWAZB/f7eWHIBZA7B3UxxTQoJp1K/fC3Kx3T4StWIAuVIFxUrVMsBypy/jACfmzOD4ZLL1Zz/aSAJaqRkAuwegDYAGpj7b6SwgGQOwJKBVzAIYBKwKTiUQXCh1PwYgF5xT81lUeXVtICRu/YBqDe1EGqgSaJVFYFIWfOtVk7hiU9wyBN2CiDAcNbCUNQ1A0E/W39m5ewbM9+TsUg57J+PWDvx8g3bNXljJm+m2k8mQ1R/L2pFHajEA+XtyxQq+cvAMbtk77ul76ZSAajGAWiqozQCEekcC0llAXSQS9GNG7BI6nQUkXea17DD7mZiVLaVIQOXKmrJhvBAPBRD0k7XDXE0VsCTpYgCctQwRpVvlXLqARDhgLWpbhyP4+4++edW/vx2GRUvogI8QDwWsVFtZt6IiM4D2bkogYvgxEg02HNjihZW8Oat4LB7CC+dTAOwLMqBMnlvK4ejFFcxnirjnrZd7ev2o4bfp/dLIFMtVLOfMiW/y9yXDASTCAav+4lJHewBdJBz0QVamd2IkJKBIQAtZxAz/hvRZ7wXcPACzgKq7fy+5G64ZgNUbaLl7Tbl6ALVeQIDwADJFTGyQnDccCVoeQFwpGHObqfuyKACTxVZTQ5E1GYBUvoREOIjxmGFJQNIDkDLapiHz73J6PosHv38c+3eOWAHoVkQdxXaLmdr7cVEYhqVsCYlQAAG/TwSBtQQ08KiLc6eCj7KidqVQXtUoyEFBSmVqELhQqnQ9CAyYgWBpAFbbBgJQ0ytrmS2WB6DMAwBMT0cWgW0Ew9EgFoUBUDu/Rl2CwMdm0jACPis7actwpKEEVK0ynlUa27mxki8jKTyA5VxJ7MzFLAYRBA4F/JhIhPClJ07h3HIed7/tcs8Fgc52GwvZohVol4HgVK5keWyJcMBWm7BW8qX6RIBO4enbQES3EdFLRHSMiO5zuf8jRPQsET1FRD8kon3i+AfFMfmvSkTXi/seE68p75vs6JVdAqgGoFM7T3W04lqqgPsdKwvI5gGsz2Sq4WjQGoO41joAoNZPClBaWssgsGy3UDIloPEN8gCGIgaWs0WkhRwjcbaqAMwMoMvGY1b9ibNICzCDtf/5Wy/jls98F//Hf/kh/ufjpxr+7hXhAUjjt5gtKlk5NQO8ZSiMxWwJ+6aSeMsVE56vzRnIXsoWrQZz0gAs52opp8mw2YakU0NhvnLoDG78/75lycmdpKUBICI/zNm+7wKwD8D75QKv8BAzX8fM1wP4DID7AYCZv8TM14vjHwJwgpmfUp73QXk/M8+gz5DFYD7qXLuFUMBnNVgbXcPust9xa+O7HoVggD0zqzMxAPs1AA0koHRxwwzAsGhbIaeBSZytKgBTAtq7KWHdnhqKIJUvWxlEMyt5vOOPvo8//vZRXDYRQ9Tw49R8Y03digGIDdFculAXAwBqgeC73+p99w+IBoyi2M5s8VHCleL85QAetegsEQ6C2VsLaS/81U/OYnMyjMlE66K1dvHybbgRwDFmPs7MRQAPA7hDfQAzp5SbMQBupu/94rkDg5Qb5PzWTmBOuzK/YNoDaIx7DGB9PABZne2jWrX1agj6fYiHAo4gsLmYqu2gAXMHupwrbZgBGImaNQsLmSLiyjU7d8/ZYhnTizlcIfR/oFaNKyd0fe+lWaQLZXzl11+PL/7aTdg+ErXl3DuxYgDCA5hPF7GUKyHoJ5vHfMveCdyydxy3Xbu5rWuTr5ErVbCSN+d7bB4KYygSdPUApAfUKg5QrTL+5ulz+L4Ym+rGibkMnjqzhJ9/bXfaqXhJidgK4IxyexrATc4HEdHdAD4GwADwNpfX+SU4DAeAzxNRBcDXAPw+O9vr9Tjyy9lp3Tli+JEulHUKaBNkfnzalgXU/UIwoLbrH4oE4VvjrIWhSNAWA5AeQChol4DOLGxsWvCQkLoupPIOD6C2e/b5CK/MmLGRvZtUAyBy9Jfz2Lspge+9PIuJRMiaJzGZDLUwAGYMQK3BMKuADdvG6wM37cAHbmp/5Kg62Ux6KaMxA5uU87IbAPP/Zgbg8ePz+P1vPI/nzqZw5aYE3tRAkvr6T8+CCLj91d0xAB37NjDzA8y8B8AnAHxSvY+IbgKQZebnlMMfZObrANwi/n3I7XWJ6C4iOkREh2ZnG1vKSxGp03Y680S6/Wsdnt7P+HxiLrD4wpYqVVSqtQKqbiJ1/06k6CYjQVsWkNMD8PvMnHtZGb5hEpBY/CpVRlyZ/iYXTzmL4ZVZMwV0z0TNAMiJXOeXcqhUGT88Noc37Z2wFu/NybCVbeOkUDYDpMlI0CqAm08XsZxbWxW2ijoY3hryEzOwSZwXszmHYCjq9ADqA8GVKuN3v/o07nzwcSyki7h6KtkwYMzM+N8/PYuf2TPesmndavFiAM4C2K7c3iaONeJhAO9zHLsTwJfVA8x8Vvy/AuAhmFJTHcz8IDPvZ+b9ExPeAzeXAuGueQBSAtIGoBlqQ7jaPOD1MwBryQCSDEXcJSD1OmKhAE4tmDvricTGZQFJ4qHaz86h6mdcBtRsSoZBZHoAz0wvYSlbwpuuGLfdP5su1M30BWq77EQ4gGTYrMGYSxdtO/K1onoAsg3EaFQagDzypSqK5WpLCahaZXzia8/gK4em8ZE378F3/sVbcPNlow09hZ+cXsTphSze18Vuul5WpoMA9hLRbiIyYC7mB9QHENFe5eZ7ABxV7vMB+EUo+j8RBYhoXPwcBPBeAKp30Bd0ywOQH8hRXQTWlJhSwVmTTtYvCNwJD2A4YjgqgWUQuHYdkaDfaqm8cR5A7VrtdQBi9yzehzOLWUwkQjYDFvT7MJkI4dxSDt9/eQ5Epl4v2TQURqXKVp8fFXVYPRFhLBbCfNqUgIY7ZQCUtiKyCGwkakpAMysFyytwSkDqzp6Z8a8PHMFXD0/jt2/di/vedRXCQT8S4aA1N9zJ1396FuGgr+2YRTu0jAEwc5mI7gHwKAA/gM8x8xEi+jSAQ8x8AMA9RHQrgBKARQAfVl7iTQDOMPNx5VgIwKNi8fcD+BaAP+vIFV1CyLGQnV50LAOgYwBNUaeCOdMnu4ncDXdCghiKBG2D4QuWBGSXWeQCspFZQJJEyF4HAMBKBZ1ezFljE1XMWoAcjs+m8aqtQzbvdpMYRHMhla9rSW15AMLrGIsbohV3CVduTqAT2DwASwIKYlPSNEyy5kMawaSLB/BH//Ayvvj4Kfz6my/DvT9b2y/Lx6YLZZvHUixX8bfPnMc79m3uavW6p1dm5kcAPOI49inl53ubPPcxADc7jmUA3NDOifYicrHp9KIjP5BraQU9CGwZjuC40JydBVTdpJMegFzQZBDVzQOQO9Rw0GfLellPVLnLWQkMKBLQYhav2T5S9/wtQxE8eXIB8+lCXYuGTWLRd4sDyEVWpsyOxUOYy3RPAlrImNlF8VDASst86YJZ2dwsCPylJ07j1qs34b7brrIFptV4gXq+j700g6VsCT/Xpewfia4E7iLyw995D0DHALxw9eYETsxlkBcDy4H1iQHI96UTGTkTiRDKVbaaCubdPABxTePxUFfHXTYjEQrALzKeYsqONWbNBa6gXKni/FIe20frPYCpoTBmVwqoMuoyYmQA1C0TSAZa5UI6HjNwcTmPdKFsk6XWghoElkN+iAibRCfRozN2AxAO+hDwkXVui5ki5jNF3LR7tO79aZQx9MSJBUSCftxy+Ti6iW4G10Vkql6nYwARww9D5IhrGnP1VBJVNndoZSGRrEchWCIcxH//0A1WGuNamBDyx+xKAaMxA/lSta6wUFY9b5T8A4geSJEg5jNF2+dSHWF6IZVHucrWDACVKZEKmggHcL1jgtxYzICPGhmAWhAYMI3uBfG4zmUBqR5Abcqb9Exevpi2/T4isrWElplPlyu1D5JGAeOlbAmjMaOr0/oAbQC6iqwE7rQH8N5XTWFTIrxhu71e4eqpJADghfMpq+/MejXPe+c1nQncyeZusysFXLk5gYKYaaC+9zLQupEGADBloPlM0dYKIqIUUclahe0uBmCrKAZ74+XjdYtewO/DRMK9FiBleQA1CUjScQNQMGMAI2LspzTOsrldUpFw1KlgsvupmvqqPg6oTxldVnoLdRNtALqINACdjgG8Yc843rCnu65hP7BjNIqY4ccL51PW4I9e655qeQBpc/HLu8w0kKmW4xucFCCzbtw8gGyxgulFMwXULQgs00Lf3KAgalMyjAsuMYBUvgyiWuBZjYt1agGNKlPXFjJFK7gc9PswHjcwly7azgFAnQcQCviw1eW6G3kA5jSz7i/POgbQRaxWEOsQeNTU4/MRrtycwAvnV6wg8HpUAncSVQICYHkAKhFj4yUgoDb8Rg0CR4O1xfPMYg5EtcpflX1TSXzuV/fjF27Y5vram5JhzDSIAcSNgFVxrf4NOpUGKovtsqUylrL2KW8yEOys+lYNwLGZNHaPx6wYiYo0Gm4eQKeC2M3orW9Dj9EtD0DjnaunknjhQspqSdxr70U8FEA46LMMgJsHEL3EPAC1HbSVBVQoY3oxi83JMAyXOAwR4W1XbUKwgea9KRmytH2VFUf3UTXwvpZpbE6ihh/pvFkJbEtRFZ6lc7FOhIOWPPXKbAZ7XPR/+TjA9GRUtAHoA0JdigFovHP1VBIr+TKOz5k6bK+9F0SEiURIMQD1HoCUKMYTG+sBbBmOYDxu2Ha6RsCHoJ+QLVUwvZBz1f+9sDkZxlK2VDcXIJUrWYso4IgBdHABjRoBXEzl68Z8ykBwvQEwPYB8qYIzi1lc7qL/A7WMoXSh3gCspZGgV3rr29BjWEHgdcg80bgjA8FPnVkC0HseAGAGgmfTUgKqWhsLSfQSkYA+8pY9+Kvf+Jm645GgORTmzGLWVf/3giwAm3HEAVbyZSQVrbwbMQDA/BvLOdyjsdrrTjYwAEkRBD4xlwEzGnoAtYyhmgRULFeRK1W0B9DrSL251wKP/cRVmxMgAp4+swygN98Lpwfg3FDIoOvEBnsA8VAAO8bqd/hRw+xndCGVx7bR1XsAAHDRMRRlpWD3AMJBP2KGH4lwwFVzXy1Rw+86h7uxBGRWocsMoEYegPlY+whJa5bBOsz70FlAXcQqBNMewIYRCwWwczSKk2KgSC++FxOJEJ48sQDA9ACcO9vbrt0MZuCy8dhGnF5LooYfx2bSYAa2r9IDkFLLBcfoyJV8GXsm7MvYWDwEdh1JsnqiRi2oa29T0VgCqjLwzPQSiIDdTd4bNWAM1FJbtQfQ40zEQ/i512zVKZsbjJSBDL9vzf35N4KJuDnKsFiuunoAiXAQv/i67ZdsXUg05LeqZd2KwLxgeQCOQLAZA3AaAKPji6faYmPEUwzAvP3T00vYOhyxNoNuOCUg6QHoOoAeJ+D34Y9+6fqNPo2B5+qpJP7uuQs9FwCWSGlnPlNAsVztORkrGgxYabhubSC8kIwEEAr4bAaAmcVAePtC+c/eeBnK1c4OUVcX8BHFA5BtKpxtWaRRevbsMl6/Z6zpayfCQatNNgDXcZbdQhsATd8jPYBeWzglai1AvlRBuMdkLLl4+n1k7eTbhYiwecg+GCZfqqJcZVsMAADe86qp1Z9sA2Rqq+H3WYV3gPne/PGd1+ONjp498pwK5aprBbD9sQ4JSBsAjaZzXD1lVm72WhGYxGYAytWe82SkfLJlOLym3jabEmFbLYCzEVw3kUZsJBask9ruuL6+Y6d6Tm49gFSSSs0AsL4eQG99kjSaVbB1OIJkONCTKaCA3QAUSpWeuw5Zp7BteHX6v2TTkL0aOLWOBkA23PPa4jupnJMXDyBdKKMqGhYui/kPug5Ao+kARIRrtgzZWhT0ErLCt9c9gNXq/5JNCbMamNlcKGX17HoslNKIeTUAqizVygNIhANghjW+dDlXQiTod62Y7jSefgMR3UZELxHRMSK6z+X+jxDRs0T0FBH9kIj2ieMfFMfkvyoRXS/uu0E85xgR/QldqikMmr7g3//8dfgPP/+qjT6NVREK+DEUCeJ8Kr9ug+07iTQAq80AkmweCiNfqloLf20YzDpIQCJ+5HUGh/RKRqLBls9xzgRYrzYQgAcDQER+AA8AeBeAfQDeLxd4hYeY+Tpmvh7AZwDcDwDM/CVmvl4c/xCAE8z8lHjOnwL45wD2in+3rflqNJoG7BqPdWxE4EYwkQhZmSK9FsyOdMgDmHSkgq44WkF3E0sCinn7XZGgH34ftZR/gFoh3yVpAADcCOAYMx9n5iLM4e53qA9g5pRyMwa4VmG8XzwXRDQFIMnMj7Ppz/0FgPe1f/oazWAwEQ9ZrQh6VgJaowcgZwNLA5DK2YfBdBM5c2HUowRERNiUCGHflmTLx8rzTxdMg5bKr58B8PKX2wrgjHJ7GsBNzgcR0d0APgbAAPA2l9f5JdQMx1bxOuprdnf4pUbTw0wkQjh8ahFA7/Uz2pQMw/D7sGuNlcoy515WA6+rB2BlAXnvMPrlu2721JHU2RF0OVfGVpeW2d2gY1sJZn6AmfcA+ASAT6r3EdFNALLM/Fy7r0tEdxHRISI6NDs726Gz1Wh6i4lECMXK+g227yTvfdUWfOdfvHnNzeo21UlAZfgItrz8bmGlgbbRYnrnWMzTTj7pGAqTusQkoLMAtiu3t4ljjXgY9XLOnQC+7HhNdfJDw9dk5geZeT8z75+YcJ8WpNH0O2qjt07PmO42fh+tOQAMmLGPyyZi+Junz6NSZazkzUZw65E/smM0CsPvw95NrTX9dnGOhTTHQa5PxpoXA3AQwF4i2k1EBszF/ID6ACLaq9x8D4Cjyn0+AL8Iof8DADOfB5AioptF9s+vAPjrVV+FRtPnTCi7514taOsEH3/7lXjp4gq+evgMUo5hMN1k20gUL/7b23DNlqGOv7Y6FrJcqSJdKF86MQBmLhPRPQAeBeAH8DlmPkJEnwZwiJkPALiHiG4FUAKwCODDyku8CcAZZj7ueOnfBPA/AEQA/J34p9FoXOhlD6CTvPu6zXjNjmH84d+/jMsn4+ui/0u61UgwapgZQyv5khUHuGQMAAAw8yMAHnEc+5Ty871NnvsYgJtdjh8CcK3XE9VoBhnVAAyyB0BE+OR7rsYv/Ok/YmalgJt2j270Ka0ZIkI8ZPYDWs82EICuBNZoegLtAdS4Yeco3n3dZgDrkwG0HsiGcNoAaDSaOkaitVm7g+wBSH73nVch6CcMr8PUrPUgIUZIrrcB6M3mKBrNgOH3EcZiBmZWCj1XCdwNdo3H8IX/80ZsWad8+W6TCAeQypfXtRU0oD0AjaZnkDJQL4617AZvuHx8zcVllwpJLQFpNJpmSAOgPYD+wykBrcc4SEAbAI2mZ5C1ANoD6D9kFlAqV4IR8K2bkdefJI2mR9g9EcNozFjTVC3NpYkcCrOenUABHQTWaHqGX3vjbvyT125r/UBNz5EIB1GpMi6k8toAaDSaekIBPyaTWv/vR2Q7iOnF3LoaAO1LajQazQZTMwBZbQA0Go1mkJBzjfOlqjYAGo1GM0ioXU21AdBoNJoBQu1plFynFteANgAajUaz4agewHoVgQHaAGg0Gs2GoyUgjUajGVBiRgBysqU2ABqNRjNA+HzmUBjgEjQARHQbEb1ERMeI6D6X+z9CRM8S0VNE9EMi2qfc9yoi+kciOiIeExbHHxOv+ZT4N9m5y9JoNJreIiENwDrOOGgZbiYiP4AHALwdwDSAg0R0gJmfVx72EDP/N/H42wHcD+A2IgoA+J8APsTMTxPRGMy5wZIPitGQGo1GM9AkwkFgeX1bQXjxAG4EcIyZjzNzEcDDAO5QH8DMKeVmDACLn98B4Blmflo8bp6ZK2s/bY1Go+kvZCA4uZ6D7j08ZiuAM8rtaXHMBhHdTUSvAPgMgN8Sh68AwET0KBH9hIh+1/G0zwv5518RyRCIRqPRDB6JcAABHyFqrF+/p44FgZn5AWbeA+ATAD4pDgcAvBHAB8X/P0dEPyvu+yAzXwfgFvHvQ26vS0R3EdEhIjo0OzvbqdPVaDSaS4pEOIihSBDruRf2YgDOAtiu3N4mjjXiYQDvEz9PA/g+M88xcxbAIwBeCwDMfFb8vwLgIZhSUx3M/CAz72fm/RMTEx5OV6PRaHqPX755J37nnVeu6+/0YgAOAthLRLuJyABwJ4AD6gOIaK9y8z0AjoqfHwVwHRFFRUD4zQCeJ6IAEY2L5wYBvBfAc2u7FI1Go+ldbtw9ijtv3LGuv7NlFhAzl4noHpiLuR/A55j5CBF9GsAhZj4A4B4iuhVmhs8igA+L5y4S0f0wjQgDeISZv0FEMQCPisXfD+BbAP6sC9en0Wg0mgYQM7d+1CXC/v37+dAhnTWq0Wg07UBEh5l5v/O4rgTWaDSaAUUbAI1GoxlQtAHQaDSaAUUbAI1GoxlQtAHQaDSaAUUbAI1GoxlQeioNlIhmAZxa5dPHAcx18HR6gUG8ZmAwr3sQrxkYzOtezTXvZOa6Vgo9ZQDWAhEdcsuD7WcG8ZqBwbzuQbxmYDCvu5PXrCUgjUajGVC0AdBoNJoBZZAMwIMbfQIbwCBeMzCY1z2I1wwM5nV37JoHJgag0Wg0GjuD5AFoNBqNRqHvDQAR3UZELxHRMSK6b6PPp1sQ0XYi+i4RPU9ER4joXnF8lIj+gYiOiv9HNvpcOw0R+Ynop0T0t+L2biJ6Qrzn/0vMsegriGiYiL5KRC8S0QtE9Pp+f6+J6KPis/0cEX2ZiML9+F4T0eeIaIaInlOOub63ZPIn4vqfIaLXtvO7+toAEJEfwAMA3gVgH4D3E9G+jT2rrlEG8HFm3gfgZgB3i2u9D8C3mXkvgG+L2/3GvQBeUG7/RwB/xMyXw5xP8Wsbclbd5Y8BfJOZrwLwapjX37fvNRFthTlrfD8zXwtzjsid6M/3+n8AuM1xrNF7+y4Ae8W/uwD8aTu/qK8NAMwxk8eY+TgzF2GOq7xjg8+pKzDzeWb+ifh5BeaCsBXm9X5BPOwLqI3r7AuIaBvMKXR/Lm4TgLcB+Kp4SD9e8xCANwH4LAAwc5GZl9Dn7zXMAVYRMV0wCuA8+vC9ZubvA1hwHG703t4B4C/Y5HEAw0Q05fV39bsB2ArgjHJ7Whzra4hoF4DXAHgCwCZmPi/uugBg00adV5f4zwB+F0BV3B4DsMTMZXG7H9/z3QBmAXxeSF9/Lqbs9e17LWaI/wGA0zAX/mUAh9H/77Wk0Xu7pjWu3w3AwEFEcQBfA/DbzJxS72Mz5atv0r6I6L0AZpj58EafyzoTAPBaAH/KzK8BkIFD7unD93oE5m53N4AtAGKol0kGgk6+t/1uAM4C2K7c3iaO9SVixvLXAHyJmf9KHL4oXULx/8xGnV8X+BkAtxPRSZjy3ttgauPDQiYA+vM9nwYwzcxPiNtfhWkQ+vm9vhXACWaeZeYSgL+C+f73+3stafTermmN63cDcBDAXpEpYMAMGh3Y4HPqCkL7/iyAF5j5fuWuAwA+LH7+MIC/Xu9z6xbM/HvMvI2Zd8F8b7/DzB8E8F0A/0Q8rK+uGQCY+QKAM0R0pTj0swCeRx+/1zCln5uJKCo+6/Ka+/q9Vmj03h4A8CsiG+hmAMuKVNQaZu7rfwDeDeBlAK8A+JcbfT5dvM43wnQLnwHwlPj3bpia+LcBHAXwLQCjG32uXbr+twD4W/HzZQCeBHAMwF8CCG30+XXheq8HcEi83/8bwEi/v9cA/g2AFwE8B+CLAEL9+F4D+DLMOEcJprf3a43eWwAEM9PxFQDPwsyS8vy7dCWwRqPRDCj9LgFpNBqNpgHaAGg0Gs2Aog2ARqPRDCjaAGg0Gs2Aog2ARqPRDCjaAGg0Gs2Aog2ARqPRDCjaAGg0Gs2A8v8D5eIKsgrXVQ0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist_pos_max_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c11ad3-a076-4859-8716-2bc3415b765c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist_props_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0820a2ad-46fa-4428-8c70-c8be0eddd5e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "EinopsError",
     "evalue": " Error while processing rearrange-reduction pattern \"a b -> a n b\".\n Input tensor shape: torch.Size([10, 10]). Additional info: {'n': 1}.\n Identifiers only on one side of expression (should be on both): {'n'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEinopsError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/Wiki_103/venv/lib/python3.9/site-packages/einops/einops.py:409\u001b[0m, in \u001b[0;36mreduce\u001b[0;34m(tensor, pattern, reduction, **axes_lengths)\u001b[0m\n\u001b[1;32m    408\u001b[0m hashable_axes_lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28msorted\u001b[39m(axes_lengths\u001b[38;5;241m.\u001b[39mitems()))\n\u001b[0;32m--> 409\u001b[0m recipe \u001b[38;5;241m=\u001b[39m \u001b[43m_prepare_transformation_recipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes_lengths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhashable_axes_lengths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _apply_recipe(recipe, tensor, reduction_type\u001b[38;5;241m=\u001b[39mreduction)\n",
      "File \u001b[0;32m~/Documents/Wiki_103/venv/lib/python3.9/site-packages/einops/einops.py:263\u001b[0m, in \u001b[0;36m_prepare_transformation_recipe\u001b[0;34m(pattern, operation, axes_lengths)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(difference) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 263\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m EinopsError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIdentifiers only on one side of expression (should be on both): \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(difference))\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m operation \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepeat\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mEinopsError\u001b[0m: Identifiers only on one side of expression (should be on both): {'n'}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mEinopsError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [52]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43meinops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrearrange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ma b -> a n b\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Wiki_103/venv/lib/python3.9/site-packages/einops/einops.py:487\u001b[0m, in \u001b[0;36mrearrange\u001b[0;34m(tensor, pattern, **axes_lengths)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRearrange can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be applied to an empty list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    486\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m get_backend(tensor[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstack_on_zeroth_dimension(tensor)\n\u001b[0;32m--> 487\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrearrange\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43maxes_lengths\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Wiki_103/venv/lib/python3.9/site-packages/einops/einops.py:418\u001b[0m, in \u001b[0;36mreduce\u001b[0;34m(tensor, pattern, reduction, **axes_lengths)\u001b[0m\n\u001b[1;32m    416\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Input is list. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    417\u001b[0m message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdditional info: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(axes_lengths)\n\u001b[0;32m--> 418\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m EinopsError(message \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e))\n",
      "\u001b[0;31mEinopsError\u001b[0m:  Error while processing rearrange-reduction pattern \"a b -> a n b\".\n Input tensor shape: torch.Size([10, 10]). Additional info: {'n': 1}.\n Identifiers only on one side of expression (should be on both): {'n'}"
     ]
    }
   ],
   "source": [
    "einops.rearrange(torch.tensor([[i for i in range(10)]] * 10), 'a b -> a n b', n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "a47a9054-3ac0-4855-9911-86e682458570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 1024)"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([\n",
    "        [1024 + j - i - 1 for j in range(1024) ] \n",
    "        for i in range(1024)\n",
    "    ]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "e29cca73-76ff-4d73-bfcf-6c1dd24ea17d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_fact.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "e3d0cc06-ec60-4f8e-b335-e714e0affc73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_fact.type(torch.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "cf32cd82-80e9-4858-ba62-72bb69795a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[29, 25, 26, ..., 52, 53, 54],\n",
       "        [33, 29, 30, ..., 56, 57, 58],\n",
       "        [32, 28, 29, ..., 55, 56, 57],\n",
       "        ...,\n",
       "        [ 6,  2,  3, ..., 29, 30, 31],\n",
       "        [ 5,  1,  2, ..., 28, 29, 30],\n",
       "        [ 4,  0,  1, ..., 27, 28, 29]],\n",
       "\n",
       "       [[29, 21, 22, ..., 48, 49, 50],\n",
       "        [37, 29, 30, ..., 56, 57, 58],\n",
       "        [36, 28, 29, ..., 55, 56, 57],\n",
       "        ...,\n",
       "        [10,  2,  3, ..., 29, 30, 31],\n",
       "        [ 9,  1,  2, ..., 28, 29, 30],\n",
       "        [ 8,  0,  1, ..., 27, 28, 29]],\n",
       "\n",
       "       [[29,  1,  2, ..., 27, 28, 30],\n",
       "        [57, 29, 30, ..., 55, 56, 58],\n",
       "        [56, 28, 29, ..., 54, 55, 57],\n",
       "        ...,\n",
       "        [31,  3,  4, ..., 29, 30, 32],\n",
       "        [30,  2,  3, ..., 28, 29, 31],\n",
       "        [28,  0,  1, ..., 26, 27, 29]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[29, 19, 20, ..., 46, 47, 48],\n",
       "        [39, 29, 30, ..., 56, 57, 58],\n",
       "        [38, 28, 29, ..., 55, 56, 57],\n",
       "        ...,\n",
       "        [12,  2,  3, ..., 29, 30, 31],\n",
       "        [11,  1,  2, ..., 28, 29, 30],\n",
       "        [10,  0,  1, ..., 27, 28, 29]],\n",
       "\n",
       "       [[29, 13, 14, ..., 40, 41, 42],\n",
       "        [45, 29, 30, ..., 56, 57, 58],\n",
       "        [44, 28, 29, ..., 55, 56, 57],\n",
       "        ...,\n",
       "        [18,  2,  3, ..., 29, 30, 31],\n",
       "        [17,  1,  2, ..., 28, 29, 30],\n",
       "        [16,  0,  1, ..., 27, 28, 29]],\n",
       "\n",
       "       [[29, 19, 20, ..., 46, 47, 48],\n",
       "        [39, 29, 30, ..., 56, 57, 58],\n",
       "        [38, 28, 29, ..., 55, 56, 57],\n",
       "        ...,\n",
       "        [12,  2,  3, ..., 29, 30, 31],\n",
       "        [11,  1,  2, ..., 28, 29, 30],\n",
       "        [10,  0,  1, ..., 27, 28, 29]]])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returned_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c6126097-8365-43df-b457-42a4c97b859a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.25330349802970886, 0.01613856665790081)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_props_l2, hist_props_l2_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2f1778cb-bcfe-4ce2-8618-16f459a68248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.21183332800865173, 0.01289786770939827)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_neg_l2, hist_neg_l2_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "411ffbd5-ceb5-4ea9-8ba3-0cc65fb6c1ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.26231759786605835, 0.019070377573370934)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_pos_max_l2, hist_pos_max_l2_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "de851be3-c786-4101-b08a-4118fb136853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66.89488220214844, 4.0206427574157715)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_pos_sum_l2, hist_pos_sum_l2_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "95a73033-2a88-428b-870c-f7167b1b334a",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_fact = torch.zeros((10 * 480, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a42b55fb-dd70-4510-8d28-ecd8029a917c",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_none_loss = torch.nn.MSELoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c1194204-1aa6-41ef-987c-bd8a30580552",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_pred = l2_none_loss(neg_fact, meanings_pred[:, 20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1e649322-1d6f-4926-8ac5-aa3bb90253f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4800, 100])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9b6dfcfa-1445-411d-96ff-b15d247184f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4800, 100])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(neg_pred * loss_mask2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "73970107-bb0e-4e79-b11c-29102fcf3cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4800, 1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_mask2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aedd3e37-23bb-4ff5-a57c-04502436525a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1571])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_mask2[480,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "id": "06abdf7c-824d-4cc9-8889-82d704c66e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4800, 120, 180])"
      ]
     },
     "execution_count": 721,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states_ext.shape\n",
    "# hidden_states = einops.repeat(hidden_states, 'r bs e -> (r bs) m e',\n",
    "# m=TokensEmb.cnt_categories * TokensEmb.cnt_meanings * cnt_negative, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4ec86a-82ed-41a2-bc61-a9d27e161637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [4800, 120, 180] = [10(agg) x 16 (bs) 30(seq), 120, 180] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "id": "6f366a90-cf12-47c4-9d6e-a8f542dfaa97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4800, 120, 80])"
      ]
     },
     "execution_count": 722,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_false_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "id": "58ebd46f-7ae5-45b4-aec9-0906b2373b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([480, 120, 80])"
      ]
     },
     "execution_count": 705,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_false_batch = torch.cat([tokens_embs, negative_batch], axis=1)\n",
    "true_false_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "id": "e7cf3326-ce66-4656-ad70-7ef69de20a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([480, 100, 30]), torch.Size([480, 100, 50]))"
      ]
     },
     "execution_count": 692,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([cat_emb_ext2, negative_batch2], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "38cdfc05-cb29-408d-802e-9fbe2e52763b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1312, -0.0948,  0.2202,  0.1414,  0.2555,  0.4131,  0.3525, -0.3640,\n",
       "        -0.0362,  0.1579, -0.0383, -0.3065,  0.1020, -0.2766, -0.3648,  0.1268,\n",
       "         0.3612,  0.1698,  0.0396, -0.1943, -0.0156,  0.1032, -0.1395,  0.2881,\n",
       "         0.1752, -0.4159, -0.2856, -0.0416, -0.0387,  0.4081],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_emb_ext2[0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "id": "ba18b4d3-e184-4399-af8b-6072a27fd88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0022,  0.0484,  0.1391,  0.3842, -0.0386,  0.2287,  0.2664, -0.2704,\n",
       "        -0.2611,  0.2052,  0.1788,  0.4159,  0.0611, -0.3091, -0.4118,  0.2832,\n",
       "        -0.1521, -0.4052, -0.1839,  0.3027, -0.3857, -0.3729,  0.0468, -0.3128,\n",
       "         0.3849,  0.0253,  0.0616, -0.1326, -0.2529, -0.1535],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 691,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_emb_ext2[0,25,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "5bd4f027-fdb4-46dc-951e-abf1610f2a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([480, 25, 50])"
      ]
     },
     "execution_count": 665,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "04344c02-dbe2-4aea-a57c-4e1fb205449f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 30, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4800, 4])"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tokens_props.shape)\n",
    "tokens_props = einops.repeat(tokens_props, 'b s f -> (m b s) f', m=10)\n",
    "tokens_props.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "bbd67e2e-e26e-42a3-9107-7da376805ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([480, 180])"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "3ea5c383-27df-4a1e-b0b2-7933bca65655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4800, 180])"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states2 = einops.rearrange(hidden_states, 'r bs e -> (r bs) e')\n",
    "hidden_states2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "642e6809-81e6-4157-8a19-07bd64c185fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = PropNet.forward(hidden_states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "705f90cc-928f-4f1a-a150-809a20f522f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4800, 4])"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_props.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "643b8fed-6d1f-4430-a3c4-6b03b56b77f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4800, 4])"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "946b899b-b5c1-4edf-a591-7b4a12d7a66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_mean_loss = torch.nn.MSELoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "9d3497d5-0edd-4f3e-989a-8f9edcd485f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4800, 4])"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_mean_loss(tmp, tokens_props).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "ebe17d95-35c3-4adc-abdb-6e2024735ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_mask = torch.tensor([1.0, ] + [0.05] * 29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "id": "69a71c77-fe17-4b94-abef-89407b0c013f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0708, 0.1571, 0.2504, 0.3486, 0.4506, 0.5557, 0.6635, 0.7737, 0.8859,\n",
       "        1.0000])"
      ]
     },
     "execution_count": 641,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_mask2 = torch.tensor([(i/10)**1.15 for i in range(1,11)])\n",
    "loss_mask2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "id": "720a8153-3b4a-4566-82c4-6fbef889d412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0794],\n",
       "         [0.0794],\n",
       "         [0.0794],\n",
       "         ...,\n",
       "         [1.0000],\n",
       "         [1.0000],\n",
       "         [1.0000]]),\n",
       " torch.Size([4800, 1]))"
      ]
     },
     "execution_count": 638,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_mask2 = torch.tensor([(i/10)**1.1 for i in range(1,11)])\n",
    "loss_mask2 =einops.repeat(loss_mask2, 'h -> (h bs) f', bs=480, f=1)\n",
    "loss_mask2, loss_mask2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "dc8cbcb5-cc21-467a-8b6a-0d0d2ea2eab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4800, 1])"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_mask2 =einops.repeat(loss_mask2, 'h -> (h bs) f', bs=480, f=1)\n",
    "loss_mask2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "161f47ed-41e5-4eac-af0e-e83185bd5ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0631])"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_mask2[479,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "1d2b2b66-e3e1-4fec-9b1d-d501aecb724e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4800, 1])"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_mask2 = einops.repeat(loss_mask, 's -> (rp b s) f', rp=10, b=16, f=1)\n",
    "loss_mask2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "ec969f70-8e58-493c-a984-b02bf826ba2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_mask2[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "34a4ad90-6eb0-4b60-8e7c-43e1b6aa9f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_mask2[30,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f268d0-5ed9-4989-a3b5-7f40c01784c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638bcb16-53e4-4ac6-a41b-a734a7e9e5fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba37041c-6066-41f7-961a-f7ca7db32a01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "811c8006-6002-482b-8859-a553f45abbb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1631, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_mean_loss(tmp, tokens_props).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20257ae6-0787-4ab5-a524-9cb8d3077a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "5e2037b7-1b60-48cb-a8a6-9dd4d42d2694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  cnt\n",
       "0  0  0  0  0    6\n",
       "1  0  0  0  1  394\n",
       "2  0  0  1  0    5\n",
       "3  0  0  1  1   19\n",
       "4  1  0  0  0   12\n",
       "5  1  0  0  1   40\n",
       "6  1  1  0  0    1\n",
       "7  1  1  0  1    3"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tokens_props).groupby([0,1,2,3]).size().to_frame('cnt').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "52416c08-92cf-48a2-8063-bcb42f6259ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 230 ms, sys: 177 ms, total: 408 ms\n",
      "Wall time: 84.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ftmp = torch.cat([pos_matrix, props_embs, tokens_embs], axis=4)\n",
    "ftmp = einops.rearrange(ftmp, 'b s1 s2 m e -> (b s1) (s2 m) e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "bae97352-07a0-49c4-92ef-349a479b72c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 433 ms, sys: 454 ms, total: 887 ms\n",
      "Wall time: 194 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tmp1 = einops.rearrange(pos_matrix, 'b s1 s2 m e -> (b s1) (s2 m) e')\n",
    "tmp2 = einops.rearrange(props_embs, 'b s1 s2 m e -> (b s1) (s2 m) e')\n",
    "tmp3 = einops.rearrange(tokens_embs, 'b s1 s2 m e -> (b s1) (s2 m) e')\n",
    "ftmp = torch.cat([tmp1, tmp2, tmp3], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "fcc4864d-7cac-4f94-a554-eccb21530601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 287 ms, sys: 203 ms, total: 491 ms\n",
      "Wall time: 127 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ftmp = torch.cat([tmp1, tmp2, tmp3], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "be44a014-4b01-4c08-8136-8dc24a290913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([480, 600, 140])"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "1e3817dd-9138-4d4d-917b-d3ada234ee3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210.0"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "140 * 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "fd3a2cbb-2065-4c00-bfc5-7f03397e24e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 30, 30, 20, 20])"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "f374f15d-e59f-46b6-b601-af169019d90c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 30, 30, 20, 40])"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "props_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "ae5ffed9-17aa-4363-97bb-7ce28fc85468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 30, 30, 20, 80])"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "03c67b3c-ac62-49f9-a897-f91f6873d3bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POS_EMB_SIZE + TITLE_EMB_SIZE + UPPER_EMB_SIZE + PART_EMB_SIZE + END_EMB_SIZE + CAT_EMB_SIZE + MEANING_EMB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "4978174f-6d75-41f8-a7e5-5ff51facc2ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TITLE_EMB_SIZE + UPPER_EMB_SIZE + PART_EMB_SIZE + END_EMB_SIZE + CAT_EMB_SIZE + MEANING_EMB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "3ed87fd2-802d-41c4-91e1-babb5fe4b31b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [10, 10] at entry 0 and [10, 20] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [261]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43meinops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrearrange\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ml a b -> a (l b)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Wiki_103/venv/lib/python3.9/site-packages/einops/einops.py:486\u001b[0m, in \u001b[0;36mrearrange\u001b[0;34m(tensor, pattern, **axes_lengths)\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tensor) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    485\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRearrange can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be applied to an empty list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 486\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43mget_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack_on_zeroth_dimension\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m reduce(tensor, pattern, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrearrange\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39maxes_lengths)\n",
      "File \u001b[0;32m~/Documents/Wiki_103/venv/lib/python3.9/site-packages/einops/_backends.py:334\u001b[0m, in \u001b[0;36mTorchBackend.stack_on_zeroth_dimension\u001b[0;34m(self, tensors)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstack_on_zeroth_dimension\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensors: \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m--> 334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [10, 10] at entry 0 and [10, 20] at entry 1"
     ]
    }
   ],
   "source": [
    "_ = einops.rearrange([a, b, c], 'l a b -> a (l b)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "123515b1-1463-4654-8265-99e9a4e4cc57",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [128, 30, 30, 20, 20] at entry 0 and [128, 30, 30, 20, 40] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m~/Documents/Wiki_103/venv/lib/python3.9/site-packages/einops/einops.py:486\u001b[0m, in \u001b[0;36mrearrange\u001b[0;34m(tensor, pattern, **axes_lengths)\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tensor) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    485\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRearrange can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be applied to an empty list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 486\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43mget_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack_on_zeroth_dimension\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m reduce(tensor, pattern, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrearrange\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39maxes_lengths)\n",
      "File \u001b[0;32m~/Documents/Wiki_103/venv/lib/python3.9/site-packages/einops/_backends.py:334\u001b[0m, in \u001b[0;36mTorchBackend.stack_on_zeroth_dimension\u001b[0;34m(self, tensors)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstack_on_zeroth_dimension\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensors: \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m--> 334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [128, 30, 30, 20, 20] at entry 0 and [128, 30, 30, 20, 40] at entry 1"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_ = einops.rearrange([pos_matrix, props_embs, tokens_embs],\n",
    "                     'l b s1 s2 c e -> b s1 s2 c e'\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d37c02-f475-4c47-9609-ce4f30c51980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "5bf9eb12-82ce-4578-a69a-31859dc57b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0785, -0.2282, -0.2500,  0.0691, -0.0209, -0.1392,  0.0557,  0.1047,\n",
       "         0.2192,  0.2140, -0.0413, -0.2430, -0.2490,  0.2573,  0.1218,  0.1201,\n",
       "        -0.2384,  0.2552,  0.2611,  0.2488], dtype=torch.float64,\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_matrix[0,0,0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "830c8427-1623-4d30-9e6d-8b7b2cd2ca3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0785, -0.2282, -0.2500,  0.0691, -0.0209, -0.1392,  0.0557,  0.1047,\n",
       "         0.2192,  0.2140, -0.0413, -0.2430, -0.2490,  0.2573,  0.1218,  0.1201,\n",
       "        -0.2384,  0.2552,  0.2611,  0.2488], dtype=torch.float64,\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_matrix[0,0,0,15,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "a412a279-7381-4a16-9414-a4aaf49b7fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0691, -0.0598,  0.2026, -0.2136,  0.0293,  0.2592, -0.0379,  0.2140,\n",
       "        -0.0849,  0.2218, -0.2666, -0.0397, -0.0484,  0.0893,  0.1081,  0.2116,\n",
       "        -0.0411, -0.0109,  0.1887, -0.0746], dtype=torch.float64,\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_matrix[0,1,0,5,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "b03fe569-7e51-4333-b375-8e76d4a7441a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "props_embs[0,0,0,0,:] == props_embs[0,0,2,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49338fc-27cd-49df-a6ae-b143cb0884b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "props_embs[:,0,0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "694a19a1-ece3-4691-bdfb-8a05a563b152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TokensEmbeding, forward time: 0.4157431125640869\n",
      "CPU times: user 580 ms, sys: 868 ms, total: 1.45 s\n",
      "Wall time: 417 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "old_var = TokensEmb.forward(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e20ef071-e904-4c78-8b10-29be044735eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TokensEmbeding, forward2 time: 3.1199347972869873\n",
      "CPU times: user 2.94 s, sys: 4.99 s, total: 7.93 s\n",
      "Wall time: 3.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "old_var2 = TokensEmb.forward2(extend_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5963b1d-9881-4de8-ad54-de1ca8ed5766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TokensEmbeding, forward3 time: 0.0433809757232666\n",
      "CPU times: user 79.1 ms, sys: 115 ms, total: 194 ms\n",
      "Wall time: 44.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "old_var3 = TokensEmb.forward3(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "abbb1c95-a5d6-4c07-9633-4291090e02ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TokensEmbeding, forward3 time: 0.032254934310913086\n",
      "CPU times: user 73.2 ms, sys: 55.6 ms, total: 129 ms\n",
      "Wall time: 33.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "old_var4 = TokensEmb.forward4(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ceb17729-2692-4810-b29e-1580219a8cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat_emb: torch.Size([128, 30, 20, 30])\n",
      "cnt_categories: 4\n",
      "cnt_meanings: 5\n",
      "cat_emb: torch.Size([128, 30, 20, 50])\n",
      "TokensEmbeding, forward5 time: 0.03566884994506836\n",
      "CPU times: user 67.5 ms, sys: 90.3 ms, total: 158 ms\n",
      "Wall time: 37.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "old_var5 = TokensEmb.forward5(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ac8125-c1cf-4ca2-831d-8e766a24127e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "abab7865-2750-4a69-9a18-9d147afc40cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(184320000)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(old_var == old_var4).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "id": "f29f9d5e-3105-41c5-a271-e8f1dada74e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 30, 30, 20, 80])"
      ]
     },
     "execution_count": 797,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_var3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "id": "22c860cc-04a2-44d7-80fc-cb8d0a77492f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184320000"
      ]
     },
     "execution_count": 798,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128 * 30 * 30 * 20 * 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e77996-408e-4b9c-ae9a-f9ab87aae485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c72a5e0-1eb8-4075-b299-7693beb510b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9146d95-f0b4-49da-babc-7ff4fa4118a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee37552c-815c-4f1b-ba27-0e52da73e9d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "id": "1fd64c6f-794d-448c-ba8c-3059d6a78f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PropsEmbeding, forward time: 0.24170589447021484\n",
      "CPU times: user 350 ms, sys: 489 ms, total: 839 ms\n",
      "Wall time: 262 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "old_var = PropsEmb.forward(extend_batch[:,:,:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "id": "87bfdb0a-e134-44bb-bbb5-25e7d0fb3abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PropsEmbeding, forward2 time: 0.6497049331665039\n",
      "CPU times: user 1.25 s, sys: 1.01 s, total: 2.26 s\n",
      "Wall time: 650 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "old_var2 = PropsEmb.forward2(extend_batch[:,:,:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "id": "7fa92d08-c5c1-4c29-99f0-4277e64d9efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PropsEmbeding, forward3 time: 0.20324993133544922\n",
      "CPU times: user 224 ms, sys: 410 ms, total: 634 ms\n",
      "Wall time: 203 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "old_var3 = PropsEmb.forward3(batch[:,:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "id": "957518c2-4565-4155-be62-bfb50cf9aa05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PropsEmbeding, forward4 time: 0.0036687850952148438\n",
      "CPU times: user 2.26 ms, sys: 2.88 ms, total: 5.14 ms\n",
      "Wall time: 3.81 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "new_var = PropsEmb.forward4(batch[:,:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "id": "974b86cc-66ad-494a-8e24-d149bc57e657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PosEncoding, forward time: 0.06662583351135254\n",
      "CPU times: user 128 ms, sys: 222 ms, total: 350 ms\n",
      "Wall time: 69.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "old_var = PosEnc.forward(torch.tensor(pos_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "id": "455ff992-d06b-46d8-b49a-a49397547e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PosEncoding, forward2 time: 0.0031812191009521484\n",
      "CPU times: user 8.88 ms, sys: 3.81 ms, total: 12.7 ms\n",
      "Wall time: 3.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "new_var = PosEnc.forward2(torch.tensor(pos_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "fae792db-31ae-4378-8e05-6ac5ae507ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 30, 30]), torch.Size([128, 30]))"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extend_batch.shape, batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "1e109573-2b4f-4b86-b1aa-a06c9e1ffc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.13287878036499023\n"
     ]
    }
   ],
   "source": [
    "a= PropsEmb.forward(extend_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "7bc9617d-d081-4405-b180-e7b3b9eba3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.4492971897125244\n"
     ]
    }
   ],
   "source": [
    "b= PropsEmb.forward2(extend_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "f305013e-3bfb-4c55-824d-bd603a2c06ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.09531116485595703\n"
     ]
    }
   ],
   "source": [
    "c= PropsEmb.forward3(batch[:,:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "id": "31f2825d-2eff-49ff-967b-d1ecd7fd34da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time1: 0.0303800106048584\n",
      "time2: 0.01830887794494629\n",
      "time3: 0.19798922538757324\n",
      "time4: 0.0001437664031982422\n",
      "time: 0.24683094024658203\n"
     ]
    }
   ],
   "source": [
    "a = TokensEmb.forward(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "65d717f9-bcf2-4db0-8aa0-827e28c9b1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time1: 1.5422999858856201\n",
      "time: 2.8998541831970215\n"
     ]
    }
   ],
   "source": [
    "b = TokensEmb.forward2(extend_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "d5f644c3-7b13-410e-9fdc-a0aaddc1de39",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "randint() received an invalid combination of arguments - got (tuple), but expected one of:\n * (int high, tuple of ints size, *, torch.Generator generator, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool requires_grad)\n * (int low, int high, tuple of ints size, *, torch.Generator generator, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool requires_grad)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [644]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: randint() received an invalid combination of arguments - got (tuple), but expected one of:\n * (int high, tuple of ints size, *, torch.Generator generator, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool requires_grad)\n * (int low, int high, tuple of ints size, *, torch.Generator generator, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool requires_grad)\n"
     ]
    }
   ],
   "source": [
    "torch.randint((128, 30, 5*4, 30+50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd13a78-0b5f-4a2e-8182-131c0d56f6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch_Size x SeqLen x Cnt_Meanings * CntCats x (CatEmb + MeaningEmb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "1f943382-226e-44f4-8e7d-2156f614d715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 643,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CAT_SIZES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "48304bc3-5ed1-450b-9f10-074304a3f3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.rand((1, 128, 30, 5*4, 30+50)).requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "id": "71db6576-e3b0-4e20-8970-de3f7ac0a0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 270 ms, sys: 404 ms, total: 674 ms\n",
      "Wall time: 149 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "c = a.repeat(30, 1,1,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "id": "abc71abb-d318-468c-b734-188178e54dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 980 µs, sys: 4.01 ms, total: 4.99 ms\n",
      "Wall time: 4.37 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "d = einops.repeat(a, 'b h w s k -> (repeat b) h w s k', repeat=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "6552682e-b501-43c9-b815-6ea23bf3dc55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RepeatBackward0 at 0x7f9909b98340>"
      ]
     },
     "execution_count": 668,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "id": "42f05593-8e75-407f-b254-0e13fcaa7c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ReshapeAliasBackward0 at 0x7f9909bd2520>"
      ]
     },
     "execution_count": 671,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "id": "0e5e3f30-5816-42ee-89e8-4cce519fd3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "id": "a9c332c7-8a7e-42d1-b400-b9da7c427e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting einops\n",
      "  Downloading einops-0.4.1-py3-none-any.whl (28 kB)\n",
      "Installing collected packages: einops\n",
      "Successfully installed einops-0.4.1\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/Users/u14510182/Documents/Wiki_103/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "4ac571c0-852e-4499-9e76-9f2033c96ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 30, 30, 20, 120])"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "props_tokens_ems.repeat(30,1,1,1,1).permute(1,0,2,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "fb278919-adf0-44ed-941b-54754849b173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 128, 30, 40])"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "props_embs.repeat(20,1,1,1).transpose(0,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6844ef83-7b72-4df5-872b-f8c4d7f3ce3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.repeat(30,1,1,1,1).permute(1,2,0,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "d8c3db83-c000-4192-a7eb-e6c356299bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 30, 40, 1])"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "props_embs.unsqueeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "67c7b181-bec1-4c0d-9bdc-601fcd5a07ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = props_embs.repeat(20,1,1,1).permute(1,2,0,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "c0232fda-e29f-42e0-8461-7d8ab3814147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 30, 20, 40])"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "ae72c0ee-e898-4379-809d-2ff660ebb34a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0372, -0.3625,  0.1196, -0.6602, -0.5109, -0.3645,  0.4461,  0.4146,\n",
       "        -0.3136, -0.0255,  0.3199,  0.2844, -0.4189,  0.2136,  0.3882, -0.0892,\n",
       "         0.0270,  0.1638,  0.4387,  0.6790,  0.2568,  0.5872, -0.1455,  0.5291,\n",
       "        -0.1140,  0.0748,  0.6403, -0.6560, -0.4452, -0.1790, -0.2137, -0.1390,\n",
       "        -0.6755, -0.4683, -0.2915,  0.0262,  0.2795,  0.4243, -0.4794, -0.3079],\n",
       "       dtype=torch.float64, grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[1, 20, 2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "2dc4a0fc-30d0-40ec-8135-12f48eb8b049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "props_embs[1, 8, :] == props_embs[1, 9, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "647dac98-c2f2-49f4-836c-0ad54b8affa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(30)\n",
      "1 tensor(40)\n",
      "2 tensor(40)\n",
      "3 tensor(40)\n",
      "4 tensor(10)\n",
      "5 tensor(0)\n",
      "6 tensor(30)\n",
      "7 tensor(30)\n",
      "8 tensor(30)\n",
      "9 tensor(40)\n",
      "10 tensor(40)\n",
      "11 tensor(40)\n",
      "12 tensor(40)\n",
      "13 tensor(20)\n",
      "14 tensor(10)\n",
      "15 tensor(30)\n",
      "16 tensor(40)\n",
      "17 tensor(40)\n",
      "18 tensor(40)\n",
      "19 tensor(40)\n",
      "20 tensor(40)\n",
      "21 tensor(40)\n",
      "22 tensor(40)\n",
      "23 tensor(40)\n",
      "24 tensor(40)\n",
      "25 tensor(30)\n",
      "26 tensor(30)\n",
      "27 tensor(30)\n",
      "28 tensor(30)\n"
     ]
    }
   ],
   "source": [
    "for i in range(29):\n",
    "    print(i, sum(props_embs[1, i, :] == props_embs[1, i+1, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "7d434501-591f-45a1-9a32-c81cc6582c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0372, -0.3625,  0.1196, -0.6602, -0.5109, -0.3645,  0.4461,  0.4146,\n",
       "        -0.3136, -0.0255,  0.3199,  0.2844, -0.4189,  0.2136,  0.3882, -0.0892,\n",
       "         0.0270,  0.1638,  0.4387,  0.6790,  0.2568,  0.5872, -0.1455,  0.5291,\n",
       "        -0.1140,  0.0748,  0.6403, -0.6560, -0.4452, -0.1790, -0.2137, -0.1390,\n",
       "        -0.6755, -0.4683, -0.2915,  0.0262,  0.2795,  0.4243, -0.4794, -0.3079],\n",
       "       dtype=torch.float64, grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "props_embs[1, 2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1683b35c-a8a6-4b3e-9c81-cfdcfaec91fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp[0, 0, 0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22a0654-0fa0-4c27-ac50-25a9a57cf7cb",
   "metadata": {},
   "source": [
    "1) batch[:,:,0] -> Token_Emb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e1ade9-862e-40ec-a260-2de141d4c130",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Arhitecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f12923-9fbc-4713-8a46-e3a72c984d9c",
   "metadata": {},
   "source": [
    "#### Примерный план\n",
    "1) Каким то образом получаем батч из числовых последовательностей токенов = [Batch_Size, MAX_SEQ_LEN]\n",
    "2) Определяем конец батча\n",
    "3) Определяем целевой токен для каждой строки батча\n",
    "    Получаем следующие данные W0 = [Enc_Pos_0, Token_0], W_Other = [Enc_Pos, Token]\n",
    "4) Рандомом из батча выбираем где мы будем учитывать \n",
    "\n",
    "\n",
    "Рассмотрим на примере одного \"предложения\".\n",
    "Предложение -> Tokens -> Seq (Seq_length может быть не равна MAX_SEQ_LEN)\n",
    "Строим матрицу Seq_Tokens = [Seq] * Seq_length.\n",
    "Так же берем матрицу расстояний = [MAX_SEQ_LEN, MAX_SEQ_LEN, POS_EMB_SIZE]\n",
    "Из нее извлекаем подматрицу Seq_Pos = [Seq_length, Seq_length, POS_EMB_SIZE]\n",
    "\n",
    "Получается две матрицы - Seq_Tokens и Seq_Pos\n",
    "Выбираем целевое слово, точнее его порядковый номер.\n",
    "Перемещаем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc94eb2f-778e-40ca-8961-02bcc373d2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a89ab45-c477-4492-aa81-a33b4a92e920",
   "metadata": {},
   "source": [
    "Можно так же подавать неправильные токены в последовательность, с целью чтоб они все равно предсказывали верные.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18fb676-da1f-40b9-a81f-bdba88229de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq = [token_0, token_1, token_2, token_3]\n",
    "all_seq = [\n",
    "    [token_0, token_1, token_2, token_3],\n",
    "    [mask, token_1, token_2, token_3],\n",
    "    [token_0, mask, token_2, token_3],\n",
    "    [token_0, token_1, mask, token_3],\n",
    "    [token_0, token_1, token_2, mask],\n",
    "]\n",
    "\n",
    "for seq in all_seq:\n",
    "    seq_emb = []\n",
    "    mask_pos = get_mask_pos(seq)\n",
    "    \n",
    "    \n",
    "    for token_pos, token in enumerate(seq):\n",
    "        if token != '[MASK]':\n",
    "            token_info = []\n",
    "            pos_emb = get_pos_encoding(token_pos, mask_pos)\n",
    "            for cat in range(CNT_CATS):\n",
    "                emb_meanings = get_emb(token, cat) # Cnt_Meanings x Emb_Size\n",
    "                cat_emb = CATS[cat]\n",
    "                for m in range(Cnt_Meanings):\n",
    "                    token_info.append(torch.cat([pos_emb, cat_emb, emb_meaning]))\n",
    "                    \n",
    "            token_info = torch.cat(token_info) # Большой тензор, в котором заенкожена вся информация по токену\n",
    "            seq_emb.append(token_info)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf4db3e-009f-4ac7-b834-151436408779",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_encod_matrix = gen_pos_encodind(MAX_LEN_SEQ)\n",
    "input_seq = [token_0, token_1, token_2, token_3]\n",
    "seq_emb = []\n",
    "\n",
    "for token_pos, token in enumerate(seq):\n",
    "    token_info = []\n",
    "    pos_emb = get_pos_encoding(token_pos, mask_pos)\n",
    "    for cat in range(CNT_CATS):\n",
    "        emb_meanings = get_emb(token, cat) # Cnt_Meanings x Emb_Size\n",
    "        cat_emb = CATS[cat]\n",
    "        for m in range(Cnt_Meanings):\n",
    "            token_info.append(torch.cat([pos_emb, cat_emb, emb_meaning]))\n",
    "\n",
    "    token_info = torch.cat(token_info) # Большой тензор, в котором заенкожена вся информация по токену\n",
    "    seq_emb.append(token_info)\n",
    "    \n",
    "\n",
    "variant = choose_variant() # Выбираеем вариант\n",
    "\n",
    "# Кличество вариаций обработки одной последовательности:\n",
    "# 1) Изменяем какое-либо слова:\n",
    "#      N вариантов выбрать изменяемое слово в последовательности.\n",
    "#      N вариантов выбрать целевое слово в последовательности.\n",
    "#      N^2 вариантов, если мы еще добавим опцию опускать(маскировать) ли целевое слово во время агрегации то 2 * N^2\n",
    "# 2) Не изменяем слова в последовательности:\n",
    "#      N вариантов выбрать целевое слово.\n",
    "#      2 - опускаем или нет целевое слово при аггрегации\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50be1093-07a8-49f8-a7e1-06c5be7b2eae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad555dc3-3006-4ae8-b065-e3edc7a00115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8dcb63-60a4-4f71-b508-c6ecb0d89a08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231d359c-dff0-4ae4-baa3-ddaf22d2acd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d072cbea-163e-409d-a087-f13af5efce19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8f38dd-7771-4686-a967-9a2cf7ef7317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5728e85-0b93-4f59-8efc-265d9ff14da5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb213974-c4e9-4fa8-8a8f-6832c3db3958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ded5a5-b823-4842-9f45-b700ef2bb2f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
